{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hhh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:237: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n",
      "C:\\Users\\hhh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "C:\\Users\\hhh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of outliers using Isolation Forest:\n",
      "127\n",
      "amount of outliers using one-class SVM:\n",
      "741\n"
     ]
    }
   ],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "#grab datafile using pandas\n",
    "dataFrame = pd.read_csv(\"yeast.data\", delim_whitespace=1, names=[\"mcg\",\"gvh\",\"alm\",\"mit\",\"erl\",\"pox\",\"vac\",\"nuc\",\"class\"])\n",
    "\n",
    "\n",
    "#outlier detection using Isolation Forest:\n",
    "df = dataFrame.drop(columns=\"class\")\n",
    "dfOnlyClasses = dataFrame.drop(columns=[\"mcg\",\"gvh\",\"alm\",\"mit\",\"erl\",\"pox\",\"vac\",\"nuc\"])\n",
    "IF = IsolationForest(n_estimators=8)\n",
    "IF.fit(df)\n",
    "#negative values are outliers\n",
    "\n",
    "#find outliers and remove them\n",
    "count = 0\n",
    "IFlen = []\n",
    "for x in IF.predict(df):\n",
    "    if x < 0 and count < len(df):\n",
    "        df = df.drop(df.index[count])\n",
    "        dfOnlyClasses = dfOnlyClasses.drop(dfOnlyClasses.index[count])\n",
    "        IFlen.append(x)\n",
    "    count = count + 1\n",
    "\n",
    "\n",
    "#outlier dectection using one-class SVM\n",
    "OCSVM = OneClassSVM(gamma='auto').fit(dataFrame.drop(columns=\"class\"))\n",
    "#negative values are outliers\n",
    "outliersWithOCSVM = [x for x in OCSVM.predict(dataFrame.drop(columns=\"class\")) if x < 0]\n",
    "print('amount of outliers using Isolation Forest:')\n",
    "print(len(IFlen))\n",
    "print('amount of outliers using one-class SVM:')\n",
    "print(len(outliersWithOCSVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hhh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\hhh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 802 samples, validate on 90 samples\n",
      "Epoch 1/150\n",
      "802/802 [==============================] - 0s 192us/step - loss: 0.1382 - accuracy: 0.2232 - val_loss: 0.0905 - val_accuracy: 0.2778\n",
      "Epoch 2/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 0.0844 - accuracy: 0.2968 - val_loss: 0.0826 - val_accuracy: 0.2778\n",
      "Epoch 3/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 0.0811 - accuracy: 0.2718 - val_loss: 0.0813 - val_accuracy: 0.2778\n",
      "Epoch 4/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 0.0801 - accuracy: 0.2880 - val_loss: 0.0810 - val_accuracy: 0.2778\n",
      "Epoch 5/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 0.0796 - accuracy: 0.2968 - val_loss: 0.0820 - val_accuracy: 0.1889\n",
      "Epoch 6/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 0.0798 - accuracy: 0.2606 - val_loss: 0.0807 - val_accuracy: 0.1889\n",
      "Epoch 7/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 0.0794 - accuracy: 0.2805 - val_loss: 0.0806 - val_accuracy: 0.1889\n",
      "Epoch 8/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 0.0793 - accuracy: 0.2768 - val_loss: 0.0805 - val_accuracy: 0.2778\n",
      "Epoch 9/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 0.0791 - accuracy: 0.2968 - val_loss: 0.0805 - val_accuracy: 0.2778\n",
      "Epoch 10/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 0.0790 - accuracy: 0.2818 - val_loss: 0.0805 - val_accuracy: 0.2778\n",
      "Epoch 11/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 0.0790 - accuracy: 0.2968 - val_loss: 0.0801 - val_accuracy: 0.2778\n",
      "Epoch 12/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 0.0788 - accuracy: 0.2868 - val_loss: 0.0838 - val_accuracy: 0.2778\n",
      "Epoch 13/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 0.0794 - accuracy: 0.2968 - val_loss: 0.0803 - val_accuracy: 0.2778\n",
      "Epoch 14/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 0.0789 - accuracy: 0.2718 - val_loss: 0.0804 - val_accuracy: 0.2778\n",
      "Epoch 15/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 0.0789 - accuracy: 0.2893 - val_loss: 0.0804 - val_accuracy: 0.2778\n",
      "Epoch 16/150\n",
      "802/802 [==============================] - 0s 46us/step - loss: 0.0789 - accuracy: 0.2968 - val_loss: 0.0805 - val_accuracy: 0.2778\n",
      "Epoch 17/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 0.0787 - accuracy: 0.2830 - val_loss: 0.0800 - val_accuracy: 0.2778\n",
      "Epoch 18/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 0.0788 - accuracy: 0.2880 - val_loss: 0.0801 - val_accuracy: 0.2778\n",
      "Epoch 19/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 0.0787 - accuracy: 0.2968 - val_loss: 0.0801 - val_accuracy: 0.2778\n",
      "Epoch 20/150\n",
      "802/802 [==============================] - 0s 45us/step - loss: 0.0788 - accuracy: 0.2905 - val_loss: 0.0800 - val_accuracy: 0.2778\n",
      "Epoch 21/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 0.0786 - accuracy: 0.2980 - val_loss: 0.0802 - val_accuracy: 0.2778\n",
      "Epoch 22/150\n",
      "802/802 [==============================] - 0s 47us/step - loss: 0.0789 - accuracy: 0.2731 - val_loss: 0.0801 - val_accuracy: 0.2778\n",
      "Epoch 23/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 0.0787 - accuracy: 0.2968 - val_loss: 0.0804 - val_accuracy: 0.2778\n",
      "Epoch 24/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 0.0787 - accuracy: 0.2781 - val_loss: 0.0802 - val_accuracy: 0.2778\n",
      "Epoch 25/150\n",
      "802/802 [==============================] - 0s 47us/step - loss: 0.0787 - accuracy: 0.2855 - val_loss: 0.0808 - val_accuracy: 0.1889\n",
      "Epoch 26/150\n",
      "802/802 [==============================] - 0s 47us/step - loss: 0.0793 - accuracy: 0.2656 - val_loss: 0.0804 - val_accuracy: 0.1889\n",
      "Epoch 27/150\n",
      "802/802 [==============================] - 0s 42us/step - loss: 0.0790 - accuracy: 0.2656 - val_loss: 0.0801 - val_accuracy: 0.2778\n",
      "Epoch 28/150\n",
      "802/802 [==============================] - 0s 44us/step - loss: 0.0788 - accuracy: 0.2968 - val_loss: 0.0799 - val_accuracy: 0.2778\n",
      "Epoch 29/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 0.0788 - accuracy: 0.2843 - val_loss: 0.0804 - val_accuracy: 0.2778\n",
      "Epoch 30/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 0.0789 - accuracy: 0.2868 - val_loss: 0.0801 - val_accuracy: 0.2778\n",
      "Epoch 31/150\n",
      "802/802 [==============================] - 0s 50us/step - loss: 0.0788 - accuracy: 0.2756 - val_loss: 0.0845 - val_accuracy: 0.2778\n",
      "Epoch 32/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 0.0797 - accuracy: 0.2880 - val_loss: 0.0801 - val_accuracy: 0.2778\n",
      "Epoch 33/150\n",
      "802/802 [==============================] - 0s 42us/step - loss: 0.0787 - accuracy: 0.2968 - val_loss: 0.0830 - val_accuracy: 0.2778\n",
      "Epoch 34/150\n",
      "802/802 [==============================] - 0s 42us/step - loss: 0.0794 - accuracy: 0.2880 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 35/150\n",
      "802/802 [==============================] - 0s 44us/step - loss: 0.0788 - accuracy: 0.2693 - val_loss: 0.0801 - val_accuracy: 0.2778\n",
      "Epoch 36/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0788 - accuracy: 0.2968 - val_loss: 0.0841 - val_accuracy: 0.2778\n",
      "Epoch 37/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0794 - accuracy: 0.2968 - val_loss: 0.0800 - val_accuracy: 0.2778\n",
      "Epoch 38/150\n",
      "802/802 [==============================] - 0s 30us/step - loss: 0.0787 - accuracy: 0.2781 - val_loss: 0.0802 - val_accuracy: 0.2778\n",
      "Epoch 39/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0788 - accuracy: 0.2880 - val_loss: 0.0800 - val_accuracy: 0.3111\n",
      "Epoch 40/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0785 - accuracy: 0.2843 - val_loss: 0.0805 - val_accuracy: 0.2778\n",
      "Epoch 41/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0788 - accuracy: 0.2968 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 42/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0787 - accuracy: 0.2980 - val_loss: 0.0801 - val_accuracy: 0.2778\n",
      "Epoch 43/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 0.0788 - accuracy: 0.2880 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 44/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0787 - accuracy: 0.2968 - val_loss: 0.0834 - val_accuracy: 0.2778\n",
      "Epoch 45/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0793 - accuracy: 0.2880 - val_loss: 0.0841 - val_accuracy: 0.2778\n",
      "Epoch 46/150\n",
      "802/802 [==============================] - 0s 29us/step - loss: 0.0792 - accuracy: 0.2918 - val_loss: 0.0803 - val_accuracy: 0.2778\n",
      "Epoch 47/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0788 - accuracy: 0.2968 - val_loss: 0.0801 - val_accuracy: 0.2778\n",
      "Epoch 48/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0788 - accuracy: 0.2968 - val_loss: 0.0802 - val_accuracy: 0.2778\n",
      "Epoch 49/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0788 - accuracy: 0.2968 - val_loss: 0.0849 - val_accuracy: 0.2778\n",
      "Epoch 50/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 0.0795 - accuracy: 0.2968 - val_loss: 0.0803 - val_accuracy: 0.2778\n",
      "Epoch 51/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0787 - accuracy: 0.2980 - val_loss: 0.0801 - val_accuracy: 0.2778\n",
      "Epoch 52/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 0.0788 - accuracy: 0.2868 - val_loss: 0.0801 - val_accuracy: 0.2778\n",
      "Epoch 53/150\n",
      "802/802 [==============================] - 0s 39us/step - loss: 0.0787 - accuracy: 0.2880 - val_loss: 0.0802 - val_accuracy: 0.2778\n",
      "Epoch 54/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0787 - accuracy: 0.2818 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 55/150\n",
      "802/802 [==============================] - 0s 30us/step - loss: 0.0787 - accuracy: 0.2930 - val_loss: 0.0799 - val_accuracy: 0.2778\n",
      "Epoch 56/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0787 - accuracy: 0.2968 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 57/150\n",
      "802/802 [==============================] - 0s 30us/step - loss: 0.0787 - accuracy: 0.2880 - val_loss: 0.0799 - val_accuracy: 0.2778\n",
      "Epoch 58/150\n",
      "802/802 [==============================] - 0s 27us/step - loss: 0.0788 - accuracy: 0.2793 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 59/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 0.0785 - accuracy: 0.2855 - val_loss: 0.0804 - val_accuracy: 0.2778\n",
      "Epoch 60/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0786 - accuracy: 0.2943 - val_loss: 0.0806 - val_accuracy: 0.2778\n",
      "Epoch 61/150\n",
      "802/802 [==============================] - 0s 30us/step - loss: 0.0787 - accuracy: 0.2905 - val_loss: 0.0835 - val_accuracy: 0.2778\n",
      "Epoch 62/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0790 - accuracy: 0.2968 - val_loss: 0.0836 - val_accuracy: 0.2778\n",
      "Epoch 63/150\n",
      "802/802 [==============================] - 0s 30us/step - loss: 0.0793 - accuracy: 0.2968 - val_loss: 0.0804 - val_accuracy: 0.2778\n",
      "Epoch 64/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0788 - accuracy: 0.2781 - val_loss: 0.0800 - val_accuracy: 0.2778\n",
      "Epoch 65/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0786 - accuracy: 0.2893 - val_loss: 0.0799 - val_accuracy: 0.2778\n",
      "Epoch 66/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0787 - accuracy: 0.2756 - val_loss: 0.0799 - val_accuracy: 0.2778\n",
      "Epoch 67/150\n",
      "802/802 [==============================] - 0s 44us/step - loss: 0.0786 - accuracy: 0.2968 - val_loss: 0.0804 - val_accuracy: 0.2778\n",
      "Epoch 68/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 0.0786 - accuracy: 0.2918 - val_loss: 0.0803 - val_accuracy: 0.2778\n",
      "Epoch 69/150\n",
      "802/802 [==============================] - 0s 45us/step - loss: 0.0787 - accuracy: 0.2968 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 70/150\n",
      "802/802 [==============================] - 0s 49us/step - loss: 0.0786 - accuracy: 0.2793 - val_loss: 0.0799 - val_accuracy: 0.2778\n",
      "Epoch 71/150\n",
      "802/802 [==============================] - 0s 45us/step - loss: 0.0786 - accuracy: 0.2968 - val_loss: 0.0806 - val_accuracy: 0.1889\n",
      "Epoch 72/150\n",
      "802/802 [==============================] - 0s 44us/step - loss: 0.0791 - accuracy: 0.2307 - val_loss: 0.0799 - val_accuracy: 0.2778\n",
      "Epoch 73/150\n",
      "802/802 [==============================] - 0s 45us/step - loss: 0.0787 - accuracy: 0.2756 - val_loss: 0.0827 - val_accuracy: 0.2778\n",
      "Epoch 74/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0791 - accuracy: 0.2968 - val_loss: 0.0804 - val_accuracy: 0.2778\n",
      "Epoch 75/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 0.0788 - accuracy: 0.2968 - val_loss: 0.0802 - val_accuracy: 0.2778\n",
      "Epoch 76/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0787 - accuracy: 0.2968 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 77/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 0.0786 - accuracy: 0.2793 - val_loss: 0.0800 - val_accuracy: 0.2778\n",
      "Epoch 78/150\n",
      "802/802 [==============================] - 0s 30us/step - loss: 0.0787 - accuracy: 0.2968 - val_loss: 0.0797 - val_accuracy: 0.2778\n",
      "Epoch 79/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0787 - accuracy: 0.2968 - val_loss: 0.0800 - val_accuracy: 0.2778\n",
      "Epoch 80/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0787 - accuracy: 0.2968 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 81/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0787 - accuracy: 0.2880 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 82/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0786 - accuracy: 0.2968 - val_loss: 0.0799 - val_accuracy: 0.2778\n",
      "Epoch 83/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0787 - accuracy: 0.2818 - val_loss: 0.0802 - val_accuracy: 0.2778\n",
      "Epoch 84/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0788 - accuracy: 0.2968 - val_loss: 0.0800 - val_accuracy: 0.2778\n",
      "Epoch 85/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 0.0788 - accuracy: 0.2843 - val_loss: 0.0801 - val_accuracy: 0.2778\n",
      "Epoch 86/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0787 - accuracy: 0.2968 - val_loss: 0.0803 - val_accuracy: 0.1889\n",
      "Epoch 87/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 0.0789 - accuracy: 0.2830 - val_loss: 0.0833 - val_accuracy: 0.2778\n",
      "Epoch 88/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 0.0791 - accuracy: 0.2968 - val_loss: 0.0828 - val_accuracy: 0.2778\n",
      "Epoch 89/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0794 - accuracy: 0.2880 - val_loss: 0.0803 - val_accuracy: 0.2778\n",
      "Epoch 90/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 0.0787 - accuracy: 0.2693 - val_loss: 0.0801 - val_accuracy: 0.2778\n",
      "Epoch 91/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0786 - accuracy: 0.2968 - val_loss: 0.0804 - val_accuracy: 0.2778\n",
      "Epoch 92/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0788 - accuracy: 0.2968 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 93/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0786 - accuracy: 0.2880 - val_loss: 0.0825 - val_accuracy: 0.2778\n",
      "Epoch 94/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0789 - accuracy: 0.2955 - val_loss: 0.0800 - val_accuracy: 0.2778\n",
      "Epoch 95/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0787 - accuracy: 0.2968 - val_loss: 0.0806 - val_accuracy: 0.2778\n",
      "Epoch 96/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 0.0787 - accuracy: 0.2968 - val_loss: 0.0802 - val_accuracy: 0.2778\n",
      "Epoch 97/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 0.0785 - accuracy: 0.2880 - val_loss: 0.0799 - val_accuracy: 0.2778\n",
      "Epoch 98/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 0.0786 - accuracy: 0.2968 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 99/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0787 - accuracy: 0.2968 - val_loss: 0.0799 - val_accuracy: 0.3000\n",
      "Epoch 100/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0786 - accuracy: 0.2531 - val_loss: 0.0804 - val_accuracy: 0.2778\n",
      "Epoch 101/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0786 - accuracy: 0.3030 - val_loss: 0.0805 - val_accuracy: 0.2778\n",
      "Epoch 102/150\n",
      "802/802 [==============================] - 0s 40us/step - loss: 0.0786 - accuracy: 0.2893 - val_loss: 0.0800 - val_accuracy: 0.2778\n",
      "Epoch 103/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 0.0786 - accuracy: 0.2793 - val_loss: 0.0799 - val_accuracy: 0.2778\n",
      "Epoch 104/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0786 - accuracy: 0.2968 - val_loss: 0.0803 - val_accuracy: 0.2778\n",
      "Epoch 105/150\n",
      "802/802 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.31 - 0s 34us/step - loss: 0.0787 - accuracy: 0.2968 - val_loss: 0.0799 - val_accuracy: 0.2778\n",
      "Epoch 106/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 0.0787 - accuracy: 0.2768 - val_loss: 0.0801 - val_accuracy: 0.2778\n",
      "Epoch 107/150\n",
      "802/802 [==============================] - 0s 37us/step - loss: 0.0786 - accuracy: 0.2968 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 108/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 0.0787 - accuracy: 0.2768 - val_loss: 0.0799 - val_accuracy: 0.2778\n",
      "Epoch 109/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 34us/step - loss: 0.0784 - accuracy: 0.2893 - val_loss: 0.0799 - val_accuracy: 0.2778\n",
      "Epoch 110/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0786 - accuracy: 0.2855 - val_loss: 0.0800 - val_accuracy: 0.3000\n",
      "Epoch 111/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0784 - accuracy: 0.2955 - val_loss: 0.0799 - val_accuracy: 0.2778\n",
      "Epoch 112/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0786 - accuracy: 0.2968 - val_loss: 0.0803 - val_accuracy: 0.1889\n",
      "Epoch 113/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0790 - accuracy: 0.2731 - val_loss: 0.0801 - val_accuracy: 0.2778\n",
      "Epoch 114/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0787 - accuracy: 0.2968 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 115/150\n",
      "802/802 [==============================] - 0s 30us/step - loss: 0.0785 - accuracy: 0.2930 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 116/150\n",
      "802/802 [==============================] - 0s 29us/step - loss: 0.0787 - accuracy: 0.2880 - val_loss: 0.0798 - val_accuracy: 0.2889\n",
      "Epoch 117/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0787 - accuracy: 0.2980 - val_loss: 0.0826 - val_accuracy: 0.2778\n",
      "Epoch 118/150\n",
      "802/802 [==============================] - 0s 44us/step - loss: 0.0791 - accuracy: 0.2968 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 119/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 0.0786 - accuracy: 0.2868 - val_loss: 0.0799 - val_accuracy: 0.2778\n",
      "Epoch 120/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0787 - accuracy: 0.2793 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 121/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 0.0787 - accuracy: 0.2743 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 122/150\n",
      "802/802 [==============================] - 0s 30us/step - loss: 0.0785 - accuracy: 0.2868 - val_loss: 0.0800 - val_accuracy: 0.2778\n",
      "Epoch 123/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0787 - accuracy: 0.2868 - val_loss: 0.0833 - val_accuracy: 0.2778\n",
      "Epoch 124/150\n",
      "802/802 [==============================] - 0s 37us/step - loss: 0.0793 - accuracy: 0.2880 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 125/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0785 - accuracy: 0.2968 - val_loss: 0.0797 - val_accuracy: 0.2778\n",
      "Epoch 126/150\n",
      "802/802 [==============================] - 0s 30us/step - loss: 0.0787 - accuracy: 0.2855 - val_loss: 0.0800 - val_accuracy: 0.3000\n",
      "Epoch 127/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0788 - accuracy: 0.2980 - val_loss: 0.0799 - val_accuracy: 0.3222\n",
      "Epoch 128/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0788 - accuracy: 0.2980 - val_loss: 0.0797 - val_accuracy: 0.2778\n",
      "Epoch 129/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0784 - accuracy: 0.2905 - val_loss: 0.0803 - val_accuracy: 0.1889\n",
      "Epoch 130/150\n",
      "802/802 [==============================] - 0s 40us/step - loss: 0.0790 - accuracy: 0.2544 - val_loss: 0.0820 - val_accuracy: 0.2778\n",
      "Epoch 131/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 0.0791 - accuracy: 0.2880 - val_loss: 0.0800 - val_accuracy: 0.2778\n",
      "Epoch 132/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 0.0784 - accuracy: 0.2868 - val_loss: 0.0803 - val_accuracy: 0.1889\n",
      "Epoch 133/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0788 - accuracy: 0.2481 - val_loss: 0.0820 - val_accuracy: 0.2778\n",
      "Epoch 134/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0789 - accuracy: 0.2968 - val_loss: 0.0819 - val_accuracy: 0.2778\n",
      "Epoch 135/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0790 - accuracy: 0.2756 - val_loss: 0.0797 - val_accuracy: 0.2778\n",
      "Epoch 136/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0785 - accuracy: 0.2930 - val_loss: 0.0799 - val_accuracy: 0.2778\n",
      "Epoch 137/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0785 - accuracy: 0.2968 - val_loss: 0.0832 - val_accuracy: 0.2778\n",
      "Epoch 138/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0793 - accuracy: 0.2968 - val_loss: 0.0804 - val_accuracy: 0.2778\n",
      "Epoch 139/150\n",
      "802/802 [==============================] - 0s 30us/step - loss: 0.0786 - accuracy: 0.2968 - val_loss: 0.0796 - val_accuracy: 0.2778\n",
      "Epoch 140/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 0.0785 - accuracy: 0.2880 - val_loss: 0.0800 - val_accuracy: 0.2778\n",
      "Epoch 141/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0785 - accuracy: 0.2618 - val_loss: 0.0822 - val_accuracy: 0.2778\n",
      "Epoch 142/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0789 - accuracy: 0.2855 - val_loss: 0.0825 - val_accuracy: 0.2778\n",
      "Epoch 143/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0791 - accuracy: 0.2880 - val_loss: 0.0799 - val_accuracy: 0.1889\n",
      "Epoch 144/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0787 - accuracy: 0.2668 - val_loss: 0.0799 - val_accuracy: 0.1889\n",
      "Epoch 145/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0788 - accuracy: 0.2706 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 146/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0786 - accuracy: 0.2880 - val_loss: 0.0798 - val_accuracy: 0.2778\n",
      "Epoch 147/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 0.0785 - accuracy: 0.2618 - val_loss: 0.0801 - val_accuracy: 0.2778\n",
      "Epoch 148/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 0.0784 - accuracy: 0.2980 - val_loss: 0.0797 - val_accuracy: 0.2778\n",
      "Epoch 149/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 0.0785 - accuracy: 0.2968 - val_loss: 0.0796 - val_accuracy: 0.2778\n",
      "Epoch 150/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 0.0785 - accuracy: 0.2968 - val_loss: 0.0797 - val_accuracy: 0.2778\n",
      "460/460 [==============================] - 0s 22us/step\n",
      "Loss: 0.08\n",
      "Accuracy 0.29\n",
      "output_layer_weights_lastLayer: \n",
      "[[-0.27606156 -1.4038812  -0.5728978  -1.0594298  -0.485574   -0.32437\n",
      "  -0.81127423  0.16203487 -1.0192299  -0.6636164 ]\n",
      " [-0.6449831  -1.8637195  -0.84349406 -1.1720519  -1.1885544  -1.2601882\n",
      "  -0.14267258 -0.5117398  -0.81530875 -1.1960652 ]\n",
      " [-0.42177975 -0.5832488  -0.8698366  -0.6824993  -1.2796354  -0.33239457\n",
      "  -0.98979026  0.0804784  -1.7024909  -0.6197543 ]]\n",
      "output_layer_weights_secondtolastLayer: \n",
      "[[ 0.06224793  1.2195497   0.60866135]\n",
      " [-0.47400582  0.21686588 -0.7652299 ]\n",
      " [ 0.7465594  -0.94031984  1.0848718 ]]\n",
      "output_layer_biases_lastLayer: \n",
      "[-0.27116582 -1.7541325  -1.9916769  -1.566547   -1.0564239  -0.80012643\n",
      " -0.45275947 -0.502019   -1.5580297  -1.8727641 ]\n",
      "output_layer_biases_secondtolastLayer: \n",
      "[0.23786035 0.43843737 0.024409  ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#import what's needed to build ann\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#encode classes using one hot encoder:\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(dfOnlyClasses)\n",
    "OneHotEncoder(categorical_features=None, categories=None, drop=None, handle_unknown='ignore', n_values=None)\n",
    "y = enc.transform(dfOnlyClasses).toarray()\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "y = np.array(y)\n",
    "#split data into training and testing:\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.34, random_state=42)\n",
    "#print(X_train) #test\n",
    "#build ann model using keras:\n",
    "model = Sequential()\n",
    "model.add(Dense(3, activation='sigmoid', input_dim=8))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "#comile the model:\n",
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=10)\n",
    "model.compile(\n",
    "  optimizer=opt,\n",
    "  loss='mean_squared_error',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "weights_history = []\n",
    "_biases= []\n",
    "# A custom callback to get weights for plotting\n",
    "class MyCallback(keras.callbacks.Callback):\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        weights = model.get_weights()[0]\n",
    "        biases = model.get_weights()[1]\n",
    "        w1,w2,w3,w4,w5,w6,w7,w8 = weights\n",
    "        w01,w02,w03 = biases\n",
    "        biases = [w01]\n",
    "        weights = [w1[0], w2[0], w3[0]]\n",
    "        weights_history.append(weights)\n",
    "        _biases.append(biases)\n",
    "\n",
    "#create checkpoint for plot, to grab val_loss\n",
    "callback = MyCallback()\n",
    "filepath=\"weights-improvement-{epoch:04d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "#fit the model with training set:\n",
    "history = model.fit(\n",
    "  X_train,\n",
    "  y_train,\n",
    "  epochs=150,\n",
    "  batch_size=100, \n",
    "  verbose=1,\n",
    "  validation_split=0.1,\n",
    "  callbacks=[callback]\n",
    ")\n",
    "\n",
    "#test model using training set:\n",
    "loss, accuracy = model.evaluate(\n",
    "  X_test,\n",
    "  y_test\n",
    ")\n",
    "print('Loss: %.2f' % loss)\n",
    "print(\"Accuracy %.2f\" %(accuracy))\n",
    "model.save_weights('model.h5')\n",
    "#get weights and biases from output layer for problem #4:\n",
    "from tensorflow.contrib.keras import layers\n",
    "output_layer_weights_lastLayer = model.layers[2].get_weights()[0]\n",
    "output_layer_weights_secondtolastlayer  = model.layers[1].get_weights()[0]\n",
    "output_layer_biases_lastLayer = model.layers[2].get_weights()[1]\n",
    "output_layer_biases_secondtolastlayer  = model.layers[1].get_weights()[1]\n",
    "print(\"output_layer_weights_lastLayer: \")\n",
    "print(output_layer_weights_lastLayer) #test\n",
    "print(\"output_layer_weights_secondtolastLayer: \")\n",
    "print(output_layer_weights_secondtolastlayer) #test\n",
    "print(\"output_layer_biases_lastLayer: \")\n",
    "print(output_layer_biases_lastLayer) #test\n",
    "print(\"output_layer_biases_secondtolastLayer: \")\n",
    "print(output_layer_biases_secondtolastlayer) #test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#plot the training and testing error:\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('train/test error per iteration')\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "#plot the weights for CYT class:\n",
    "plt.axis([0, 150, -1, 1])\n",
    "plt.plot(weights_history)\n",
    "plt.plot(_biases)\n",
    "plt.title('weights per iteration for CYT class')\n",
    "plt.ylabel('weights')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['w0','w1', 'w2','w3'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hhh\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "2 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "3 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "4 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "5 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "6 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "7 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "8 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "9 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "10 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "11 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "12 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "13 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "14 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "15 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "16 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "17 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "18 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "19 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "20 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "21 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "22 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "23 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "24 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "25 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "26 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "27 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "28 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "29 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "30 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "31 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "32 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "33 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "34 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "35 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "36 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "37 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "38 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "39 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "40 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "41 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "42 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "43 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "44 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "45 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "46 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "47 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "48 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "49 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "50 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "51 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "52 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "53 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "54 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "55 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "56 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "57 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "58 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "59 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "60 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "61 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "62 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "63 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "64 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "65 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "66 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "67 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "68 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "69 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "70 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "71 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "72 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "73 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "74 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "75 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "76 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "77 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "78 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "79 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "80 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "81 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "82 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "83 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "84 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "85 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "86 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "87 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "88 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "89 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "90 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "91 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "92 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "93 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "94 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "95 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "96 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "97 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "98 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "99 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "100 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "101 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "102 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "103 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "104 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "105 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "106 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "107 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "108 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "109 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "110 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "111 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "112 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "113 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "114 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "115 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "116 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "117 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "118 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "119 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "120 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "121 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "122 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "123 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "124 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "125 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "126 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "127 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "128 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "129 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "130 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "131 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "132 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "133 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "134 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "135 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "136 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "137 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "138 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "139 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "140 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "141 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "142 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "143 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "144 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "145 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "146 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "147 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "148 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "149 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "150 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "151 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "152 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "153 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "154 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "155 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "156 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "157 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "158 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "159 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "160 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "161 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "162 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "163 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "164 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "165 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "166 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "167 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "168 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "169 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "170 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "171 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "172 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "173 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "174 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "175 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "176 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "177 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "178 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "179 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "180 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "181 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "182 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "183 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "184 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "185 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "186 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "187 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "188 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "189 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "190 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "191 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "192 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "193 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "194 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "195 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "196 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "197 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "198 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "199 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "200 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "201 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "202 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "203 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "204 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "205 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "206 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "207 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "208 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "209 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "210 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "211 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "212 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "213 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "214 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "215 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "216 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "217 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "218 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "219 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "220 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ERL\n",
      "221 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "222 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "223 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "224 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "225 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "226 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "227 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "228 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "229 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "230 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "231 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "232 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "233 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "234 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "235 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "236 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "237 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "238 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "239 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "240 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "241 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "242 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "243 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "244 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "245 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "246 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "247 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "248 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "249 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "250 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "251 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "252 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "253 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "254 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "255 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "256 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "257 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "258 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "259 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "260 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "261 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "262 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "263 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "264 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "265 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "266 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "267 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "268 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "269 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "270 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "271 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "272 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "273 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "274 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "275 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "276 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "277 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "278 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "279 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "280 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "281 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "282 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "283 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "284 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "285 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "286 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "287 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "288 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "289 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "290 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "291 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "292 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "293 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "294 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "295 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "296 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "297 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "298 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "299 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "300 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "301 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "302 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "303 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "304 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "305 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ERL\n",
      "306 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "307 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "308 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "309 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "310 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "311 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "312 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "313 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "314 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "315 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "316 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "317 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "318 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "319 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "320 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "321 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "322 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "323 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "324 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "325 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "326 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "327 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "328 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "329 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "330 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "331 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "332 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "333 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "334 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "335 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "336 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "337 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "338 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "339 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "340 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "341 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "342 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "343 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "344 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "345 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "346 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "347 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "348 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "349 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "350 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "351 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "352 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "353 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "354 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "355 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "356 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "357 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "358 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "359 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "360 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "361 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "362 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "363 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "364 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "365 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "366 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "367 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "368 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "369 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "370 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "371 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "372 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "373 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "374 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "375 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "376 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "377 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "378 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "379 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "380 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "381 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "382 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "383 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "384 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "385 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "386 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "387 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "388 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "389 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "390 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "391 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "392 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "393 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "394 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "395 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "396 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "397 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "398 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "399 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "400 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "401 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "402 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "403 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "404 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "405 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "406 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "407 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUC\n",
      "408 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "409 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "410 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "411 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "412 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "413 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "414 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "415 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "416 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "417 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "418 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "419 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "420 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "421 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "422 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "423 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "424 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "425 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "426 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "427 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "428 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "429 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "430 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "431 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "432 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "433 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "434 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "435 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "436 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "437 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "438 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "439 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "440 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "441 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "442 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "443 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "444 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "445 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "446 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "447 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "448 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "449 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "450 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "451 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "452 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "453 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "454 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "455 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "456 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "457 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "458 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "459 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "460 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "461 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "462 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "463 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "464 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "465 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "466 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "467 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "468 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "469 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "470 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "471 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "472 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "473 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "474 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "475 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "476 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "477 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "478 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "479 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "480 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "481 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "482 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "483 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "484 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "485 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "486 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "487 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "488 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "489 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ERL\n",
      "490 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "491 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "492 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "493 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "494 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "495 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "496 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "497 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "498 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "499 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "500 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "501 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "502 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "503 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "504 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "505 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "506 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "507 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ERL\n",
      "508 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "509 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "510 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "511 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "512 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "513 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "514 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "515 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "516 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "517 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "518 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "519 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "520 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "521 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "522 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "523 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "524 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "525 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "526 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "527 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "528 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "529 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "530 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "531 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "532 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "533 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "534 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "535 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "536 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "537 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "538 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "539 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "540 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "541 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "542 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "543 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "544 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "545 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "546 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "547 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "548 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "549 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "550 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "551 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "552 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "553 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "554 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "555 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "556 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "557 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "558 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "559 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "560 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "561 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "562 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "563 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "564 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "565 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "566 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "567 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "568 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "569 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "570 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "571 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "572 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "573 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "574 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "575 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "576 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "577 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "578 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "579 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "580 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "581 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "582 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "583 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "584 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "585 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "586 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "587 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "588 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "589 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "590 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "591 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "592 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "593 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "594 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "595 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "596 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "597 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "598 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "599 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "600 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "601 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "602 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "603 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "604 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "605 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "606 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "607 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "608 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "609 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "610 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "611 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "612 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "613 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "614 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "615 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "616 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "617 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "618 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "619 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "620 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "621 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "622 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "623 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "624 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "625 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "626 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "627 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "628 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "629 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "630 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "631 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "632 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "633 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "634 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "635 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "636 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "637 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "638 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "639 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "640 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "641 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "642 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "643 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "644 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "645 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "646 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "647 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "648 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "649 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "650 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "651 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "652 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "653 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "654 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "655 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "656 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "657 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "658 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "659 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "660 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "661 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "662 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "663 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "664 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "665 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "666 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "667 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "668 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "669 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "670 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "671 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "672 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "673 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "674 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "675 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "676 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "677 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "678 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "679 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "680 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "681 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "682 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "683 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "684 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "685 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "686 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "687 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "688 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "689 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "690 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "691 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "692 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "693 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "694 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "695 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "696 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "697 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "698 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "699 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "700 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "701 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "702 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "703 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "704 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "705 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "706 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "707 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "708 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "709 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "710 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "711 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "712 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "713 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "714 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "715 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "716 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "717 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "718 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "719 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "720 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "721 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "722 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "723 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "724 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "725 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "726 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "727 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "728 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "729 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "730 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "731 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "732 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "733 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "734 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "735 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "736 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "737 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "738 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "739 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "740 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "ERL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "741 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "742 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "743 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "744 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "745 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "746 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "747 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "748 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "749 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "750 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "751 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "752 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "753 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "754 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "755 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "756 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "757 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "758 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "759 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "760 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "761 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "762 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "763 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "764 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "765 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "766 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "767 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "768 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "769 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "770 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "771 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "772 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "773 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "774 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "775 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "776 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "777 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "778 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "779 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "780 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "781 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "782 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "783 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "784 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "785 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "786 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "787 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "788 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "789 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "790 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "791 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "792 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "793 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "794 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "795 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "796 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "797 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "798 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "799 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "800 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "801 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "802 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "803 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "804 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "805 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "806 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "807 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "808 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "809 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "810 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "811 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "812 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "813 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "814 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "815 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "816 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "817 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "818 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "819 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "820 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "821 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "822 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "823 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "824 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "825 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "826 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "827 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "828 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "829 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "830 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "831 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "832 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "833 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "834 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "835 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "836 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "837 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "838 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "839 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "840 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "841 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "842 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "843 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "844 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "845 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "846 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "847 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "848 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "849 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "850 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "851 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "852 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "853 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "854 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "855 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "856 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "857 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "858 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "859 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "860 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "861 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "862 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "863 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "864 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "865 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "866 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "867 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "868 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "869 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "870 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "871 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "872 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "873 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "874 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "875 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "876 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "877 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "878 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "879 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "880 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "881 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "882 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "883 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "884 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "885 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "886 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "887 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "888 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "889 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "890 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "891 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "892 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "893 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "894 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "895 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "896 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "897 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "898 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "899 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "900 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "901 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "902 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "903 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "904 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "905 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "906 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "907 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "908 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "909 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "910 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "911 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "912 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "913 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "914 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "915 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "916 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "917 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "918 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "919 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "920 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "921 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "922 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "923 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "924 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "925 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "926 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "927 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "928 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "929 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "930 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "931 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "932 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "933 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "934 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "935 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "936 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "937 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "938 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "939 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "940 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "941 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "942 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "943 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "944 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "945 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "946 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "947 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "948 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "949 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "950 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "951 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "952 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "953 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "954 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "955 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "956 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "957 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "958 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "959 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "960 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "961 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "962 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "963 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "964 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "965 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "966 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "967 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "968 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "969 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "970 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "971 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "972 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "973 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "974 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "975 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "976 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "977 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "978 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "979 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "980 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "981 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "982 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "983 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "984 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "985 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "986 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "987 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "988 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "989 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "990 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "991 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "992 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "993 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "994 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "995 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "996 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "997 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "998 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "999 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1000 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1001 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1002 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1003 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1004 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1005 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1006 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1007 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1008 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1009 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1010 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1011 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1012 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1013 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1014 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1015 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1016 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1017 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1018 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1019 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1020 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1021 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1022 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1023 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1024 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1025 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1026 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1027 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1028 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1029 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1030 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1031 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1032 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1033 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1034 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1035 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1036 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1037 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1038 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1039 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1040 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1041 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1042 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1043 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1044 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1045 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1046 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1047 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1048 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1049 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1050 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1051 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1052 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "1053 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1054 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1055 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1056 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1057 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1058 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1059 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "1060 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1061 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "1062 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1063 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1064 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1065 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1066 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1067 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1068 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1069 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1070 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1071 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "1072 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "1073 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1074 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1075 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1076 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1077 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1078 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1079 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1080 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1081 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1082 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1083 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1084 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1085 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "1086 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1087 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1088 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1089 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1090 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "1091 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1092 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1093 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1094 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1095 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1096 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1097 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1098 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1099 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1100 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1101 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1102 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1103 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1104 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1105 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1106 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1107 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1108 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "1109 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1110 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1111 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1112 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1113 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1114 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1115 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1116 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1117 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1118 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1119 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1120 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1121 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1122 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1123 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1124 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1125 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1126 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1127 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1128 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1129 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1130 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1131 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1132 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1133 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1134 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1135 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1136 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1137 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1138 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1139 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1140 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1141 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1142 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1143 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "1144 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "1145 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1146 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "1147 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1148 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1149 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1150 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1151 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1152 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1153 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1154 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1155 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1156 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1157 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1158 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1159 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1160 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1161 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1162 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1163 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1164 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1165 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1166 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1167 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1168 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1169 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1170 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1171 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1172 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1173 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1174 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1175 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1176 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1177 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1178 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1179 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1180 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1181 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1182 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1183 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1184 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1185 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1186 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "1187 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1188 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1189 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "1190 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1191 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1192 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1193 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1194 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1195 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1196 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1197 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1198 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1199 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1200 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1201 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1202 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1203 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1204 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1205 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1206 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "1207 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1208 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "1209 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "1210 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "1211 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1212 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1213 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1214 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1215 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1216 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1217 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1218 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1219 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1220 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1221 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1222 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1223 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1224 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1225 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1226 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1227 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1228 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1229 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1230 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1231 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1232 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1233 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1234 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1235 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1236 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1237 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1238 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1239 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1240 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1241 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1242 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1243 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1244 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1245 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1246 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1247 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1248 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1249 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1250 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1251 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1252 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1253 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1254 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1255 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1256 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1257 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1258 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1259 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1260 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1261 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1262 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1263 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1264 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1265 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1266 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1267 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1268 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1269 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1270 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1271 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1272 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1273 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1274 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1275 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1276 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1277 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1278 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "1279 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1280 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1281 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1282 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1283 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1284 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1285 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1286 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1287 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1288 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1289 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1290 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1291 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1292 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1293 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1294 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1295 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1296 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1297 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1298 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1299 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1300 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "1301 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1302 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1303 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1304 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1305 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1306 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1307 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1308 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1309 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1310 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1311 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1312 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1313 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1314 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1315 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1316 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1317 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1318 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1319 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1320 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1321 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1322 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1323 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1324 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1325 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1326 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1327 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1328 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1329 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1330 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1331 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1332 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "1333 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1334 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1335 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "1336 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "1337 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "1338 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "1339 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "1340 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "1341 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "1342 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "1343 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "1344 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "1345 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "1346 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1347 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1348 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1349 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1350 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1351 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1352 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "VAC\n",
      "1353 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1354 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1355 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1356 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1357 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1358 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1359 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1360 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1361 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1362 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1363 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1364 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1365 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "1366 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1367 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1368 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1369 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1370 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1371 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1372 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1373 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1374 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1375 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1376 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1377 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1378 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1379 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1380 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1381 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1382 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1383 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1384 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1385 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1386 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1387 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1388 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1389 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "1390 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "1391 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1392 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1393 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1394 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1395 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1396 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "1397 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1398 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1399 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1400 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1401 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1402 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1403 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1404 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "1405 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1406 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1408 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1409 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1410 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1411 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "1412 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1413 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1414 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1415 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1416 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1417 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1418 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1419 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1420 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1421 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EXC\n",
      "1422 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1423 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1424 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1425 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1426 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1427 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1428 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1429 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1430 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1431 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1432 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1433 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1434 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1435 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "1436 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1437 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1438 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1439 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1440 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "1441 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1442 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1443 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "1444 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1445 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1446 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1447 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1448 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1449 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1450 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1451 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1452 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1453 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1454 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1455 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1456 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1457 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "ME1\n",
      "1458 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1459 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1460 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1461 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1462 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "POX\n",
      "1463 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1464 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1465 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1466 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1467 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "ME3\n",
      "1468 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1469 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1470 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1471 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1472 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "MIT\n",
      "1473 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1474 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1475 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1476 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1477 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1478 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1479 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "1480 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "1481 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1482 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "ME2\n",
      "1483 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "NUC\n",
      "1484 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "CYT\n",
      "Train on 1335 samples, validate on 149 samples\n",
      "Epoch 1/150\n",
      "1335/1335 [==============================] - 0s 32us/step - loss: 0.0764 - accuracy: 0.3109 - val_loss: 0.0910 - val_accuracy: 0.1678\n",
      "Epoch 2/150\n",
      "1335/1335 [==============================] - 0s 32us/step - loss: 0.0762 - accuracy: 0.3184 - val_loss: 0.0921 - val_accuracy: 0.1678\n",
      "Epoch 3/150\n",
      "1335/1335 [==============================] - 0s 27us/step - loss: 0.0762 - accuracy: 0.3281 - val_loss: 0.0915 - val_accuracy: 0.1678\n",
      "Epoch 4/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0761 - accuracy: 0.3281 - val_loss: 0.0923 - val_accuracy: 0.1678\n",
      "Epoch 5/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0762 - accuracy: 0.3288 - val_loss: 0.0919 - val_accuracy: 0.1678\n",
      "Epoch 6/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0761 - accuracy: 0.3236 - val_loss: 0.0907 - val_accuracy: 0.1879\n",
      "Epoch 7/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0762 - accuracy: 0.3154 - val_loss: 0.0915 - val_accuracy: 0.1678\n",
      "Epoch 8/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0761 - accuracy: 0.3296 - val_loss: 0.0915 - val_accuracy: 0.1678\n",
      "Epoch 9/150\n",
      "1335/1335 [==============================] - 0s 19us/step - loss: 0.0761 - accuracy: 0.3199 - val_loss: 0.0915 - val_accuracy: 0.1678\n",
      "Epoch 10/150\n",
      "1335/1335 [==============================] - 0s 19us/step - loss: 0.0761 - accuracy: 0.3228 - val_loss: 0.0916 - val_accuracy: 0.1678\n",
      "Epoch 11/150\n",
      "1335/1335 [==============================] - 0s 20us/step - loss: 0.0762 - accuracy: 0.3243 - val_loss: 0.0919 - val_accuracy: 0.1678\n",
      "Epoch 12/150\n",
      "1335/1335 [==============================] - 0s 25us/step - loss: 0.0761 - accuracy: 0.3236 - val_loss: 0.0913 - val_accuracy: 0.2013\n",
      "Epoch 13/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0761 - accuracy: 0.3213 - val_loss: 0.0919 - val_accuracy: 0.1879\n",
      "Epoch 14/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0761 - accuracy: 0.3154 - val_loss: 0.0916 - val_accuracy: 0.1678\n",
      "Epoch 15/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0761 - accuracy: 0.3176 - val_loss: 0.0916 - val_accuracy: 0.1678\n",
      "Epoch 16/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0760 - accuracy: 0.3281 - val_loss: 0.0915 - val_accuracy: 0.1678\n",
      "Epoch 17/150\n",
      "1335/1335 [==============================] - 0s 19us/step - loss: 0.0760 - accuracy: 0.3101 - val_loss: 0.0915 - val_accuracy: 0.1678\n",
      "Epoch 18/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0760 - accuracy: 0.3258 - val_loss: 0.0912 - val_accuracy: 0.1879\n",
      "Epoch 19/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0760 - accuracy: 0.3011 - val_loss: 0.0922 - val_accuracy: 0.1678\n",
      "Epoch 20/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0760 - accuracy: 0.3146 - val_loss: 0.0910 - val_accuracy: 0.1678\n",
      "Epoch 21/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0760 - accuracy: 0.3236 - val_loss: 0.0919 - val_accuracy: 0.1678\n",
      "Epoch 22/150\n",
      "1335/1335 [==============================] - 0s 15us/step - loss: 0.0760 - accuracy: 0.3273 - val_loss: 0.0920 - val_accuracy: 0.1678\n",
      "Epoch 23/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0759 - accuracy: 0.3273 - val_loss: 0.0923 - val_accuracy: 0.1678\n",
      "Epoch 24/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0759 - accuracy: 0.3281 - val_loss: 0.0910 - val_accuracy: 0.1879\n",
      "Epoch 25/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0759 - accuracy: 0.3191 - val_loss: 0.0918 - val_accuracy: 0.1678\n",
      "Epoch 26/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0759 - accuracy: 0.3281 - val_loss: 0.0915 - val_accuracy: 0.1879\n",
      "Epoch 27/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0759 - accuracy: 0.3169 - val_loss: 0.0917 - val_accuracy: 0.1879\n",
      "Epoch 28/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0759 - accuracy: 0.3131 - val_loss: 0.0923 - val_accuracy: 0.1678\n",
      "Epoch 29/150\n",
      "1335/1335 [==============================] - 0s 19us/step - loss: 0.0758 - accuracy: 0.3281 - val_loss: 0.0908 - val_accuracy: 0.1678\n",
      "Epoch 30/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0758 - accuracy: 0.3071 - val_loss: 0.0911 - val_accuracy: 0.1678\n",
      "Epoch 31/150\n",
      "1335/1335 [==============================] - 0s 19us/step - loss: 0.0758 - accuracy: 0.3281 - val_loss: 0.0911 - val_accuracy: 0.1678\n",
      "Epoch 32/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0758 - accuracy: 0.3176 - val_loss: 0.0906 - val_accuracy: 0.1678\n",
      "Epoch 33/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0757 - accuracy: 0.3326 - val_loss: 0.0911 - val_accuracy: 0.1879\n",
      "Epoch 34/150\n",
      "1335/1335 [==============================] - 0s 24us/step - loss: 0.0757 - accuracy: 0.3221 - val_loss: 0.0916 - val_accuracy: 0.1678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/150\n",
      "1335/1335 [==============================] - 0s 30us/step - loss: 0.0756 - accuracy: 0.3281 - val_loss: 0.0909 - val_accuracy: 0.1879\n",
      "Epoch 36/150\n",
      "1335/1335 [==============================] - 0s 22us/step - loss: 0.0756 - accuracy: 0.3243 - val_loss: 0.0911 - val_accuracy: 0.1678\n",
      "Epoch 37/150\n",
      "1335/1335 [==============================] - 0s 22us/step - loss: 0.0755 - accuracy: 0.3184 - val_loss: 0.0915 - val_accuracy: 0.1678\n",
      "Epoch 38/150\n",
      "1335/1335 [==============================] - 0s 19us/step - loss: 0.0755 - accuracy: 0.3184 - val_loss: 0.0913 - val_accuracy: 0.1678\n",
      "Epoch 39/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0755 - accuracy: 0.3154 - val_loss: 0.0920 - val_accuracy: 0.1678\n",
      "Epoch 40/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0754 - accuracy: 0.3251 - val_loss: 0.0915 - val_accuracy: 0.1678\n",
      "Epoch 41/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0753 - accuracy: 0.3341 - val_loss: 0.0914 - val_accuracy: 0.1678\n",
      "Epoch 42/150\n",
      "1335/1335 [==============================] - 0s 19us/step - loss: 0.0753 - accuracy: 0.3221 - val_loss: 0.0903 - val_accuracy: 0.1678\n",
      "Epoch 43/150\n",
      "1335/1335 [==============================] - 0s 22us/step - loss: 0.0751 - accuracy: 0.3206 - val_loss: 0.0920 - val_accuracy: 0.1678\n",
      "Epoch 44/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0751 - accuracy: 0.3243 - val_loss: 0.0902 - val_accuracy: 0.1678\n",
      "Epoch 45/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0750 - accuracy: 0.3288 - val_loss: 0.0915 - val_accuracy: 0.1678\n",
      "Epoch 46/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0749 - accuracy: 0.3228 - val_loss: 0.0909 - val_accuracy: 0.1678\n",
      "Epoch 47/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0748 - accuracy: 0.3243 - val_loss: 0.0919 - val_accuracy: 0.1678\n",
      "Epoch 48/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0747 - accuracy: 0.3318 - val_loss: 0.0915 - val_accuracy: 0.1812\n",
      "Epoch 49/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0746 - accuracy: 0.3161 - val_loss: 0.0918 - val_accuracy: 0.1678\n",
      "Epoch 50/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0745 - accuracy: 0.3311 - val_loss: 0.0911 - val_accuracy: 0.2013\n",
      "Epoch 51/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0743 - accuracy: 0.3258 - val_loss: 0.0912 - val_accuracy: 0.1678\n",
      "Epoch 52/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0742 - accuracy: 0.3341 - val_loss: 0.0904 - val_accuracy: 0.1812\n",
      "Epoch 53/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0740 - accuracy: 0.3386 - val_loss: 0.0909 - val_accuracy: 0.2013\n",
      "Epoch 54/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0738 - accuracy: 0.3423 - val_loss: 0.0915 - val_accuracy: 0.1812\n",
      "Epoch 55/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0738 - accuracy: 0.3431 - val_loss: 0.0907 - val_accuracy: 0.2282\n",
      "Epoch 56/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0735 - accuracy: 0.3566 - val_loss: 0.0908 - val_accuracy: 0.2282\n",
      "Epoch 57/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0734 - accuracy: 0.3543 - val_loss: 0.0908 - val_accuracy: 0.1745\n",
      "Epoch 58/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0731 - accuracy: 0.3655 - val_loss: 0.0906 - val_accuracy: 0.1745\n",
      "Epoch 59/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0729 - accuracy: 0.3715 - val_loss: 0.0901 - val_accuracy: 0.2349\n",
      "Epoch 60/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0727 - accuracy: 0.3835 - val_loss: 0.0905 - val_accuracy: 0.1812\n",
      "Epoch 61/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0725 - accuracy: 0.3895 - val_loss: 0.0908 - val_accuracy: 0.2081\n",
      "Epoch 62/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0724 - accuracy: 0.3873 - val_loss: 0.0902 - val_accuracy: 0.2550\n",
      "Epoch 63/150\n",
      "1335/1335 [==============================] - 0s 20us/step - loss: 0.0722 - accuracy: 0.3880 - val_loss: 0.0902 - val_accuracy: 0.1879\n",
      "Epoch 64/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0720 - accuracy: 0.3978 - val_loss: 0.0904 - val_accuracy: 0.2349\n",
      "Epoch 65/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0718 - accuracy: 0.4120 - val_loss: 0.0899 - val_accuracy: 0.2550\n",
      "Epoch 66/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0716 - accuracy: 0.4105 - val_loss: 0.0905 - val_accuracy: 0.2013\n",
      "Epoch 67/150\n",
      "1335/1335 [==============================] - 0s 19us/step - loss: 0.0714 - accuracy: 0.4060 - val_loss: 0.0913 - val_accuracy: 0.2416\n",
      "Epoch 68/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0712 - accuracy: 0.4277 - val_loss: 0.0899 - val_accuracy: 0.2081\n",
      "Epoch 69/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0710 - accuracy: 0.4247 - val_loss: 0.0908 - val_accuracy: 0.2349\n",
      "Epoch 70/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0709 - accuracy: 0.4240 - val_loss: 0.0899 - val_accuracy: 0.2550\n",
      "Epoch 71/150\n",
      "1335/1335 [==============================] - 0s 19us/step - loss: 0.0708 - accuracy: 0.4277 - val_loss: 0.0900 - val_accuracy: 0.2349\n",
      "Epoch 72/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0706 - accuracy: 0.4157 - val_loss: 0.0898 - val_accuracy: 0.2550\n",
      "Epoch 73/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0706 - accuracy: 0.4337 - val_loss: 0.0899 - val_accuracy: 0.2148\n",
      "Epoch 74/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0704 - accuracy: 0.4120 - val_loss: 0.0901 - val_accuracy: 0.2148\n",
      "Epoch 75/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0703 - accuracy: 0.4315 - val_loss: 0.0896 - val_accuracy: 0.2483\n",
      "Epoch 76/150\n",
      "1335/1335 [==============================] - 0s 19us/step - loss: 0.0703 - accuracy: 0.4157 - val_loss: 0.0894 - val_accuracy: 0.2349\n",
      "Epoch 77/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0702 - accuracy: 0.4322 - val_loss: 0.0909 - val_accuracy: 0.2282\n",
      "Epoch 78/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0701 - accuracy: 0.4150 - val_loss: 0.0929 - val_accuracy: 0.2483\n",
      "Epoch 79/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0702 - accuracy: 0.4202 - val_loss: 0.0897 - val_accuracy: 0.2081\n",
      "Epoch 80/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0699 - accuracy: 0.4225 - val_loss: 0.0901 - val_accuracy: 0.2148\n",
      "Epoch 81/150\n",
      "1335/1335 [==============================] - 0s 19us/step - loss: 0.0700 - accuracy: 0.4157 - val_loss: 0.0896 - val_accuracy: 0.2617\n",
      "Epoch 82/150\n",
      "1335/1335 [==============================] - 0s 20us/step - loss: 0.0698 - accuracy: 0.4187 - val_loss: 0.0897 - val_accuracy: 0.2416\n",
      "Epoch 83/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0699 - accuracy: 0.4240 - val_loss: 0.0892 - val_accuracy: 0.2349\n",
      "Epoch 84/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0699 - accuracy: 0.4165 - val_loss: 0.0898 - val_accuracy: 0.2483\n",
      "Epoch 85/150\n",
      "1335/1335 [==============================] - 0s 19us/step - loss: 0.0697 - accuracy: 0.4247 - val_loss: 0.0893 - val_accuracy: 0.2416\n",
      "Epoch 86/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0697 - accuracy: 0.4187 - val_loss: 0.0898 - val_accuracy: 0.2550\n",
      "Epoch 87/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0696 - accuracy: 0.4457 - val_loss: 0.0901 - val_accuracy: 0.2416\n",
      "Epoch 88/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0696 - accuracy: 0.4225 - val_loss: 0.0895 - val_accuracy: 0.2416\n",
      "Epoch 89/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0695 - accuracy: 0.4172 - val_loss: 0.0903 - val_accuracy: 0.2416\n",
      "Epoch 90/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0696 - accuracy: 0.4345 - val_loss: 0.0939 - val_accuracy: 0.2282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0696 - accuracy: 0.4202 - val_loss: 0.0896 - val_accuracy: 0.2416\n",
      "Epoch 92/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0695 - accuracy: 0.4412 - val_loss: 0.0891 - val_accuracy: 0.2215\n",
      "Epoch 93/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0694 - accuracy: 0.4292 - val_loss: 0.0916 - val_accuracy: 0.2148\n",
      "Epoch 94/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0695 - accuracy: 0.4187 - val_loss: 0.0928 - val_accuracy: 0.2550\n",
      "Epoch 95/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0694 - accuracy: 0.4255 - val_loss: 0.0899 - val_accuracy: 0.2215\n",
      "Epoch 96/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0693 - accuracy: 0.4337 - val_loss: 0.0890 - val_accuracy: 0.2282\n",
      "Epoch 97/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0693 - accuracy: 0.4270 - val_loss: 0.0907 - val_accuracy: 0.2483\n",
      "Epoch 98/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0693 - accuracy: 0.4457 - val_loss: 0.0895 - val_accuracy: 0.2282\n",
      "Epoch 99/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0694 - accuracy: 0.4232 - val_loss: 0.0905 - val_accuracy: 0.2215\n",
      "Epoch 100/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0693 - accuracy: 0.4255 - val_loss: 0.0889 - val_accuracy: 0.2416\n",
      "Epoch 101/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0692 - accuracy: 0.4225 - val_loss: 0.0895 - val_accuracy: 0.2013\n",
      "Epoch 102/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0691 - accuracy: 0.4457 - val_loss: 0.0897 - val_accuracy: 0.2617\n",
      "Epoch 103/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0693 - accuracy: 0.4210 - val_loss: 0.0902 - val_accuracy: 0.2685\n",
      "Epoch 104/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0693 - accuracy: 0.4255 - val_loss: 0.0899 - val_accuracy: 0.2685\n",
      "Epoch 105/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0692 - accuracy: 0.4247 - val_loss: 0.0896 - val_accuracy: 0.2349\n",
      "Epoch 106/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0690 - accuracy: 0.4262 - val_loss: 0.0894 - val_accuracy: 0.2752\n",
      "Epoch 107/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0691 - accuracy: 0.4375 - val_loss: 0.0891 - val_accuracy: 0.2349\n",
      "Epoch 108/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0692 - accuracy: 0.4045 - val_loss: 0.0902 - val_accuracy: 0.2282\n",
      "Epoch 109/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0692 - accuracy: 0.4375 - val_loss: 0.0894 - val_accuracy: 0.2148\n",
      "Epoch 110/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0692 - accuracy: 0.4225 - val_loss: 0.0893 - val_accuracy: 0.2081\n",
      "Epoch 111/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0691 - accuracy: 0.4330 - val_loss: 0.0911 - val_accuracy: 0.2282\n",
      "Epoch 112/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0691 - accuracy: 0.4397 - val_loss: 0.0901 - val_accuracy: 0.2550\n",
      "Epoch 113/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0690 - accuracy: 0.4240 - val_loss: 0.0892 - val_accuracy: 0.2349\n",
      "Epoch 114/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0691 - accuracy: 0.4300 - val_loss: 0.0891 - val_accuracy: 0.2483\n",
      "Epoch 115/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0691 - accuracy: 0.4315 - val_loss: 0.0910 - val_accuracy: 0.2685\n",
      "Epoch 116/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0689 - accuracy: 0.4404 - val_loss: 0.0898 - val_accuracy: 0.2752\n",
      "Epoch 117/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0690 - accuracy: 0.4419 - val_loss: 0.0894 - val_accuracy: 0.2550\n",
      "Epoch 118/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0691 - accuracy: 0.4300 - val_loss: 0.0902 - val_accuracy: 0.2215\n",
      "Epoch 119/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0690 - accuracy: 0.4427 - val_loss: 0.0889 - val_accuracy: 0.2483\n",
      "Epoch 120/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0689 - accuracy: 0.4375 - val_loss: 0.0889 - val_accuracy: 0.2752\n",
      "Epoch 121/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0690 - accuracy: 0.4390 - val_loss: 0.0901 - val_accuracy: 0.2685\n",
      "Epoch 122/150\n",
      "1335/1335 [==============================] - 0s 24us/step - loss: 0.0689 - accuracy: 0.4330 - val_loss: 0.0892 - val_accuracy: 0.2685\n",
      "Epoch 123/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0691 - accuracy: 0.4277 - val_loss: 0.0895 - val_accuracy: 0.2282\n",
      "Epoch 124/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0688 - accuracy: 0.4502 - val_loss: 0.0902 - val_accuracy: 0.2215\n",
      "Epoch 125/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0690 - accuracy: 0.4112 - val_loss: 0.0887 - val_accuracy: 0.2685\n",
      "Epoch 126/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0690 - accuracy: 0.4382 - val_loss: 0.0894 - val_accuracy: 0.2215\n",
      "Epoch 127/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0689 - accuracy: 0.4285 - val_loss: 0.0897 - val_accuracy: 0.2282\n",
      "Epoch 128/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0690 - accuracy: 0.4262 - val_loss: 0.0908 - val_accuracy: 0.2282\n",
      "Epoch 129/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0688 - accuracy: 0.4375 - val_loss: 0.0898 - val_accuracy: 0.2752\n",
      "Epoch 130/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0688 - accuracy: 0.4404 - val_loss: 0.0897 - val_accuracy: 0.2416\n",
      "Epoch 131/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0689 - accuracy: 0.4292 - val_loss: 0.0891 - val_accuracy: 0.2416\n",
      "Epoch 132/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0688 - accuracy: 0.4277 - val_loss: 0.0888 - val_accuracy: 0.2752\n",
      "Epoch 133/150\n",
      "1335/1335 [==============================] - 0s 19us/step - loss: 0.0688 - accuracy: 0.4442 - val_loss: 0.0892 - val_accuracy: 0.2282\n",
      "Epoch 134/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0689 - accuracy: 0.4345 - val_loss: 0.0902 - val_accuracy: 0.2416\n",
      "Epoch 135/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0689 - accuracy: 0.4397 - val_loss: 0.0901 - val_accuracy: 0.2483\n",
      "Epoch 136/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0689 - accuracy: 0.4202 - val_loss: 0.0892 - val_accuracy: 0.2215\n",
      "Epoch 137/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0687 - accuracy: 0.4412 - val_loss: 0.0909 - val_accuracy: 0.2282\n",
      "Epoch 138/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0688 - accuracy: 0.4375 - val_loss: 0.0891 - val_accuracy: 0.2282\n",
      "Epoch 139/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0688 - accuracy: 0.4232 - val_loss: 0.0891 - val_accuracy: 0.2215\n",
      "Epoch 140/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0688 - accuracy: 0.4322 - val_loss: 0.0888 - val_accuracy: 0.2685\n",
      "Epoch 141/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0687 - accuracy: 0.4449 - val_loss: 0.0885 - val_accuracy: 0.2483\n",
      "Epoch 142/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0688 - accuracy: 0.4337 - val_loss: 0.0885 - val_accuracy: 0.2416\n",
      "Epoch 143/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0687 - accuracy: 0.4397 - val_loss: 0.0889 - val_accuracy: 0.2416\n",
      "Epoch 144/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0688 - accuracy: 0.4442 - val_loss: 0.0889 - val_accuracy: 0.2483\n",
      "Epoch 145/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0686 - accuracy: 0.4464 - val_loss: 0.0880 - val_accuracy: 0.2349\n",
      "Epoch 146/150\n",
      "1335/1335 [==============================] - 0s 17us/step - loss: 0.0686 - accuracy: 0.4345 - val_loss: 0.0903 - val_accuracy: 0.2752\n",
      "Epoch 147/150\n",
      "1335/1335 [==============================] - 0s 18us/step - loss: 0.0686 - accuracy: 0.4517 - val_loss: 0.0884 - val_accuracy: 0.2349\n",
      "Epoch 148/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0686 - accuracy: 0.4360 - val_loss: 0.0889 - val_accuracy: 0.2752\n",
      "Epoch 149/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0686 - accuracy: 0.4547 - val_loss: 0.0901 - val_accuracy: 0.2282\n",
      "Epoch 150/150\n",
      "1335/1335 [==============================] - 0s 16us/step - loss: 0.0686 - accuracy: 0.4322 - val_loss: 0.0885 - val_accuracy: 0.2215\n",
      "1484/1484 [==============================] - 0s 16us/step\n",
      "acc: \n",
      "0.40835580229759216\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#create df including all data as stated in directions\n",
    "dataFrameWithAllData = pd.read_csv(\"yeast.data\", delim_whitespace=1, names=[\"mcg\",\"gvh\",\"alm\",\"mit\",\"erl\",\"pox\",\"vac\",\"nuc\",\"class\"])\n",
    "dfe = dataFrameWithAllData.drop(columns=\"class\")\n",
    "#grab classes for model:\n",
    "cdfe = dataFrameWithAllData.drop(columns=[\"mcg\",\"gvh\",\"alm\",\"mit\",\"erl\",\"pox\",\"vac\",\"nuc\"])\n",
    "\n",
    "#use new one hot encoder for new y column vector\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#label encode for decoding later:\n",
    "l = LabelEncoder()\n",
    "e = l.fit_transform(cdfe)\n",
    "#use one hot encoder to encode classes, this time without removing data as instructed\n",
    "\n",
    "newenc = OneHotEncoder()\n",
    "newenc.fit(cdfe)\n",
    "OneHotEncoder(categorical_features=None, categories=None, drop=None, handle_unknown='ignore', n_values=None)\n",
    "y = enc.transform(cdfe).toarray()\n",
    "#turn into numpy array\n",
    "y = np.array(y)\n",
    "#create counter \n",
    "it=1\n",
    "#create empty list to append argmax's to, basically what index 1 lands on from ohe\n",
    "f = []\n",
    "#decodes on hot encoder: \n",
    "#create a list of indexes to decode\n",
    "for i in y:\n",
    "    f.append(np.argmax(i))\n",
    "#reset counter:\n",
    "it = 1\n",
    "#decode and print, this will show you my encoded classes\n",
    "#what row you are on, and the decoded class\n",
    "for j in l.inverse_transform(f):\n",
    "    print(it, end =\" \")\n",
    "    print(y[it-1])\n",
    "    print(j)\n",
    "    it = it + 1\n",
    "#Train model with all data\n",
    "#it will show less in model because I am using 0.1 for validation\n",
    "history = model.fit(\n",
    "  dfe,\n",
    "  y,\n",
    "  epochs=150,\n",
    "  batch_size=100, \n",
    "  verbose=1,\n",
    "  validation_split=0.1\n",
    ")\n",
    "#now get training error, to do this I run model with training data, in this case it is all the data\n",
    "loss, accuracy = model.evaluate(dfe,y)\n",
    "print(\"acc: \")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "892/892 [==============================] - 0s 158us/step - loss: 0.1583 - accuracy: 0.2814\n",
      "Epoch 2/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0950 - accuracy: 0.2848\n",
      "Epoch 3/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0858 - accuracy: 0.2904\n",
      "Epoch 4/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0828 - accuracy: 0.2948\n",
      "Epoch 5/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0814 - accuracy: 0.2948\n",
      "Epoch 6/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0805 - accuracy: 0.2948\n",
      "Epoch 7/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0801 - accuracy: 0.2803\n",
      "Epoch 8/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0798 - accuracy: 0.2803\n",
      "Epoch 9/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0795 - accuracy: 0.2848\n",
      "Epoch 10/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0794 - accuracy: 0.2948\n",
      "Epoch 11/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0792 - accuracy: 0.2881\n",
      "Epoch 12/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0791 - accuracy: 0.2926\n",
      "Epoch 13/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0791 - accuracy: 0.2948\n",
      "Epoch 14/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0790 - accuracy: 0.2892\n",
      "Epoch 15/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0789 - accuracy: 0.2926\n",
      "Epoch 16/150\n",
      "892/892 [==============================] - 0s 34us/step - loss: 0.0789 - accuracy: 0.2724\n",
      "Epoch 17/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0788 - accuracy: 0.2836\n",
      "Epoch 18/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0788 - accuracy: 0.2948\n",
      "Epoch 19/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0788 - accuracy: 0.2657\n",
      "Epoch 20/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0787 - accuracy: 0.2870\n",
      "Epoch 21/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0787 - accuracy: 0.2948\n",
      "Epoch 22/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0787 - accuracy: 0.2735\n",
      "Epoch 23/150\n",
      "892/892 [==============================] - 0s 33us/step - loss: 0.0787 - accuracy: 0.2735\n",
      "Epoch 24/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0787 - accuracy: 0.2948\n",
      "Epoch 25/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0787 - accuracy: 0.2713\n",
      "Epoch 26/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0787 - accuracy: 0.2948\n",
      "Epoch 27/150\n",
      "892/892 [==============================] - 0s 33us/step - loss: 0.0787 - accuracy: 0.2960\n",
      "Epoch 28/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 29/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0786 - accuracy: 0.2702\n",
      "Epoch 30/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 31/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0787 - accuracy: 0.2747\n",
      "Epoch 32/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 33/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2612\n",
      "Epoch 34/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 35/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2960\n",
      "Epoch 36/150\n",
      "892/892 [==============================] - 0s 33us/step - loss: 0.0786 - accuracy: 0.2971\n",
      "Epoch 37/150\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.26 - 0s 34us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 38/150\n",
      "892/892 [==============================] - 0s 33us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 39/150\n",
      "892/892 [==============================] - 0s 33us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 40/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 41/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0786 - accuracy: 0.2791\n",
      "Epoch 42/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 43/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 44/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 45/150\n",
      "892/892 [==============================] - 0s 33us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 46/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 47/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 48/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 49/150\n",
      "892/892 [==============================] - 0s 33us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 50/150\n",
      "892/892 [==============================] - 0s 36us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 51/150\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.38 - 0s 30us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 52/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 53/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 54/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 55/150\n",
      "892/892 [==============================] - 0s 37us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 56/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 57/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 58/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2702\n",
      "Epoch 59/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 60/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 61/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 62/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 63/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 64/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 65/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 66/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 67/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 68/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2702\n",
      "Epoch 69/150\n",
      "892/892 [==============================] - 0s 16us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 70/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 71/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 72/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 73/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 74/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 75/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 76/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 77/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 78/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2993\n",
      "Epoch 79/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 80/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 81/150\n",
      "892/892 [==============================] - 0s 15us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 82/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2702\n",
      "Epoch 83/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 84/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 85/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 86/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 87/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 88/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2702\n",
      "Epoch 89/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2971\n",
      "Epoch 90/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2635\n",
      "Epoch 91/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0786 - accuracy: 0.2803\n",
      "Epoch 92/150\n",
      "892/892 [==============================] - 0s 16us/step - loss: 0.0786 - accuracy: 0.2713\n",
      "Epoch 93/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 94/150\n",
      "892/892 [==============================] - 0s 16us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 95/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 96/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 97/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 98/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 99/150\n",
      "892/892 [==============================] - 0s 16us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 100/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 101/150\n",
      "892/892 [==============================] - 0s 16us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 102/150\n",
      "892/892 [==============================] - 0s 16us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 103/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2791\n",
      "Epoch 104/150\n",
      "892/892 [==============================] - 0s 16us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 105/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 106/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 107/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2758\n",
      "Epoch 108/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 109/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 110/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 111/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 112/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2735\n",
      "Epoch 113/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 114/150\n",
      "892/892 [==============================] - 0s 16us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 115/150\n",
      "892/892 [==============================] - 0s 16us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 116/150\n",
      "892/892 [==============================] - 0s 16us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 117/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 118/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 119/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2735\n",
      "Epoch 120/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 121/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 122/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 123/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 124/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 125/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 126/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 127/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 128/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2758\n",
      "Epoch 129/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 130/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 131/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2646\n",
      "Epoch 132/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 133/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 134/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 135/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 136/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 137/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 138/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 139/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 140/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 141/150\n",
      "892/892 [==============================] - 0s 16us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 142/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 143/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 144/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 145/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 146/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 147/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 148/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 149/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2971\n",
      "Epoch 150/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.3004\n",
      "460/460 [==============================] - 0s 96us/step\n",
      "Loss: 0.08\n",
      "Accuracy 0.33\n",
      "Epoch 1/150\n",
      "892/892 [==============================] - 0s 213us/step - loss: 0.1527 - accuracy: 0.2679\n",
      "Epoch 2/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0927 - accuracy: 0.2948\n",
      "Epoch 3/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0844 - accuracy: 0.2948\n",
      "Epoch 4/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0818 - accuracy: 0.2904\n",
      "Epoch 5/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0807 - accuracy: 0.2904\n",
      "Epoch 6/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0800 - accuracy: 0.2948\n",
      "Epoch 7/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892/892 [==============================] - 0s 20us/step - loss: 0.0797 - accuracy: 0.2948\n",
      "Epoch 8/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0794 - accuracy: 0.2881\n",
      "Epoch 9/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0793 - accuracy: 0.2814\n",
      "Epoch 10/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0791 - accuracy: 0.2915\n",
      "Epoch 11/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0791 - accuracy: 0.2814\n",
      "Epoch 12/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0790 - accuracy: 0.2948\n",
      "Epoch 13/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0789 - accuracy: 0.2814\n",
      "Epoch 14/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0788 - accuracy: 0.2803\n",
      "Epoch 15/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0788 - accuracy: 0.2948\n",
      "Epoch 16/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0788 - accuracy: 0.2836\n",
      "Epoch 17/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0788 - accuracy: 0.2791\n",
      "Epoch 18/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0787 - accuracy: 0.2948\n",
      "Epoch 19/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0787 - accuracy: 0.2948\n",
      "Epoch 20/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0787 - accuracy: 0.2881\n",
      "Epoch 21/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0787 - accuracy: 0.2881\n",
      "Epoch 22/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 23/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 24/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0786 - accuracy: 0.2937\n",
      "Epoch 25/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 26/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 27/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 28/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 29/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 30/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 31/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 32/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 33/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 34/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 35/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2691\n",
      "Epoch 36/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 37/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 38/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0786 - accuracy: 0.2679\n",
      "Epoch 39/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 40/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2803\n",
      "Epoch 41/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 42/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2657\n",
      "Epoch 43/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2960\n",
      "Epoch 44/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 45/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2735\n",
      "Epoch 46/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 47/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2735\n",
      "Epoch 48/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 49/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 50/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2993\n",
      "Epoch 51/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 52/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 53/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2803\n",
      "Epoch 54/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 55/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 56/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 57/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 58/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 59/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 60/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2713\n",
      "Epoch 61/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 62/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 63/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 64/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 65/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 66/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 67/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2668\n",
      "Epoch 68/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 69/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 70/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 71/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 72/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 73/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2646\n",
      "Epoch 74/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0786 - accuracy: 0.2623\n",
      "Epoch 75/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 76/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 77/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.3004\n",
      "Epoch 78/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 79/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 80/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 81/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 82/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 83/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 84/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 85/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2612\n",
      "Epoch 86/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 87/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2635\n",
      "Epoch 88/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 89/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 90/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 91/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 92/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 93/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 94/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2679\n",
      "Epoch 95/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 96/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 97/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 98/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2724\n",
      "Epoch 99/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 100/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 101/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 102/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 103/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 104/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 105/150\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.32 - 0s 20us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 106/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 107/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 108/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 109/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 110/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2657\n",
      "Epoch 111/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 112/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 113/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2612\n",
      "Epoch 114/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2758\n",
      "Epoch 115/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 116/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 117/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2702\n",
      "Epoch 118/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2982\n",
      "Epoch 119/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 120/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2735\n",
      "Epoch 121/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 122/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2971\n",
      "Epoch 123/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 124/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 125/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 126/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 127/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 128/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 129/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 130/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 131/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 132/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 133/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 134/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 135/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 136/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 137/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 138/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 139/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 140/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 141/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 142/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 143/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 144/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 145/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2971\n",
      "Epoch 146/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2713\n",
      "Epoch 147/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 148/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 149/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 150/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "460/460 [==============================] - 0s 122us/step\n",
      "Loss: 0.08\n",
      "Accuracy 0.29\n",
      "Epoch 1/150\n",
      "892/892 [==============================] - 0s 334us/step - loss: 0.1527 - accuracy: 0.2590\n",
      "Epoch 2/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0898 - accuracy: 0.2825\n",
      "Epoch 3/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0833 - accuracy: 0.2713\n",
      "Epoch 4/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0813 - accuracy: 0.2881\n",
      "Epoch 5/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0804 - accuracy: 0.2859\n",
      "Epoch 6/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0799 - accuracy: 0.2948\n",
      "Epoch 7/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0796 - accuracy: 0.2948\n",
      "Epoch 8/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0794 - accuracy: 0.2948\n",
      "Epoch 9/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0792 - accuracy: 0.2948\n",
      "Epoch 10/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0791 - accuracy: 0.2948\n",
      "Epoch 11/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0790 - accuracy: 0.2702\n",
      "Epoch 12/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0790 - accuracy: 0.2915\n",
      "Epoch 13/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0789 - accuracy: 0.2814\n",
      "Epoch 14/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892/892 [==============================] - 0s 22us/step - loss: 0.0788 - accuracy: 0.2848\n",
      "Epoch 15/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0788 - accuracy: 0.2735\n",
      "Epoch 16/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0788 - accuracy: 0.2960\n",
      "Epoch 17/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0788 - accuracy: 0.2769\n",
      "Epoch 18/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0787 - accuracy: 0.2892\n",
      "Epoch 19/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0787 - accuracy: 0.2825\n",
      "Epoch 20/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0787 - accuracy: 0.2848\n",
      "Epoch 21/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0787 - accuracy: 0.2825\n",
      "Epoch 22/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0787 - accuracy: 0.2948\n",
      "Epoch 23/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 24/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 25/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0787 - accuracy: 0.2668\n",
      "Epoch 26/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 27/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 28/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 29/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 30/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 31/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 32/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 33/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2904\n",
      "Epoch 34/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 35/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2904\n",
      "Epoch 36/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 37/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2926\n",
      "Epoch 38/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 39/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2791\n",
      "Epoch 40/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2724\n",
      "Epoch 41/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 42/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 43/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2758\n",
      "Epoch 44/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2926\n",
      "Epoch 45/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 46/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 47/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 48/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 49/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 50/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 51/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 52/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2926\n",
      "Epoch 53/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2612\n",
      "Epoch 54/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 55/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 56/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2960\n",
      "Epoch 57/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 58/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 59/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2713\n",
      "Epoch 60/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 61/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 62/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2668\n",
      "Epoch 63/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 64/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 65/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 66/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2724\n",
      "Epoch 67/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 68/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 69/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 70/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 71/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 72/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 73/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 74/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 75/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 76/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2646\n",
      "Epoch 77/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 78/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 79/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 80/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 81/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 82/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 83/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 84/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 85/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2758\n",
      "Epoch 86/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 87/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 88/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2657\n",
      "Epoch 89/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 90/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 91/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2702\n",
      "Epoch 92/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2791\n",
      "Epoch 93/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 94/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 95/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 96/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2758\n",
      "Epoch 97/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 98/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2960\n",
      "Epoch 99/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 100/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 101/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 102/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 103/150\n",
      "892/892 [==============================] - 0s 37us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 104/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 105/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 106/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 107/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 108/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 109/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 110/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 111/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 112/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 113/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 114/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 115/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2735\n",
      "Epoch 116/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 117/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 118/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 119/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 120/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 121/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 122/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 123/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 124/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 125/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 126/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 127/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2713\n",
      "Epoch 128/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 129/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 130/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2635\n",
      "Epoch 131/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 132/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 133/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.3004\n",
      "Epoch 134/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 135/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 136/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 137/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 138/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2646\n",
      "Epoch 139/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 140/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 141/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 142/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 143/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 144/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 145/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2679\n",
      "Epoch 146/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2668\n",
      "Epoch 147/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 148/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 149/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 150/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "460/460 [==============================] - 0s 193us/step\n",
      "Loss: 0.08\n",
      "Accuracy 0.33\n",
      "Epoch 1/150\n",
      "892/892 [==============================] - 0s 360us/step - loss: 0.1526 - accuracy: 0.2870\n",
      "Epoch 2/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0918 - accuracy: 0.2870\n",
      "Epoch 3/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0841 - accuracy: 0.2904\n",
      "Epoch 4/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0817 - accuracy: 0.2747\n",
      "Epoch 5/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0806 - accuracy: 0.2657\n",
      "Epoch 6/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0800 - accuracy: 0.2948\n",
      "Epoch 7/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0797 - accuracy: 0.2803\n",
      "Epoch 8/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0794 - accuracy: 0.2948\n",
      "Epoch 9/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0793 - accuracy: 0.2758\n",
      "Epoch 10/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0792 - accuracy: 0.2971\n",
      "Epoch 11/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0791 - accuracy: 0.2769\n",
      "Epoch 12/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0790 - accuracy: 0.2904\n",
      "Epoch 13/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0789 - accuracy: 0.2735\n",
      "Epoch 14/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0789 - accuracy: 0.2791\n",
      "Epoch 15/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0789 - accuracy: 0.2859\n",
      "Epoch 16/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0788 - accuracy: 0.2859\n",
      "Epoch 17/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0788 - accuracy: 0.2904\n",
      "Epoch 18/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0787 - accuracy: 0.2948\n",
      "Epoch 19/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0787 - accuracy: 0.2769\n",
      "Epoch 20/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0787 - accuracy: 0.2948\n",
      "Epoch 21/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892/892 [==============================] - 0s 25us/step - loss: 0.0787 - accuracy: 0.2960\n",
      "Epoch 22/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0787 - accuracy: 0.2814\n",
      "Epoch 23/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0787 - accuracy: 0.2848\n",
      "Epoch 24/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0787 - accuracy: 0.2657\n",
      "Epoch 25/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2904\n",
      "Epoch 26/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 27/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 28/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 29/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2960\n",
      "Epoch 30/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 31/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2578\n",
      "Epoch 32/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 33/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 34/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2926\n",
      "Epoch 35/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 36/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2937\n",
      "Epoch 37/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 38/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 39/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 40/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 41/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 42/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 43/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 44/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 45/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2691\n",
      "Epoch 46/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2679\n",
      "Epoch 47/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 48/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 49/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 50/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 51/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 52/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 53/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 54/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 55/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 56/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 57/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 58/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 59/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 60/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 61/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 62/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 63/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 64/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 65/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 66/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2679\n",
      "Epoch 67/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 68/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 69/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 70/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 71/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 72/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 73/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2735\n",
      "Epoch 74/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 75/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 76/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 77/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 78/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 79/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 80/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 81/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 82/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 83/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 84/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 85/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 86/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2646\n",
      "Epoch 87/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 88/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 89/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 90/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 91/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 92/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 93/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 94/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 95/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2713\n",
      "Epoch 96/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 97/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2735\n",
      "Epoch 98/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 99/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 100/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 101/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 102/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 103/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 104/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 105/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 106/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 107/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 108/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 109/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 110/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 111/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2993\n",
      "Epoch 112/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.3061\n",
      "Epoch 113/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 114/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 115/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 116/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2960\n",
      "Epoch 117/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 118/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 119/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 120/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 121/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 122/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 123/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 124/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 125/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 126/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 127/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2758\n",
      "Epoch 128/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 129/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2960\n",
      "Epoch 130/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 131/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2567\n",
      "Epoch 132/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 133/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 134/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 135/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 136/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2702\n",
      "Epoch 137/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 138/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 139/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 140/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 141/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 142/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 143/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2735\n",
      "Epoch 144/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 145/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 146/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 147/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 148/150\n",
      "892/892 [==============================] - 0s 39us/step - loss: 0.0786 - accuracy: 0.2679\n",
      "Epoch 149/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 150/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "460/460 [==============================] - 0s 193us/step\n",
      "Loss: 0.08\n",
      "Accuracy 0.29\n",
      "Epoch 1/150\n",
      "892/892 [==============================] - 0s 188us/step - loss: 0.1392 - accuracy: 0.2399\n",
      "Epoch 2/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0858 - accuracy: 0.2803\n",
      "Epoch 3/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0816 - accuracy: 0.2735\n",
      "Epoch 4/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0803 - accuracy: 0.2848\n",
      "Epoch 5/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0797 - accuracy: 0.2892\n",
      "Epoch 6/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0794 - accuracy: 0.2904\n",
      "Epoch 7/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0792 - accuracy: 0.2769\n",
      "Epoch 8/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0791 - accuracy: 0.2836\n",
      "Epoch 9/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0790 - accuracy: 0.2747\n",
      "Epoch 10/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0789 - accuracy: 0.2915\n",
      "Epoch 11/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0789 - accuracy: 0.2948\n",
      "Epoch 12/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0788 - accuracy: 0.2993\n",
      "Epoch 13/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0787 - accuracy: 0.2926\n",
      "Epoch 14/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0787 - accuracy: 0.3038\n",
      "Epoch 15/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0787 - accuracy: 0.2825\n",
      "Epoch 16/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0787 - accuracy: 0.2612\n",
      "Epoch 17/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0787 - accuracy: 0.2881\n",
      "Epoch 18/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 19/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0787 - accuracy: 0.2758\n",
      "Epoch 20/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 21/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2904\n",
      "Epoch 22/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 23/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2982\n",
      "Epoch 24/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 25/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 26/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 27/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2803\n",
      "Epoch 28/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 29/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2679\n",
      "Epoch 30/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 31/150\n",
      "892/892 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 32/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 33/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2747\n",
      "Epoch 34/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 35/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 36/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 37/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0786 - accuracy: 0.2702\n",
      "Epoch 38/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 39/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2971\n",
      "Epoch 40/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 41/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 42/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 43/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 44/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2747\n",
      "Epoch 45/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 46/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 47/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 48/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 49/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 50/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 51/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 52/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 53/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 54/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2971\n",
      "Epoch 55/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 56/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 57/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 58/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 59/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 60/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 61/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 62/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 63/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 64/150\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.29 - 0s 20us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 65/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2691\n",
      "Epoch 66/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 67/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2758\n",
      "Epoch 68/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 69/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 70/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2567\n",
      "Epoch 71/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 72/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2691\n",
      "Epoch 73/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 74/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2747\n",
      "Epoch 75/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 76/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2635\n",
      "Epoch 77/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2758\n",
      "Epoch 78/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 79/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 80/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 81/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 82/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 83/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 84/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 85/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 86/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 87/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 88/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 89/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 90/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 91/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 92/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 93/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 94/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 95/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2993\n",
      "Epoch 96/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 97/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2724\n",
      "Epoch 98/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 99/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 100/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 101/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 102/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 103/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2735\n",
      "Epoch 104/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 105/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 106/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2904\n",
      "Epoch 107/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2993\n",
      "Epoch 108/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2937\n",
      "Epoch 109/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 110/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2971\n",
      "Epoch 111/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 112/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2713\n",
      "Epoch 113/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2724\n",
      "Epoch 114/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 115/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 116/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2657\n",
      "Epoch 117/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 118/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2960\n",
      "Epoch 119/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2668\n",
      "Epoch 120/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 121/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 122/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2679\n",
      "Epoch 123/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 124/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 125/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 126/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 127/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 128/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 129/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 130/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2724\n",
      "Epoch 131/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 132/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 133/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 134/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.3049\n",
      "Epoch 135/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2713\n",
      "Epoch 136/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 137/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 138/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2960\n",
      "Epoch 139/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2679\n",
      "Epoch 140/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 141/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 142/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 143/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 144/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2758\n",
      "Epoch 145/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 146/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 147/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 148/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 149/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2623\n",
      "Epoch 150/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "460/460 [==============================] - 0s 161us/step\n",
      "Loss: 0.08\n",
      "Accuracy 0.33\n",
      "Epoch 1/150\n",
      "892/892 [==============================] - 0s 258us/step - loss: 0.1233 - accuracy: 0.2948\n",
      "Epoch 2/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0838 - accuracy: 0.2904\n",
      "Epoch 3/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0808 - accuracy: 0.2948\n",
      "Epoch 4/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0799 - accuracy: 0.2702\n",
      "Epoch 5/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0794 - accuracy: 0.2803\n",
      "Epoch 6/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0792 - accuracy: 0.2993\n",
      "Epoch 7/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0791 - accuracy: 0.2713\n",
      "Epoch 8/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0790 - accuracy: 0.2747\n",
      "Epoch 9/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0789 - accuracy: 0.2836\n",
      "Epoch 10/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0788 - accuracy: 0.2803\n",
      "Epoch 11/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0788 - accuracy: 0.2948\n",
      "Epoch 12/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0787 - accuracy: 0.2870\n",
      "Epoch 13/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0787 - accuracy: 0.2892\n",
      "Epoch 14/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0787 - accuracy: 0.2948\n",
      "Epoch 15/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0787 - accuracy: 0.2691\n",
      "Epoch 16/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0787 - accuracy: 0.2848\n",
      "Epoch 17/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0787 - accuracy: 0.2780\n",
      "Epoch 18/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0787 - accuracy: 0.2769\n",
      "Epoch 19/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 20/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 21/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2803\n",
      "Epoch 22/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 23/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0787 - accuracy: 0.2892\n",
      "Epoch 24/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 25/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 26/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 27/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2668\n",
      "Epoch 28/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 29/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 30/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2803\n",
      "Epoch 31/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 32/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 33/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 34/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2904\n",
      "Epoch 35/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 36/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 37/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2735\n",
      "Epoch 38/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2993\n",
      "Epoch 39/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 40/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2623\n",
      "Epoch 41/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 42/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 43/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 44/150\n",
      "892/892 [==============================] - 0s 18us/step - loss: 0.0786 - accuracy: 0.2735\n",
      "Epoch 45/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 46/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 47/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 48/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 49/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 50/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 51/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 52/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2702\n",
      "Epoch 53/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2982\n",
      "Epoch 54/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 55/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 56/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 57/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 58/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 59/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2791\n",
      "Epoch 60/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2601\n",
      "Epoch 61/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 62/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 63/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 64/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 65/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 66/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 67/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2971\n",
      "Epoch 68/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 69/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2937\n",
      "Epoch 70/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2904\n",
      "Epoch 71/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 72/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 73/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 74/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 75/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2937\n",
      "Epoch 76/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 77/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2937\n",
      "Epoch 78/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2522\n",
      "Epoch 79/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2713\n",
      "Epoch 80/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 81/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 82/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 83/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 84/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2747\n",
      "Epoch 85/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 86/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2735\n",
      "Epoch 87/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 88/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2713\n",
      "Epoch 89/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 90/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 91/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 92/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.3027\n",
      "Epoch 93/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 94/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 95/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 96/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2735\n",
      "Epoch 97/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2691\n",
      "Epoch 98/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 99/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 100/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2702\n",
      "Epoch 101/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 102/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 103/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2904\n",
      "Epoch 104/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2646\n",
      "Epoch 105/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 106/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 107/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 108/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 109/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2904\n",
      "Epoch 110/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 111/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 112/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0786 - accuracy: 0.2410\n",
      "Epoch 113/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 114/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2646\n",
      "Epoch 115/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2635\n",
      "Epoch 116/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 117/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 118/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2578\n",
      "Epoch 119/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 120/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 121/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2993\n",
      "Epoch 122/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 123/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2646\n",
      "Epoch 124/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2713\n",
      "Epoch 125/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 126/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 127/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 128/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 129/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2724\n",
      "Epoch 130/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 131/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 132/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 133/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2735\n",
      "Epoch 134/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 135/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 136/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.3038\n",
      "Epoch 137/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 138/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 139/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2657\n",
      "Epoch 140/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 141/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 142/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2691\n",
      "Epoch 143/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 144/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 145/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 146/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2982\n",
      "Epoch 147/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 148/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 149/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 150/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "460/460 [==============================] - 0s 189us/step\n",
      "Loss: 0.08\n",
      "Accuracy 0.33\n",
      "Epoch 1/150\n",
      "892/892 [==============================] - 0s 327us/step - loss: 0.1260 - accuracy: 0.2870\n",
      "Epoch 2/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0842 - accuracy: 0.2769\n",
      "Epoch 3/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0810 - accuracy: 0.2971\n",
      "Epoch 4/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0800 - accuracy: 0.2948\n",
      "Epoch 5/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0795 - accuracy: 0.2859\n",
      "Epoch 6/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0793 - accuracy: 0.2848\n",
      "Epoch 7/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0791 - accuracy: 0.2780\n",
      "Epoch 8/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0790 - accuracy: 0.2904\n",
      "Epoch 9/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0789 - accuracy: 0.2803\n",
      "Epoch 10/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0789 - accuracy: 0.2948\n",
      "Epoch 11/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0788 - accuracy: 0.2769\n",
      "Epoch 12/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0787 - accuracy: 0.2948\n",
      "Epoch 13/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0787 - accuracy: 0.2702\n",
      "Epoch 14/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0787 - accuracy: 0.2892\n",
      "Epoch 15/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0787 - accuracy: 0.2870\n",
      "Epoch 16/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0787 - accuracy: 0.2825\n",
      "Epoch 17/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 18/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0787 - accuracy: 0.2780\n",
      "Epoch 19/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 20/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 21/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2904\n",
      "Epoch 22/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 23/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2926\n",
      "Epoch 24/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 25/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2612\n",
      "Epoch 26/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 27/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 28/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 29/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2960\n",
      "Epoch 30/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 31/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 32/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 33/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 34/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2904\n",
      "Epoch 35/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 36/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 37/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0787 - accuracy: 0.2791\n",
      "Epoch 38/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 39/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2904\n",
      "Epoch 40/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 41/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2982\n",
      "Epoch 42/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2926\n",
      "Epoch 43/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 44/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 45/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2993\n",
      "Epoch 46/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 47/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 48/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 49/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 50/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 51/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 52/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 53/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2960\n",
      "Epoch 54/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 55/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 56/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 57/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2679\n",
      "Epoch 58/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2960\n",
      "Epoch 59/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.3004\n",
      "Epoch 60/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 61/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 62/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 63/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 64/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 65/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 66/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 67/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 68/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2657\n",
      "Epoch 69/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 70/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 71/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 72/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 73/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 74/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2803\n",
      "Epoch 75/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2971\n",
      "Epoch 76/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2668\n",
      "Epoch 77/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2702\n",
      "Epoch 78/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2960\n",
      "Epoch 79/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2982\n",
      "Epoch 80/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2747\n",
      "Epoch 81/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 82/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 83/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 84/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2960\n",
      "Epoch 85/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 86/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 87/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 88/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 89/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2713\n",
      "Epoch 90/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 91/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 92/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 93/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2612\n",
      "Epoch 94/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 95/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 96/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 97/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 98/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 99/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 100/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 101/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 102/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 103/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 104/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0785 - accuracy: 0.2971\n",
      "Epoch 105/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 106/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 107/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2758\n",
      "Epoch 108/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 109/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.3004\n",
      "Epoch 110/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2735\n",
      "Epoch 111/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2803\n",
      "Epoch 112/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 113/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2937\n",
      "Epoch 114/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 115/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 116/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 117/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 118/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 119/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 120/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 121/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 122/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2960\n",
      "Epoch 123/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.3049\n",
      "Epoch 124/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 125/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2691\n",
      "Epoch 126/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 127/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 128/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 129/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 130/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2657\n",
      "Epoch 131/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 132/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.3049\n",
      "Epoch 133/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 134/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 135/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 136/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 137/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2713\n",
      "Epoch 138/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 139/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 140/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 141/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 142/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 143/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 144/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 145/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 146/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 147/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 148/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 149/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 150/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "460/460 [==============================] - 0s 239us/step\n",
      "Loss: 0.08\n",
      "Accuracy 0.33\n",
      "Epoch 1/150\n",
      "892/892 [==============================] - 0s 392us/step - loss: 0.1389 - accuracy: 0.2287\n",
      "Epoch 2/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0852 - accuracy: 0.2848\n",
      "Epoch 3/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0813 - accuracy: 0.2747\n",
      "Epoch 4/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0801 - accuracy: 0.2825\n",
      "Epoch 5/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0796 - accuracy: 0.2836\n",
      "Epoch 6/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0793 - accuracy: 0.2791\n",
      "Epoch 7/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0791 - accuracy: 0.2948\n",
      "Epoch 8/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0790 - accuracy: 0.2859\n",
      "Epoch 9/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0789 - accuracy: 0.2747\n",
      "Epoch 10/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0788 - accuracy: 0.2926\n",
      "Epoch 11/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0788 - accuracy: 0.3004\n",
      "Epoch 12/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0788 - accuracy: 0.2657\n",
      "Epoch 13/150\n",
      "892/892 [==============================] - 0s 33us/step - loss: 0.0787 - accuracy: 0.2948\n",
      "Epoch 14/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0787 - accuracy: 0.3038\n",
      "Epoch 15/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0787 - accuracy: 0.2948\n",
      "Epoch 16/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0787 - accuracy: 0.2780\n",
      "Epoch 17/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0787 - accuracy: 0.2926\n",
      "Epoch 18/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 19/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 20/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0787 - accuracy: 0.2724\n",
      "Epoch 21/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0787 - accuracy: 0.2803\n",
      "Epoch 22/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 23/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2679\n",
      "Epoch 24/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 25/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2679\n",
      "Epoch 26/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2937\n",
      "Epoch 27/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2646\n",
      "Epoch 28/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2904\n",
      "Epoch 29/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 30/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 31/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.3004\n",
      "Epoch 32/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 33/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0786 - accuracy: 0.2960\n",
      "Epoch 34/150\n",
      "892/892 [==============================] - 0s 46us/step - loss: 0.0786 - accuracy: 0.2904\n",
      "Epoch 35/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 36/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 37/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 38/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 39/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 40/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0787 - accuracy: 0.2881\n",
      "Epoch 41/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 42/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 43/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 44/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2960\n",
      "Epoch 45/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2713\n",
      "Epoch 46/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 47/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 48/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2657\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 50/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 51/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 52/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2926\n",
      "Epoch 53/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2926\n",
      "Epoch 54/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 55/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 56/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 57/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 58/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 59/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 60/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 61/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 62/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 63/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 64/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 65/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2803\n",
      "Epoch 66/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 67/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 68/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2635\n",
      "Epoch 69/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 70/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 71/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.3038\n",
      "Epoch 72/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 73/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 74/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 75/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2735\n",
      "Epoch 76/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 77/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 78/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 79/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2971\n",
      "Epoch 80/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 81/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 82/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2702\n",
      "Epoch 83/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 84/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 85/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2982\n",
      "Epoch 86/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 87/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2702\n",
      "Epoch 88/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2679\n",
      "Epoch 89/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 90/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 91/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 92/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 93/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 94/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 95/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 96/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 97/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 98/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 99/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 100/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 101/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 102/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.3027\n",
      "Epoch 103/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 104/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 105/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 106/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 107/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 108/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 109/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2623\n",
      "Epoch 110/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2971\n",
      "Epoch 111/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 112/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 113/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 114/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 115/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 116/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 117/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 118/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 119/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 120/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 121/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 122/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 123/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2713\n",
      "Epoch 124/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 125/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 126/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 127/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 128/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 129/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 130/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 131/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2758\n",
      "Epoch 132/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 133/150\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.31 - 0s 25us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 134/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2982\n",
      "Epoch 135/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0787 - accuracy: 0.2635\n",
      "Epoch 136/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2724\n",
      "Epoch 137/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 138/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 139/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 140/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 141/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0785 - accuracy: 0.2713\n",
      "Epoch 142/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 143/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 144/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 145/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 146/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 147/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 148/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 149/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.3016\n",
      "Epoch 150/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "460/460 [==============================] - 0s 259us/step\n",
      "Loss: 0.08\n",
      "Accuracy 0.33\n",
      "Epoch 1/150\n",
      "892/892 [==============================] - 0s 278us/step - loss: 0.1394 - accuracy: 0.2220\n",
      "Epoch 2/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0860 - accuracy: 0.2747\n",
      "Epoch 3/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0815 - accuracy: 0.2848\n",
      "Epoch 4/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0802 - accuracy: 0.2791\n",
      "Epoch 5/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0796 - accuracy: 0.2892\n",
      "Epoch 6/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0793 - accuracy: 0.2859\n",
      "Epoch 7/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0791 - accuracy: 0.2848\n",
      "Epoch 8/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0790 - accuracy: 0.2859\n",
      "Epoch 9/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0789 - accuracy: 0.2948\n",
      "Epoch 10/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0788 - accuracy: 0.2836\n",
      "Epoch 11/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0788 - accuracy: 0.2915\n",
      "Epoch 12/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0787 - accuracy: 0.2814\n",
      "Epoch 13/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0787 - accuracy: 0.2948\n",
      "Epoch 14/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0787 - accuracy: 0.2825\n",
      "Epoch 15/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0787 - accuracy: 0.2904\n",
      "Epoch 16/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0787 - accuracy: 0.2825\n",
      "Epoch 17/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 18/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0787 - accuracy: 0.2836\n",
      "Epoch 19/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2904\n",
      "Epoch 20/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0787 - accuracy: 0.2567\n",
      "Epoch 21/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 22/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 23/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2982\n",
      "Epoch 24/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0787 - accuracy: 0.2870\n",
      "Epoch 25/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 26/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2993\n",
      "Epoch 27/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 28/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 29/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2982\n",
      "Epoch 30/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 31/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 32/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 33/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0787 - accuracy: 0.2948\n",
      "Epoch 34/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 35/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 36/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 37/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 38/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 39/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 40/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 41/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.3027\n",
      "Epoch 42/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 43/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2982\n",
      "Epoch 44/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2758\n",
      "Epoch 45/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 46/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 47/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 48/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 49/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2601\n",
      "Epoch 50/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 51/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 52/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 53/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2971\n",
      "Epoch 54/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 55/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 56/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 57/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2993\n",
      "Epoch 58/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0787 - accuracy: 0.2948\n",
      "Epoch 59/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 60/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2758\n",
      "Epoch 61/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 62/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 63/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 64/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 65/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 66/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2747\n",
      "Epoch 67/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 68/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 69/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2713\n",
      "Epoch 70/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2646\n",
      "Epoch 71/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 72/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2960\n",
      "Epoch 73/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 74/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 75/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 76/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 77/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 78/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 79/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2904\n",
      "Epoch 80/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2747\n",
      "Epoch 81/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2747\n",
      "Epoch 82/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 83/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 84/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 85/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 86/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 87/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 88/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 89/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 90/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 91/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 92/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 93/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2735\n",
      "Epoch 94/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 95/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 96/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 97/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 98/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 99/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 100/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2791\n",
      "Epoch 101/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 102/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2791\n",
      "Epoch 103/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2926\n",
      "Epoch 104/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 105/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 106/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2735\n",
      "Epoch 107/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 108/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 109/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2960\n",
      "Epoch 110/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 111/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 112/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 113/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 114/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 115/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 116/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 117/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 118/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 119/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 120/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 121/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0786 - accuracy: 0.2545\n",
      "Epoch 122/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 123/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 124/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2937\n",
      "Epoch 125/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 126/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2803\n",
      "Epoch 127/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2735\n",
      "Epoch 128/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 129/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2713\n",
      "Epoch 130/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 131/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 132/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 133/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2904\n",
      "Epoch 134/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2993\n",
      "Epoch 135/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.3016\n",
      "Epoch 136/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 137/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 138/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 139/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 140/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 141/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 142/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 143/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 144/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 145/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 146/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 147/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 148/150\n",
      "892/892 [==============================] - 0s 20us/step - loss: 0.0785 - accuracy: 0.2735\n",
      "Epoch 149/150\n",
      "892/892 [==============================] - 0s 19us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 150/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "460/460 [==============================] - 0s 235us/step\n",
      "Loss: 0.08\n",
      "Accuracy 0.33\n",
      "Epoch 1/150\n",
      "892/892 [==============================] - 0s 289us/step - loss: 0.1357 - accuracy: 0.2422\n",
      "Epoch 2/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0839 - accuracy: 0.2769\n",
      "Epoch 3/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0808 - accuracy: 0.2803\n",
      "Epoch 4/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0798 - accuracy: 0.2825\n",
      "Epoch 5/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0794 - accuracy: 0.2848\n",
      "Epoch 6/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0791 - accuracy: 0.2836\n",
      "Epoch 7/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0791 - accuracy: 0.2825\n",
      "Epoch 8/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0790 - accuracy: 0.2926\n",
      "Epoch 9/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0788 - accuracy: 0.2915\n",
      "Epoch 10/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0788 - accuracy: 0.2679\n",
      "Epoch 11/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0789 - accuracy: 0.2791\n",
      "Epoch 12/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0788 - accuracy: 0.2825\n",
      "Epoch 13/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0787 - accuracy: 0.2948\n",
      "Epoch 14/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0788 - accuracy: 0.2713\n",
      "Epoch 15/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0787 - accuracy: 0.2735\n",
      "Epoch 16/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0788 - accuracy: 0.2623\n",
      "Epoch 17/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 18/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2691\n",
      "Epoch 19/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 20/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 21/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2993\n",
      "Epoch 22/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2713\n",
      "Epoch 23/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 24/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 25/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 26/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0787 - accuracy: 0.2713\n",
      "Epoch 27/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2612\n",
      "Epoch 28/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 29/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 30/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 31/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2702\n",
      "Epoch 32/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 33/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2803\n",
      "Epoch 34/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0787 - accuracy: 0.2859\n",
      "Epoch 35/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 36/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0787 - accuracy: 0.2590\n",
      "Epoch 37/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2747\n",
      "Epoch 38/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0787 - accuracy: 0.2870\n",
      "Epoch 39/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 40/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0787 - accuracy: 0.2668\n",
      "Epoch 41/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 42/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 43/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 44/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2691\n",
      "Epoch 45/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 46/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2735\n",
      "Epoch 47/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 48/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2758\n",
      "Epoch 49/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 50/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2982\n",
      "Epoch 51/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2635\n",
      "Epoch 52/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 53/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 54/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 55/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 56/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 57/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 58/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2679\n",
      "Epoch 59/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 60/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 61/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 62/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 63/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2803\n",
      "Epoch 64/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2668\n",
      "Epoch 65/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2702\n",
      "Epoch 66/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2937\n",
      "Epoch 67/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 68/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 69/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2657\n",
      "Epoch 70/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0787 - accuracy: 0.2747\n",
      "Epoch 71/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 72/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2971\n",
      "Epoch 73/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 74/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 75/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 76/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 77/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 78/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 79/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 80/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2982\n",
      "Epoch 81/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 82/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 83/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 84/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 85/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.3038\n",
      "Epoch 86/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 87/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 88/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2791\n",
      "Epoch 89/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 90/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 91/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 92/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 93/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 94/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 95/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 96/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 97/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 98/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 99/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2758\n",
      "Epoch 100/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 101/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 102/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 103/150\n",
      "892/892 [==============================] - 0s 36us/step - loss: 0.0785 - accuracy: 0.2735\n",
      "Epoch 104/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 105/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.3016\n",
      "Epoch 106/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 107/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 108/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 109/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 110/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 111/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 112/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0785 - accuracy: 0.2971\n",
      "Epoch 113/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 114/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2747\n",
      "Epoch 115/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2713\n",
      "Epoch 116/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2635\n",
      "Epoch 117/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 118/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 119/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 120/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 121/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2668\n",
      "Epoch 122/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0787 - accuracy: 0.2702\n",
      "Epoch 123/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 124/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2780\n",
      "Epoch 125/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0787 - accuracy: 0.2825\n",
      "Epoch 126/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2758\n",
      "Epoch 127/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2993\n",
      "Epoch 128/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 129/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2971\n",
      "Epoch 130/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 131/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 132/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.3004\n",
      "Epoch 133/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2971\n",
      "Epoch 134/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 135/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0787 - accuracy: 0.2960\n",
      "Epoch 136/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 137/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2926\n",
      "Epoch 138/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 139/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 140/150\n",
      "892/892 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.36 - 0s 28us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 141/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 142/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2668\n",
      "Epoch 143/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 144/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 145/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 146/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 147/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 148/150\n",
      "892/892 [==============================] - 0s 22us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 149/150\n",
      "892/892 [==============================] - 0s 21us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 150/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "460/460 [==============================] - 0s 265us/step\n",
      "Loss: 0.08\n",
      "Accuracy 0.33\n",
      "Epoch 1/150\n",
      "892/892 [==============================] - 0s 365us/step - loss: 0.1446 - accuracy: 0.2343\n",
      "Epoch 2/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0869 - accuracy: 0.2948\n",
      "Epoch 3/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0820 - accuracy: 0.2668\n",
      "Epoch 4/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0805 - accuracy: 0.2814\n",
      "Epoch 5/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0798 - accuracy: 0.2825\n",
      "Epoch 6/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0795 - accuracy: 0.2881\n",
      "Epoch 7/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0792 - accuracy: 0.2881\n",
      "Epoch 8/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0792 - accuracy: 0.2635\n",
      "Epoch 9/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0791 - accuracy: 0.2747\n",
      "Epoch 10/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0789 - accuracy: 0.2948\n",
      "Epoch 11/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0789 - accuracy: 0.2848\n",
      "Epoch 12/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0789 - accuracy: 0.2948\n",
      "Epoch 13/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0788 - accuracy: 0.2814\n",
      "Epoch 14/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0788 - accuracy: 0.2836\n",
      "Epoch 15/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0788 - accuracy: 0.2971\n",
      "Epoch 16/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0787 - accuracy: 0.3004\n",
      "Epoch 17/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0787 - accuracy: 0.2948\n",
      "Epoch 18/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0787 - accuracy: 0.2758\n",
      "Epoch 19/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0787 - accuracy: 0.2948\n",
      "Epoch 20/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0787 - accuracy: 0.2859\n",
      "Epoch 21/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 22/150\n",
      "892/892 [==============================] - 0s 33us/step - loss: 0.0787 - accuracy: 0.2668\n",
      "Epoch 23/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0787 - accuracy: 0.2769\n",
      "Epoch 24/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2747\n",
      "Epoch 25/150\n",
      "892/892 [==============================] - 0s 45us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 26/150\n",
      "892/892 [==============================] - 0s 34us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 27/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2702\n",
      "Epoch 28/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 29/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 30/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 31/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2791\n",
      "Epoch 32/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 33/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 34/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 35/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2668\n",
      "Epoch 36/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 37/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2657\n",
      "Epoch 38/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 39/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2657\n",
      "Epoch 40/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2937\n",
      "Epoch 41/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 42/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 43/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.3016\n",
      "Epoch 44/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 45/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2713\n",
      "Epoch 46/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 47/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2657\n",
      "Epoch 48/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 49/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2646\n",
      "Epoch 50/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 51/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 52/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2735\n",
      "Epoch 53/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2758\n",
      "Epoch 54/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2982\n",
      "Epoch 55/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 56/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2982\n",
      "Epoch 57/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 58/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 59/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2668\n",
      "Epoch 60/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 61/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 62/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 63/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 64/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 65/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2735\n",
      "Epoch 66/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 67/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2803\n",
      "Epoch 68/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 69/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 70/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 71/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2993\n",
      "Epoch 72/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 73/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 74/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 75/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2791\n",
      "Epoch 76/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 77/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 78/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 79/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 80/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2691\n",
      "Epoch 81/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 82/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 83/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 84/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 85/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 86/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.3016\n",
      "Epoch 87/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.2623\n",
      "Epoch 88/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 89/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 90/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2455\n",
      "Epoch 91/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 92/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.3004\n",
      "Epoch 93/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 94/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 95/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 96/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 97/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 98/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 99/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 100/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 101/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 102/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2713\n",
      "Epoch 103/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 104/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 105/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 106/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 107/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 108/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2747\n",
      "Epoch 109/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 110/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2702\n",
      "Epoch 111/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 112/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 113/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 114/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 115/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.3049\n",
      "Epoch 116/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.3016\n",
      "Epoch 117/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 118/150\n",
      "892/892 [==============================] - 0s 35us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 119/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 120/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 121/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 122/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2803\n",
      "Epoch 123/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 124/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 125/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 126/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 127/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 128/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 129/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 130/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2724\n",
      "Epoch 131/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 132/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 133/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 134/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2657\n",
      "Epoch 135/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2691\n",
      "Epoch 136/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0785 - accuracy: 0.2993\n",
      "Epoch 137/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2567\n",
      "Epoch 138/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2702\n",
      "Epoch 139/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 140/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 141/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2691\n",
      "Epoch 142/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2691\n",
      "Epoch 143/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2769\n",
      "Epoch 144/150\n",
      "892/892 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 145/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 146/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 147/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 148/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 149/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2747\n",
      "Epoch 150/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "460/460 [==============================] - 0s 304us/step\n",
      "Loss: 0.08\n",
      "Accuracy 0.33\n",
      "Epoch 1/150\n",
      "892/892 [==============================] - 0s 431us/step - loss: 0.1335 - accuracy: 0.2321\n",
      "Epoch 2/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0841 - accuracy: 0.2948\n",
      "Epoch 3/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0808 - accuracy: 0.2747\n",
      "Epoch 4/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0798 - accuracy: 0.2612\n",
      "Epoch 5/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0794 - accuracy: 0.2803\n",
      "Epoch 6/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0792 - accuracy: 0.2668\n",
      "Epoch 7/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0790 - accuracy: 0.2836\n",
      "Epoch 8/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0789 - accuracy: 0.2904\n",
      "Epoch 9/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0789 - accuracy: 0.2948\n",
      "Epoch 10/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0788 - accuracy: 0.2836\n",
      "Epoch 11/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0788 - accuracy: 0.2948\n",
      "Epoch 12/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0787 - accuracy: 0.2769\n",
      "Epoch 13/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0787 - accuracy: 0.2881\n",
      "Epoch 14/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 15/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0787 - accuracy: 0.2814\n",
      "Epoch 16/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0787 - accuracy: 0.2859\n",
      "Epoch 17/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0787 - accuracy: 0.2791\n",
      "Epoch 18/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 19/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 20/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0787 - accuracy: 0.2702\n",
      "Epoch 21/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 22/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2926\n",
      "Epoch 23/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 24/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 25/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.3004\n",
      "Epoch 26/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 27/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 28/150\n",
      "892/892 [==============================] - 0s 34us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 29/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2657\n",
      "Epoch 30/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2960\n",
      "Epoch 31/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0786 - accuracy: 0.2926\n",
      "Epoch 32/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 33/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2691\n",
      "Epoch 34/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2960\n",
      "Epoch 35/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2993\n",
      "Epoch 36/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 37/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0786 - accuracy: 0.2735\n",
      "Epoch 38/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 39/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.3004\n",
      "Epoch 40/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 41/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 42/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 43/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 44/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 45/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 46/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 47/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0786 - accuracy: 0.2691\n",
      "Epoch 48/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 49/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 50/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 51/150\n",
      "892/892 [==============================] - 0s 33us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 52/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2814\n",
      "Epoch 53/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 54/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0786 - accuracy: 0.2937\n",
      "Epoch 55/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 56/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 57/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2971\n",
      "Epoch 58/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 59/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.3004\n",
      "Epoch 60/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 61/150\n",
      "892/892 [==============================] - 0s 34us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 62/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0786 - accuracy: 0.2915\n",
      "Epoch 63/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0786 - accuracy: 0.2702\n",
      "Epoch 64/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 65/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 66/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0785 - accuracy: 0.2702\n",
      "Epoch 67/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 68/150\n",
      "892/892 [==============================] - 0s 36us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 69/150\n",
      "892/892 [==============================] - 0s 33us/step - loss: 0.0786 - accuracy: 0.2747\n",
      "Epoch 70/150\n",
      "892/892 [==============================] - 0s 36us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 71/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0785 - accuracy: 0.2960\n",
      "Epoch 72/150\n",
      "892/892 [==============================] - 0s 33us/step - loss: 0.0785 - accuracy: 0.3038\n",
      "Epoch 73/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 74/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0787 - accuracy: 0.3027\n",
      "Epoch 75/150\n",
      "892/892 [==============================] - 0s 35us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 76/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2702\n",
      "Epoch 77/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2803\n",
      "Epoch 78/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 79/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 80/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0787 - accuracy: 0.2545\n",
      "Epoch 81/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 82/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2747\n",
      "Epoch 83/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 84/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 85/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 86/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2859\n",
      "Epoch 87/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 88/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 89/150\n",
      "892/892 [==============================] - 0s 26us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 90/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 91/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2679\n",
      "Epoch 92/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 93/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 94/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 95/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 96/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 97/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 98/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 99/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2825\n",
      "Epoch 100/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2803\n",
      "Epoch 101/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2691\n",
      "Epoch 102/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 103/150\n",
      "892/892 [==============================] - 0s 33us/step - loss: 0.0786 - accuracy: 0.2724\n",
      "Epoch 104/150\n",
      "892/892 [==============================] - 0s 38us/step - loss: 0.0786 - accuracy: 0.2780\n",
      "Epoch 105/150\n",
      "892/892 [==============================] - 0s 35us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 106/150\n",
      "892/892 [==============================] - 0s 38us/step - loss: 0.0786 - accuracy: 0.2769\n",
      "Epoch 107/150\n",
      "892/892 [==============================] - 0s 37us/step - loss: 0.0785 - accuracy: 0.2848\n",
      "Epoch 108/150\n",
      "892/892 [==============================] - 0s 39us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 109/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0785 - accuracy: 0.2859\n",
      "Epoch 110/150\n",
      "892/892 [==============================] - 0s 41us/step - loss: 0.0785 - accuracy: 0.3061\n",
      "Epoch 111/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0785 - accuracy: 0.2948\n",
      "Epoch 112/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 113/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 114/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2747\n",
      "Epoch 115/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2836\n",
      "Epoch 116/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "Epoch 117/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2691\n",
      "Epoch 118/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2836\n",
      "Epoch 119/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 120/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2926\n",
      "Epoch 121/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2881\n",
      "Epoch 122/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0787 - accuracy: 0.2500\n",
      "Epoch 123/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2623\n",
      "Epoch 124/150\n",
      "892/892 [==============================] - 0s 35us/step - loss: 0.0786 - accuracy: 0.2937\n",
      "Epoch 125/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0785 - accuracy: 0.2803\n",
      "Epoch 126/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0786 - accuracy: 0.2870\n",
      "Epoch 127/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 128/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 129/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2825\n",
      "Epoch 130/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 131/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2904\n",
      "Epoch 132/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 133/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 134/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2881\n",
      "Epoch 135/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.3004\n",
      "Epoch 136/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2848\n",
      "Epoch 137/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0786 - accuracy: 0.2982\n",
      "Epoch 138/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 139/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 140/150\n",
      "892/892 [==============================] - 0s 28us/step - loss: 0.0785 - accuracy: 0.2892\n",
      "Epoch 141/150\n",
      "892/892 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 142/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0786 - accuracy: 0.2758\n",
      "Epoch 143/150\n",
      "892/892 [==============================] - 0s 34us/step - loss: 0.0785 - accuracy: 0.2937\n",
      "Epoch 144/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0785 - accuracy: 0.2814\n",
      "Epoch 145/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0786 - accuracy: 0.2657\n",
      "Epoch 146/150\n",
      "892/892 [==============================] - 0s 27us/step - loss: 0.0786 - accuracy: 0.2948\n",
      "Epoch 147/150\n",
      "892/892 [==============================] - 0s 31us/step - loss: 0.0785 - accuracy: 0.2915\n",
      "Epoch 148/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0785 - accuracy: 0.2791\n",
      "Epoch 149/150\n",
      "892/892 [==============================] - 0s 30us/step - loss: 0.0785 - accuracy: 0.2870\n",
      "Epoch 150/150\n",
      "892/892 [==============================] - 0s 29us/step - loss: 0.0786 - accuracy: 0.2892\n",
      "460/460 [==============================] - 0s 339us/step\n",
      "Loss: 0.08\n",
      "Accuracy 0.33\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train= np.array(X_train)\n",
    "def createModel(i,j):\n",
    "    modelSearch = Sequential()\n",
    "    for nodes in range(0,j+1):\n",
    "        modelSearch.add(Dense(i, activation='sigmoid'))\n",
    "    modelSearch.add(Dense(10, activation='sigmoid'))\n",
    "    modelSearch.compile(\n",
    "      optimizer=opt,\n",
    "      loss='mean_squared_error',\n",
    "      metrics=['accuracy'],\n",
    "    )\n",
    "    modelSearch.fit(\n",
    "      X_train,\n",
    "      y_train,\n",
    "      epochs=150,\n",
    "      batch_size=100\n",
    "    )\n",
    "    loss, accuracy = modelSearch.evaluate(\n",
    "      X_test,\n",
    "      y_test\n",
    "    )\n",
    "    print('Loss: %.2f' % loss)\n",
    "    print(\"Accuracy %.2f\" %(accuracy))\n",
    "for i in range(1,4):\n",
    "    for j in range(3,13):\n",
    "        if(j%3 == 0):\n",
    "            createModel(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 285ms/step\n",
      "[[0.37621453 0.01155958 0.02268261 0.02045378 0.02897331 0.0926016\n",
      "  0.04460382 0.46551096 0.01148574 0.01743516]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#create np array for prediction\n",
    "x = np.array([[0.52], [0.47], [0.52], [0.23], [0.55], [0.03], [0.52], [0.39]])\n",
    "#using model for prediction, change model name for two seperate models!\n",
    "prediction = model.predict(x.T, verbose=1)\n",
    "print(prediction)\n",
    "#highest number is class, can find class from decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 802 samples, validate on 90 samples\n",
      "Epoch 1/150\n",
      "802/802 [==============================] - 0s 474us/step - loss: 2.2239 - accuracy: 0.2120 - val_loss: 5.5095 - val_accuracy: 0.1111\n",
      "Epoch 2/150\n",
      "802/802 [==============================] - 0s 45us/step - loss: 2.5369 - accuracy: 0.2556 - val_loss: 4.8999 - val_accuracy: 0.0556\n",
      "Epoch 3/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.3437 - accuracy: 0.2668 - val_loss: 6.0063 - val_accuracy: 0.1889\n",
      "Epoch 4/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.5316 - accuracy: 0.2905 - val_loss: 8.2845 - val_accuracy: 0.2778\n",
      "Epoch 5/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.8976 - accuracy: 0.2793 - val_loss: 3.9388 - val_accuracy: 0.0222\n",
      "Epoch 6/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.3948 - accuracy: 0.2668 - val_loss: 7.4615 - val_accuracy: 0.2778\n",
      "Epoch 7/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.7159 - accuracy: 0.2930 - val_loss: 3.8836 - val_accuracy: 0.2778\n",
      "Epoch 8/150\n",
      "802/802 [==============================] - 0s 50us/step - loss: 2.2955 - accuracy: 0.2718 - val_loss: 5.8016 - val_accuracy: 0.2778\n",
      "Epoch 9/150\n",
      "802/802 [==============================] - 0s 44us/step - loss: 2.5245 - accuracy: 0.3017 - val_loss: 7.6236 - val_accuracy: 0.1889\n",
      "Epoch 10/150\n",
      "802/802 [==============================] - 0s 50us/step - loss: 2.7976 - accuracy: 0.2718 - val_loss: 6.0514 - val_accuracy: 0.1111\n",
      "Epoch 11/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5839 - accuracy: 0.2656 - val_loss: 4.0361 - val_accuracy: 0.0111\n",
      "Epoch 12/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.4440 - accuracy: 0.2406 - val_loss: 3.1158 - val_accuracy: 0.1889\n",
      "Epoch 13/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2471 - accuracy: 0.2718 - val_loss: 3.0020 - val_accuracy: 0.2778\n",
      "Epoch 14/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.1522 - accuracy: 0.2830 - val_loss: 3.8638 - val_accuracy: 0.2778\n",
      "Epoch 15/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.3409 - accuracy: 0.2506 - val_loss: 4.4533 - val_accuracy: 0.0111\n",
      "Epoch 16/150\n",
      "802/802 [==============================] - 0s 47us/step - loss: 2.5551 - accuracy: 0.2232 - val_loss: 2.9724 - val_accuracy: 0.2778\n",
      "Epoch 17/150\n",
      "802/802 [==============================] - 0s 50us/step - loss: 2.6306 - accuracy: 0.2444 - val_loss: 3.1984 - val_accuracy: 0.1889\n",
      "Epoch 18/150\n",
      "802/802 [==============================] - 0s 50us/step - loss: 2.2917 - accuracy: 0.2431 - val_loss: 7.4723 - val_accuracy: 0.2778\n",
      "Epoch 19/150\n",
      "802/802 [==============================] - 0s 30us/step - loss: 2.5247 - accuracy: 0.3142 - val_loss: 3.4063 - val_accuracy: 0.1889\n",
      "Epoch 20/150\n",
      "802/802 [==============================] - 0s 50us/step - loss: 2.0795 - accuracy: 0.2943 - val_loss: 3.9314 - val_accuracy: 0.1111\n",
      "Epoch 21/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.5718 - accuracy: 0.2319 - val_loss: 4.4875 - val_accuracy: 0.1111\n",
      "Epoch 22/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.3022 - accuracy: 0.2793 - val_loss: 4.0372 - val_accuracy: 0.1111\n",
      "Epoch 23/150\n",
      "802/802 [==============================] - 0s 50us/step - loss: 3.4121 - accuracy: 0.2070 - val_loss: 4.1551 - val_accuracy: 0.1889\n",
      "Epoch 24/150\n",
      "802/802 [==============================] - 0s 49us/step - loss: 2.3735 - accuracy: 0.2693 - val_loss: 4.9146 - val_accuracy: 0.2778\n",
      "Epoch 25/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4632 - accuracy: 0.2656 - val_loss: 4.1981 - val_accuracy: 0.1889\n",
      "Epoch 26/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.3909 - accuracy: 0.2880 - val_loss: 8.1708 - val_accuracy: 0.2778\n",
      "Epoch 27/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.9563 - accuracy: 0.2930 - val_loss: 4.7168 - val_accuracy: 0.2778\n",
      "Epoch 28/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.4992 - accuracy: 0.2631 - val_loss: 7.2775 - val_accuracy: 0.2778\n",
      "Epoch 29/150\n",
      "802/802 [==============================] - 0s 46us/step - loss: 2.5489 - accuracy: 0.2805 - val_loss: 2.9927 - val_accuracy: 0.2778\n",
      "Epoch 30/150\n",
      "802/802 [==============================] - 0s 44us/step - loss: 2.4391 - accuracy: 0.2681 - val_loss: 7.9830 - val_accuracy: 0.2778\n",
      "Epoch 31/150\n",
      "802/802 [==============================] - 0s 45us/step - loss: 2.8478 - accuracy: 0.2868 - val_loss: 3.0889 - val_accuracy: 0.2778\n",
      "Epoch 32/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4607 - accuracy: 0.2594 - val_loss: 3.2564 - val_accuracy: 0.2778\n",
      "Epoch 33/150\n",
      "802/802 [==============================] - 0s 46us/step - loss: 2.3659 - accuracy: 0.2519 - val_loss: 4.2992 - val_accuracy: 0.1111\n",
      "Epoch 34/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.8641 - accuracy: 0.2369 - val_loss: 7.6829 - val_accuracy: 0.2778\n",
      "Epoch 35/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 3.0021 - accuracy: 0.2382 - val_loss: 2.9631 - val_accuracy: 0.1889\n",
      "Epoch 36/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.4075 - accuracy: 0.2369 - val_loss: 3.0788 - val_accuracy: 0.2778\n",
      "Epoch 37/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3137 - accuracy: 0.2905 - val_loss: 2.3148 - val_accuracy: 0.2778\n",
      "Epoch 38/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.0506 - accuracy: 0.2706 - val_loss: 7.6263 - val_accuracy: 0.2778\n",
      "Epoch 39/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.7262 - accuracy: 0.3042 - val_loss: 3.6836 - val_accuracy: 0.1889\n",
      "Epoch 40/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6753 - accuracy: 0.2693 - val_loss: 2.9361 - val_accuracy: 0.2778\n",
      "Epoch 41/150\n",
      "802/802 [==============================] - 0s 45us/step - loss: 2.2887 - accuracy: 0.2918 - val_loss: 4.4710 - val_accuracy: 0.1889\n",
      "Epoch 42/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.6147 - accuracy: 0.2556 - val_loss: 3.9998 - val_accuracy: 0.2778\n",
      "Epoch 43/150\n",
      "802/802 [==============================] - 0s 46us/step - loss: 2.4611 - accuracy: 0.2756 - val_loss: 4.8758 - val_accuracy: 0.1111\n",
      "Epoch 44/150\n",
      "802/802 [==============================] - 0s 49us/step - loss: 2.8260 - accuracy: 0.2157 - val_loss: 3.2694 - val_accuracy: 0.2778\n",
      "Epoch 45/150\n",
      "802/802 [==============================] - 0s 40us/step - loss: 2.5535 - accuracy: 0.2618 - val_loss: 4.2775 - val_accuracy: 0.2778\n",
      "Epoch 46/150\n",
      "802/802 [==============================] - 0s 45us/step - loss: 2.2275 - accuracy: 0.2993 - val_loss: 3.2164 - val_accuracy: 0.2778\n",
      "Epoch 47/150\n",
      "802/802 [==============================] - 0s 49us/step - loss: 2.2266 - accuracy: 0.2943 - val_loss: 4.2641 - val_accuracy: 0.2778\n",
      "Epoch 48/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3679 - accuracy: 0.2781 - val_loss: 2.6933 - val_accuracy: 0.2778\n",
      "Epoch 49/150\n",
      "802/802 [==============================] - 0s 42us/step - loss: 2.1716 - accuracy: 0.2706 - val_loss: 8.5524 - val_accuracy: 0.1889\n",
      "Epoch 50/150\n",
      "802/802 [==============================] - 0s 41us/step - loss: 2.7199 - accuracy: 0.2968 - val_loss: 3.6389 - val_accuracy: 0.1889\n",
      "Epoch 51/150\n",
      "802/802 [==============================] - 0s 40us/step - loss: 2.5021 - accuracy: 0.2781 - val_loss: 4.3423 - val_accuracy: 0.0556\n",
      "Epoch 52/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6090 - accuracy: 0.2357 - val_loss: 4.8156 - val_accuracy: 0.1889\n",
      "Epoch 53/150\n",
      "802/802 [==============================] - 0s 45us/step - loss: 2.6804 - accuracy: 0.2556 - val_loss: 5.4783 - val_accuracy: 0.1889\n",
      "Epoch 54/150\n",
      "802/802 [==============================] - 0s 44us/step - loss: 2.7956 - accuracy: 0.2456 - val_loss: 3.1057 - val_accuracy: 0.2778\n",
      "Epoch 55/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.2034 - accuracy: 0.2781 - val_loss: 2.7739 - val_accuracy: 0.2778\n",
      "Epoch 56/150\n",
      "802/802 [==============================] - 0s 50us/step - loss: 2.2922 - accuracy: 0.2531 - val_loss: 3.0936 - val_accuracy: 0.1889\n",
      "Epoch 57/150\n",
      "802/802 [==============================] - 0s 49us/step - loss: 2.1426 - accuracy: 0.2843 - val_loss: 5.6421 - val_accuracy: 0.1111\n",
      "Epoch 58/150\n",
      "802/802 [==============================] - 0s 39us/step - loss: 2.4837 - accuracy: 0.2656 - val_loss: 2.8438 - val_accuracy: 0.2778\n",
      "Epoch 59/150\n",
      "802/802 [==============================] - 0s 42us/step - loss: 2.3128 - accuracy: 0.2980 - val_loss: 7.6465 - val_accuracy: 0.2778\n",
      "Epoch 60/150\n",
      "802/802 [==============================] - 0s 41us/step - loss: 2.7938 - accuracy: 0.2706 - val_loss: 4.0245 - val_accuracy: 0.1889\n",
      "Epoch 61/150\n",
      "802/802 [==============================] - 0s 42us/step - loss: 2.4926 - accuracy: 0.2918 - val_loss: 3.9267 - val_accuracy: 0.1111\n",
      "Epoch 62/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 2.4575 - accuracy: 0.2805 - val_loss: 7.6704 - val_accuracy: 0.2778\n",
      "Epoch 63/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 2.6709 - accuracy: 0.2880 - val_loss: 3.3183 - val_accuracy: 0.2778\n",
      "Epoch 64/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 2.8787 - accuracy: 0.2481 - val_loss: 3.2438 - val_accuracy: 0.1889\n",
      "Epoch 65/150\n",
      "802/802 [==============================] - 0s 39us/step - loss: 2.5957 - accuracy: 0.2556 - val_loss: 5.7783 - val_accuracy: 0.2778\n",
      "Epoch 66/150\n",
      "802/802 [==============================] - 0s 41us/step - loss: 2.6185 - accuracy: 0.2955 - val_loss: 3.8967 - val_accuracy: 0.1889\n",
      "Epoch 67/150\n",
      "802/802 [==============================] - 0s 39us/step - loss: 2.4688 - accuracy: 0.2706 - val_loss: 3.1579 - val_accuracy: 0.1889\n",
      "Epoch 68/150\n",
      "802/802 [==============================] - 0s 41us/step - loss: 2.2818 - accuracy: 0.2706 - val_loss: 7.9355 - val_accuracy: 0.2778\n",
      "Epoch 69/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 2.7636 - accuracy: 0.2768 - val_loss: 4.2176 - val_accuracy: 0.2778\n",
      "Epoch 70/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 2.5818 - accuracy: 0.2756 - val_loss: 9.7464 - val_accuracy: 0.0556\n",
      "Epoch 71/150\n",
      "802/802 [==============================] - 0s 40us/step - loss: 3.2640 - accuracy: 0.2307 - val_loss: 5.1945 - val_accuracy: 0.1111\n",
      "Epoch 72/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 2.5994 - accuracy: 0.2481 - val_loss: 2.9276 - val_accuracy: 0.1889\n",
      "Epoch 73/150\n",
      "802/802 [==============================] - 0s 39us/step - loss: 2.2330 - accuracy: 0.2643 - val_loss: 3.8726 - val_accuracy: 0.2778\n",
      "Epoch 74/150\n",
      "802/802 [==============================] - 0s 41us/step - loss: 2.2884 - accuracy: 0.2905 - val_loss: 3.9814 - val_accuracy: 0.0222\n",
      "Epoch 75/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 2.4960 - accuracy: 0.2444 - val_loss: 4.2242 - val_accuracy: 0.1889\n",
      "Epoch 76/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 2.3764 - accuracy: 0.2519 - val_loss: 4.1215 - val_accuracy: 0.0556\n",
      "Epoch 77/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 2.6101 - accuracy: 0.2369 - val_loss: 4.1181 - val_accuracy: 0.0222\n",
      "Epoch 78/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 2.4181 - accuracy: 0.2469 - val_loss: 3.0072 - val_accuracy: 0.2778\n",
      "Epoch 79/150\n",
      "802/802 [==============================] - 0s 41us/step - loss: 2.3725 - accuracy: 0.2569 - val_loss: 3.5837 - val_accuracy: 0.1889\n",
      "Epoch 80/150\n",
      "802/802 [==============================] - 0s 39us/step - loss: 2.4658 - accuracy: 0.2943 - val_loss: 4.0052 - val_accuracy: 0.1111\n",
      "Epoch 81/150\n",
      "802/802 [==============================] - 0s 37us/step - loss: 2.5023 - accuracy: 0.2768 - val_loss: 5.9653 - val_accuracy: 0.2778\n",
      "Epoch 82/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 2.3768 - accuracy: 0.2618 - val_loss: 4.9691 - val_accuracy: 0.1111\n",
      "Epoch 83/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 2.9387 - accuracy: 0.2357 - val_loss: 3.7648 - val_accuracy: 0.1889\n",
      "Epoch 84/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 2.6663 - accuracy: 0.2606 - val_loss: 4.4189 - val_accuracy: 0.1111\n",
      "Epoch 85/150\n",
      "802/802 [==============================] - 0s 40us/step - loss: 2.2832 - accuracy: 0.2681 - val_loss: 3.2890 - val_accuracy: 0.2778\n",
      "Epoch 86/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 2.4751 - accuracy: 0.2718 - val_loss: 3.9526 - val_accuracy: 0.0111\n",
      "Epoch 87/150\n",
      "802/802 [==============================] - 0s 27us/step - loss: 2.3019 - accuracy: 0.2307 - val_loss: 6.1189 - val_accuracy: 0.2778\n",
      "Epoch 88/150\n",
      "802/802 [==============================] - 0s 37us/step - loss: 2.6939 - accuracy: 0.2793 - val_loss: 6.3886 - val_accuracy: 0.2778\n",
      "Epoch 89/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 2.5198 - accuracy: 0.2993 - val_loss: 3.0961 - val_accuracy: 0.1889\n",
      "Epoch 90/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 2.1894 - accuracy: 0.2718 - val_loss: 3.3516 - val_accuracy: 0.2778\n",
      "Epoch 91/150\n",
      "802/802 [==============================] - 0s 40us/step - loss: 2.4575 - accuracy: 0.2706 - val_loss: 4.4995 - val_accuracy: 0.2778\n",
      "Epoch 92/150\n",
      "802/802 [==============================] - 0s 29us/step - loss: 2.3344 - accuracy: 0.2905 - val_loss: 3.6058 - val_accuracy: 0.1889\n",
      "Epoch 93/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 2.6246 - accuracy: 0.2481 - val_loss: 4.4587 - val_accuracy: 0.2778\n",
      "Epoch 94/150\n",
      "802/802 [==============================] - 0s 37us/step - loss: 2.4616 - accuracy: 0.2569 - val_loss: 5.0274 - val_accuracy: 0.2778\n",
      "Epoch 95/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 2.5245 - accuracy: 0.2544 - val_loss: 5.1336 - val_accuracy: 0.2778\n",
      "Epoch 96/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 2.3856 - accuracy: 0.3042 - val_loss: 3.5994 - val_accuracy: 0.2778\n",
      "Epoch 97/150\n",
      "802/802 [==============================] - 0s 40us/step - loss: 2.1918 - accuracy: 0.2731 - val_loss: 8.0648 - val_accuracy: 0.2778\n",
      "Epoch 98/150\n",
      "802/802 [==============================] - 0s 30us/step - loss: 2.7880 - accuracy: 0.2756 - val_loss: 7.5523 - val_accuracy: 0.2778\n",
      "Epoch 99/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 3.0772 - accuracy: 0.2431 - val_loss: 4.5461 - val_accuracy: 0.1111\n",
      "Epoch 100/150\n",
      "802/802 [==============================] - 0s 42us/step - loss: 2.6127 - accuracy: 0.2569 - val_loss: 4.5129 - val_accuracy: 0.2778\n",
      "Epoch 101/150\n",
      "802/802 [==============================] - 0s 30us/step - loss: 2.4782 - accuracy: 0.2219 - val_loss: 4.5979 - val_accuracy: 0.1111\n",
      "Epoch 102/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 2.7587 - accuracy: 0.2282 - val_loss: 4.3093 - val_accuracy: 0.1111\n",
      "Epoch 103/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 2.9169 - accuracy: 0.2556 - val_loss: 3.6205 - val_accuracy: 0.2778\n",
      "Epoch 104/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 2.3628 - accuracy: 0.2781 - val_loss: 3.3715 - val_accuracy: 0.2778\n",
      "Epoch 105/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 2.3197 - accuracy: 0.2743 - val_loss: 2.8293 - val_accuracy: 0.2778\n",
      "Epoch 106/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 2.5160 - accuracy: 0.2681 - val_loss: 6.5663 - val_accuracy: 0.2778\n",
      "Epoch 107/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 2.6626 - accuracy: 0.3055 - val_loss: 4.4759 - val_accuracy: 0.2778\n",
      "Epoch 108/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 2.4074 - accuracy: 0.2955 - val_loss: 4.2068 - val_accuracy: 0.1889\n",
      "Epoch 109/150\n",
      "802/802 [==============================] - 0s 37us/step - loss: 2.2365 - accuracy: 0.2693 - val_loss: 4.6076 - val_accuracy: 0.2778\n",
      "Epoch 110/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 2.4520 - accuracy: 0.2631 - val_loss: 4.5817 - val_accuracy: 0.1111\n",
      "Epoch 111/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 2.7768 - accuracy: 0.2269 - val_loss: 5.1039 - val_accuracy: 0.2778\n",
      "Epoch 112/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 2.7944 - accuracy: 0.2344 - val_loss: 4.5944 - val_accuracy: 0.1889\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 41us/step - loss: 2.5016 - accuracy: 0.2681 - val_loss: 7.1125 - val_accuracy: 0.2778\n",
      "Epoch 114/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 2.7435 - accuracy: 0.3055 - val_loss: 7.7729 - val_accuracy: 0.2778\n",
      "Epoch 115/150\n",
      "802/802 [==============================] - 0s 40us/step - loss: 2.9074 - accuracy: 0.2905 - val_loss: 4.3011 - val_accuracy: 0.0111\n",
      "Epoch 116/150\n",
      "802/802 [==============================] - 0s 40us/step - loss: 2.4027 - accuracy: 0.2606 - val_loss: 4.6619 - val_accuracy: 0.0333\n",
      "Epoch 117/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 2.5668 - accuracy: 0.2382 - val_loss: 2.7810 - val_accuracy: 0.2778\n",
      "Epoch 118/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 2.3217 - accuracy: 0.2868 - val_loss: 3.0635 - val_accuracy: 0.2778\n",
      "Epoch 119/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 2.5900 - accuracy: 0.2643 - val_loss: 4.5129 - val_accuracy: 0.2778\n",
      "Epoch 120/150\n",
      "802/802 [==============================] - 0s 37us/step - loss: 2.3689 - accuracy: 0.2768 - val_loss: 3.8530 - val_accuracy: 0.1889\n",
      "Epoch 121/150\n",
      "802/802 [==============================] - 0s 46us/step - loss: 2.7176 - accuracy: 0.2556 - val_loss: 2.9560 - val_accuracy: 0.1889\n",
      "Epoch 122/150\n",
      "802/802 [==============================] - 0s 40us/step - loss: 2.2954 - accuracy: 0.2731 - val_loss: 9.1252 - val_accuracy: 0.1889\n",
      "Epoch 123/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 2.9130 - accuracy: 0.2868 - val_loss: 4.0541 - val_accuracy: 0.1889\n",
      "Epoch 124/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 2.5773 - accuracy: 0.2556 - val_loss: 3.0967 - val_accuracy: 0.2778\n",
      "Epoch 125/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 2.4452 - accuracy: 0.2905 - val_loss: 2.9302 - val_accuracy: 0.2778\n",
      "Epoch 126/150\n",
      "802/802 [==============================] - 0s 40us/step - loss: 2.7641 - accuracy: 0.2681 - val_loss: 4.4461 - val_accuracy: 0.0556\n",
      "Epoch 127/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 2.9199 - accuracy: 0.2431 - val_loss: 4.3431 - val_accuracy: 0.1111\n",
      "Epoch 128/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 2.4736 - accuracy: 0.2706 - val_loss: 3.0268 - val_accuracy: 0.2778\n",
      "Epoch 129/150\n",
      "802/802 [==============================] - 0s 34us/step - loss: 2.5901 - accuracy: 0.2731 - val_loss: 8.1086 - val_accuracy: 0.1889\n",
      "Epoch 130/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 2.9958 - accuracy: 0.2631 - val_loss: 7.3038 - val_accuracy: 0.2778\n",
      "Epoch 131/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 2.7248 - accuracy: 0.2930 - val_loss: 3.1181 - val_accuracy: 0.2778\n",
      "Epoch 132/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 2.4029 - accuracy: 0.2955 - val_loss: 5.7045 - val_accuracy: 0.1111\n",
      "Epoch 133/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 2.5919 - accuracy: 0.2706 - val_loss: 5.6291 - val_accuracy: 0.0111\n",
      "Epoch 134/150\n",
      "802/802 [==============================] - 0s 32us/step - loss: 2.4354 - accuracy: 0.2818 - val_loss: 3.2867 - val_accuracy: 0.2778\n",
      "Epoch 135/150\n",
      "802/802 [==============================] - 0s 31us/step - loss: 2.5253 - accuracy: 0.2544 - val_loss: 4.0773 - val_accuracy: 0.0556\n",
      "Epoch 136/150\n",
      "802/802 [==============================] - 0s 37us/step - loss: 2.5087 - accuracy: 0.2394 - val_loss: 4.0748 - val_accuracy: 0.1111\n",
      "Epoch 137/150\n",
      "802/802 [==============================] - 0s 37us/step - loss: 2.6244 - accuracy: 0.2494 - val_loss: 3.8005 - val_accuracy: 0.1889\n",
      "Epoch 138/150\n",
      "802/802 [==============================] - 0s 37us/step - loss: 2.6399 - accuracy: 0.2519 - val_loss: 8.4910 - val_accuracy: 0.2778\n",
      "Epoch 139/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 2.8617 - accuracy: 0.3017 - val_loss: 4.0458 - val_accuracy: 0.0222\n",
      "Epoch 140/150\n",
      "802/802 [==============================] - 0s 40us/step - loss: 2.4373 - accuracy: 0.2419 - val_loss: 7.8828 - val_accuracy: 0.2778\n",
      "Epoch 141/150\n",
      "802/802 [==============================] - 0s 39us/step - loss: 2.7477 - accuracy: 0.3067 - val_loss: 3.5552 - val_accuracy: 0.1889\n",
      "Epoch 142/150\n",
      "802/802 [==============================] - 0s 30us/step - loss: 2.6659 - accuracy: 0.2781 - val_loss: 4.7933 - val_accuracy: 0.1889\n",
      "Epoch 143/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 2.2673 - accuracy: 0.2893 - val_loss: 3.1021 - val_accuracy: 0.1889\n",
      "Epoch 144/150\n",
      "802/802 [==============================] - 0s 39us/step - loss: 2.3827 - accuracy: 0.2718 - val_loss: 3.1934 - val_accuracy: 0.2778\n",
      "Epoch 145/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 2.3871 - accuracy: 0.2880 - val_loss: 4.1073 - val_accuracy: 0.1889\n",
      "Epoch 146/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 2.5089 - accuracy: 0.2818 - val_loss: 3.5311 - val_accuracy: 0.2778\n",
      "Epoch 147/150\n",
      "802/802 [==============================] - 0s 36us/step - loss: 2.4106 - accuracy: 0.2781 - val_loss: 5.2242 - val_accuracy: 0.1889\n",
      "Epoch 148/150\n",
      "802/802 [==============================] - 0s 35us/step - loss: 2.4947 - accuracy: 0.2594 - val_loss: 5.4342 - val_accuracy: 0.2778\n",
      "Epoch 149/150\n",
      "802/802 [==============================] - 0s 40us/step - loss: 2.5296 - accuracy: 0.3042 - val_loss: 4.1905 - val_accuracy: 0.1111\n",
      "Epoch 150/150\n",
      "802/802 [==============================] - 0s 29us/step - loss: 2.3116 - accuracy: 0.2718 - val_loss: 5.2478 - val_accuracy: 0.1889\n",
      "460/460 [==============================] - 0s 57us/step\n",
      "0.15000000596046448\n",
      "Train on 802 samples, validate on 90 samples\n",
      "Epoch 1/150\n",
      "802/802 [==============================] - 0s 534us/step - loss: 2.0777 - accuracy: 0.2731 - val_loss: 3.0449 - val_accuracy: 0.1889\n",
      "Epoch 2/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3086 - accuracy: 0.2681 - val_loss: 4.3433 - val_accuracy: 0.1111\n",
      "Epoch 3/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4865 - accuracy: 0.2706 - val_loss: 2.8676 - val_accuracy: 0.2778\n",
      "Epoch 4/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.1132 - accuracy: 0.3005 - val_loss: 5.7159 - val_accuracy: 0.0111\n",
      "Epoch 5/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5104 - accuracy: 0.2793 - val_loss: 7.7107 - val_accuracy: 0.2778\n",
      "Epoch 6/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.7284 - accuracy: 0.3005 - val_loss: 5.5493 - val_accuracy: 0.2778\n",
      "Epoch 7/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4450 - accuracy: 0.2855 - val_loss: 3.0776 - val_accuracy: 0.2778\n",
      "Epoch 8/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4403 - accuracy: 0.2519 - val_loss: 5.0742 - val_accuracy: 0.0556\n",
      "Epoch 9/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4933 - accuracy: 0.2506 - val_loss: 3.9017 - val_accuracy: 0.1111\n",
      "Epoch 10/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.8441 - accuracy: 0.2431 - val_loss: 4.0274 - val_accuracy: 0.1111\n",
      "Epoch 11/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 3.1285 - accuracy: 0.2269 - val_loss: 4.9013 - val_accuracy: 0.2778\n",
      "Epoch 12/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4285 - accuracy: 0.2830 - val_loss: 2.5741 - val_accuracy: 0.2778\n",
      "Epoch 13/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.0910 - accuracy: 0.3042 - val_loss: 3.1212 - val_accuracy: 0.2778\n",
      "Epoch 14/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5233 - accuracy: 0.2556 - val_loss: 7.2033 - val_accuracy: 0.2778\n",
      "Epoch 15/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5531 - accuracy: 0.2943 - val_loss: 4.1857 - val_accuracy: 0.0556\n",
      "Epoch 16/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.3882 - accuracy: 0.2282 - val_loss: 4.5756 - val_accuracy: 0.0222\n",
      "Epoch 17/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.4881 - accuracy: 0.2531 - val_loss: 4.4064 - val_accuracy: 0.1111\n",
      "Epoch 18/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5925 - accuracy: 0.2693 - val_loss: 4.8233 - val_accuracy: 0.2778\n",
      "Epoch 19/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.3781 - accuracy: 0.2843 - val_loss: 3.6675 - val_accuracy: 0.1889\n",
      "Epoch 20/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4591 - accuracy: 0.2581 - val_loss: 4.8734 - val_accuracy: 0.1111\n",
      "Epoch 21/150\n",
      "802/802 [==============================] - 0s 49us/step - loss: 2.3936 - accuracy: 0.2731 - val_loss: 8.8618 - val_accuracy: 0.1889\n",
      "Epoch 22/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.9218 - accuracy: 0.2830 - val_loss: 3.9936 - val_accuracy: 0.0556\n",
      "Epoch 23/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.8216 - accuracy: 0.2170 - val_loss: 4.9332 - val_accuracy: 0.0222\n",
      "Epoch 24/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.3657 - accuracy: 0.2481 - val_loss: 2.2668 - val_accuracy: 0.2778\n",
      "Epoch 25/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.3943 - accuracy: 0.2506 - val_loss: 4.6032 - val_accuracy: 0.1111\n",
      "Epoch 26/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.8758 - accuracy: 0.2369 - val_loss: 6.0974 - val_accuracy: 0.2778\n",
      "Epoch 27/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4576 - accuracy: 0.3030 - val_loss: 3.4676 - val_accuracy: 0.1889\n",
      "Epoch 28/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.5063 - accuracy: 0.2656 - val_loss: 4.2923 - val_accuracy: 0.2778\n",
      "Epoch 29/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.2542 - accuracy: 0.3055 - val_loss: 4.7594 - val_accuracy: 0.2778\n",
      "Epoch 30/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5345 - accuracy: 0.2419 - val_loss: 6.2801 - val_accuracy: 0.2778\n",
      "Epoch 31/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.6695 - accuracy: 0.2756 - val_loss: 4.4958 - val_accuracy: 0.1111\n",
      "Epoch 32/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.7263 - accuracy: 0.2057 - val_loss: 2.4107 - val_accuracy: 0.2778\n",
      "Epoch 33/150\n",
      "802/802 [==============================] - 0s 49us/step - loss: 2.4247 - accuracy: 0.2419 - val_loss: 3.0484 - val_accuracy: 0.2778\n",
      "Epoch 34/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5596 - accuracy: 0.2706 - val_loss: 4.1063 - val_accuracy: 0.2778\n",
      "Epoch 35/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.1210 - accuracy: 0.3217 - val_loss: 7.6849 - val_accuracy: 0.2778\n",
      "Epoch 36/150\n",
      "802/802 [==============================] - 0s 96us/step - loss: 2.8581 - accuracy: 0.2743 - val_loss: 4.5839 - val_accuracy: 0.2778\n",
      "Epoch 37/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4762 - accuracy: 0.2830 - val_loss: 4.7187 - val_accuracy: 0.1889\n",
      "Epoch 38/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.9074 - accuracy: 0.2307 - val_loss: 4.7000 - val_accuracy: 0.0111\n",
      "Epoch 39/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.7906 - accuracy: 0.2032 - val_loss: 5.6068 - val_accuracy: 0.1111\n",
      "Epoch 40/150\n",
      "802/802 [==============================] - 0s 49us/step - loss: 2.3552 - accuracy: 0.2581 - val_loss: 5.5762 - val_accuracy: 0.2778\n",
      "Epoch 41/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6476 - accuracy: 0.2631 - val_loss: 4.0681 - val_accuracy: 0.0222\n",
      "Epoch 42/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4631 - accuracy: 0.2307 - val_loss: 5.9959 - val_accuracy: 0.1111\n",
      "Epoch 43/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6679 - accuracy: 0.2494 - val_loss: 4.8688 - val_accuracy: 0.1889\n",
      "Epoch 44/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5133 - accuracy: 0.2506 - val_loss: 4.2718 - val_accuracy: 0.1111\n",
      "Epoch 45/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4416 - accuracy: 0.2656 - val_loss: 4.6354 - val_accuracy: 0.2778\n",
      "Epoch 46/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.6188 - accuracy: 0.2494 - val_loss: 6.4034 - val_accuracy: 0.2778\n",
      "Epoch 47/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6795 - accuracy: 0.2731 - val_loss: 5.8916 - val_accuracy: 0.2778\n",
      "Epoch 48/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4626 - accuracy: 0.3055 - val_loss: 2.8625 - val_accuracy: 0.2778\n",
      "Epoch 49/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5845 - accuracy: 0.2481 - val_loss: 4.1037 - val_accuracy: 0.0556\n",
      "Epoch 50/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4095 - accuracy: 0.2382 - val_loss: 6.1295 - val_accuracy: 0.2778\n",
      "Epoch 51/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5417 - accuracy: 0.3117 - val_loss: 7.3812 - val_accuracy: 0.2778\n",
      "Epoch 52/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6302 - accuracy: 0.3067 - val_loss: 4.7643 - val_accuracy: 0.2778\n",
      "Epoch 53/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4520 - accuracy: 0.2781 - val_loss: 4.4355 - val_accuracy: 0.2778\n",
      "Epoch 54/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3859 - accuracy: 0.2706 - val_loss: 3.7733 - val_accuracy: 0.1889\n",
      "Epoch 55/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.6145 - accuracy: 0.2519 - val_loss: 3.3574 - val_accuracy: 0.1889\n",
      "Epoch 56/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.2170 - accuracy: 0.2693 - val_loss: 3.2504 - val_accuracy: 0.1889\n",
      "Epoch 57/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4343 - accuracy: 0.2880 - val_loss: 4.1227 - val_accuracy: 0.1111\n",
      "Epoch 58/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.7337 - accuracy: 0.2394 - val_loss: 3.6207 - val_accuracy: 0.1889\n",
      "Epoch 59/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6016 - accuracy: 0.2656 - val_loss: 4.7090 - val_accuracy: 0.1111\n",
      "Epoch 60/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.3812 - accuracy: 0.2830 - val_loss: 4.0904 - val_accuracy: 0.1111\n",
      "Epoch 61/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.7843 - accuracy: 0.2456 - val_loss: 4.3377 - val_accuracy: 0.0111\n",
      "Epoch 62/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5139 - accuracy: 0.2431 - val_loss: 3.0939 - val_accuracy: 0.2778\n",
      "Epoch 63/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5099 - accuracy: 0.2706 - val_loss: 3.7848 - val_accuracy: 0.1111\n",
      "Epoch 64/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6464 - accuracy: 0.2594 - val_loss: 4.9715 - val_accuracy: 0.2778\n",
      "Epoch 65/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4857 - accuracy: 0.2369 - val_loss: 7.4072 - val_accuracy: 0.2778\n",
      "Epoch 66/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.7927 - accuracy: 0.2880 - val_loss: 4.4954 - val_accuracy: 0.2778\n",
      "Epoch 67/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5006 - accuracy: 0.2830 - val_loss: 3.0717 - val_accuracy: 0.2778\n",
      "Epoch 68/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3364 - accuracy: 0.2793 - val_loss: 7.9033 - val_accuracy: 0.1889\n",
      "Epoch 69/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.7260 - accuracy: 0.2793 - val_loss: 5.3922 - val_accuracy: 0.2778\n",
      "Epoch 70/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.7349 - accuracy: 0.2718 - val_loss: 6.8299 - val_accuracy: 0.2778\n",
      "Epoch 71/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5793 - accuracy: 0.2980 - val_loss: 3.7876 - val_accuracy: 0.1889\n",
      "Epoch 72/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.6451 - accuracy: 0.2556 - val_loss: 3.8808 - val_accuracy: 0.2778\n",
      "Epoch 73/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5652 - accuracy: 0.2594 - val_loss: 4.6565 - val_accuracy: 0.2778\n",
      "Epoch 74/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 64us/step - loss: 2.5709 - accuracy: 0.2781 - val_loss: 4.3667 - val_accuracy: 0.0333\n",
      "Epoch 75/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5252 - accuracy: 0.2444 - val_loss: 2.8725 - val_accuracy: 0.2778\n",
      "Epoch 76/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4574 - accuracy: 0.2731 - val_loss: 4.3229 - val_accuracy: 0.1111\n",
      "Epoch 77/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 3.2276 - accuracy: 0.2357 - val_loss: 7.8258 - val_accuracy: 0.2778\n",
      "Epoch 78/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.7100 - accuracy: 0.3092 - val_loss: 3.8845 - val_accuracy: 0.0222\n",
      "Epoch 79/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2990 - accuracy: 0.2431 - val_loss: 7.5967 - val_accuracy: 0.2778\n",
      "Epoch 80/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.9223 - accuracy: 0.2768 - val_loss: 4.7251 - val_accuracy: 0.2778\n",
      "Epoch 81/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.6464 - accuracy: 0.2594 - val_loss: 7.4625 - val_accuracy: 0.1889\n",
      "Epoch 82/150\n",
      "802/802 [==============================] - 0s 50us/step - loss: 2.7736 - accuracy: 0.2606 - val_loss: 4.0064 - val_accuracy: 0.2778\n",
      "Epoch 83/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.3079 - accuracy: 0.2930 - val_loss: 8.1824 - val_accuracy: 0.1889\n",
      "Epoch 84/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.8742 - accuracy: 0.2855 - val_loss: 4.7873 - val_accuracy: 0.1111\n",
      "Epoch 85/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.3626 - accuracy: 0.2768 - val_loss: 4.0174 - val_accuracy: 0.0333\n",
      "Epoch 86/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.4037 - accuracy: 0.2456 - val_loss: 3.5643 - val_accuracy: 0.1889\n",
      "Epoch 87/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.4346 - accuracy: 0.2805 - val_loss: 2.8330 - val_accuracy: 0.2778\n",
      "Epoch 88/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4694 - accuracy: 0.2456 - val_loss: 4.0889 - val_accuracy: 0.1111\n",
      "Epoch 89/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 3.1222 - accuracy: 0.2344 - val_loss: 3.0144 - val_accuracy: 0.2778\n",
      "Epoch 90/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6325 - accuracy: 0.2618 - val_loss: 3.5595 - val_accuracy: 0.1889\n",
      "Epoch 91/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.6588 - accuracy: 0.2805 - val_loss: 3.9877 - val_accuracy: 0.1111\n",
      "Epoch 92/150\n",
      "802/802 [==============================] - 0s 49us/step - loss: 2.9664 - accuracy: 0.2618 - val_loss: 7.8503 - val_accuracy: 0.2778\n",
      "Epoch 93/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.7050 - accuracy: 0.3105 - val_loss: 3.1684 - val_accuracy: 0.2778\n",
      "Epoch 94/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6159 - accuracy: 0.2693 - val_loss: 5.1397 - val_accuracy: 0.2778\n",
      "Epoch 95/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.5388 - accuracy: 0.2681 - val_loss: 4.6160 - val_accuracy: 0.1111\n",
      "Epoch 96/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.3557 - accuracy: 0.2843 - val_loss: 3.2206 - val_accuracy: 0.2778\n",
      "Epoch 97/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.3497 - accuracy: 0.2893 - val_loss: 6.1767 - val_accuracy: 0.2778\n",
      "Epoch 98/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5583 - accuracy: 0.2943 - val_loss: 4.1298 - val_accuracy: 0.1111\n",
      "Epoch 99/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5505 - accuracy: 0.2681 - val_loss: 4.0249 - val_accuracy: 0.0222\n",
      "Epoch 100/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.2051 - accuracy: 0.2781 - val_loss: 3.1601 - val_accuracy: 0.2778\n",
      "Epoch 101/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.5632 - accuracy: 0.2643 - val_loss: 6.5194 - val_accuracy: 0.1889\n",
      "Epoch 102/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.8558 - accuracy: 0.2120 - val_loss: 3.4703 - val_accuracy: 0.1889\n",
      "Epoch 103/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.3988 - accuracy: 0.2594 - val_loss: 3.4208 - val_accuracy: 0.1889\n",
      "Epoch 104/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.9169 - accuracy: 0.2157 - val_loss: 5.2681 - val_accuracy: 0.0222\n",
      "Epoch 105/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3171 - accuracy: 0.2394 - val_loss: 3.9682 - val_accuracy: 0.0556\n",
      "Epoch 106/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4720 - accuracy: 0.2569 - val_loss: 3.5615 - val_accuracy: 0.2778\n",
      "Epoch 107/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6279 - accuracy: 0.2319 - val_loss: 6.8577 - val_accuracy: 0.2778\n",
      "Epoch 108/150\n",
      "802/802 [==============================] - 0s 50us/step - loss: 2.4955 - accuracy: 0.2793 - val_loss: 9.3053 - val_accuracy: 0.1889\n",
      "Epoch 109/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 3.1927 - accuracy: 0.2581 - val_loss: 3.6915 - val_accuracy: 0.1889\n",
      "Epoch 110/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4849 - accuracy: 0.2431 - val_loss: 4.3806 - val_accuracy: 0.0111\n",
      "Epoch 111/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4071 - accuracy: 0.2519 - val_loss: 8.0784 - val_accuracy: 0.2778\n",
      "Epoch 112/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.8556 - accuracy: 0.2993 - val_loss: 4.3903 - val_accuracy: 0.0556\n",
      "Epoch 113/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.2434 - accuracy: 0.2843 - val_loss: 3.9268 - val_accuracy: 0.0333\n",
      "Epoch 114/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4922 - accuracy: 0.2369 - val_loss: 7.3792 - val_accuracy: 0.2778\n",
      "Epoch 115/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6981 - accuracy: 0.2968 - val_loss: 3.0111 - val_accuracy: 0.2778\n",
      "Epoch 116/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.2290 - accuracy: 0.2743 - val_loss: 6.8741 - val_accuracy: 0.2778\n",
      "Epoch 117/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.6860 - accuracy: 0.2668 - val_loss: 3.0508 - val_accuracy: 0.2778\n",
      "Epoch 118/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.2710 - accuracy: 0.2793 - val_loss: 7.3146 - val_accuracy: 0.2778\n",
      "Epoch 119/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.6472 - accuracy: 0.3055 - val_loss: 4.1612 - val_accuracy: 0.1111\n",
      "Epoch 120/150\n",
      "802/802 [==============================] - 0s 49us/step - loss: 2.2834 - accuracy: 0.2955 - val_loss: 3.7875 - val_accuracy: 0.1889\n",
      "Epoch 121/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4450 - accuracy: 0.2618 - val_loss: 5.1816 - val_accuracy: 0.1889\n",
      "Epoch 122/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5777 - accuracy: 0.2805 - val_loss: 3.9342 - val_accuracy: 0.0222\n",
      "Epoch 123/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6909 - accuracy: 0.2170 - val_loss: 7.2698 - val_accuracy: 0.2778\n",
      "Epoch 124/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.8726 - accuracy: 0.2606 - val_loss: 4.1868 - val_accuracy: 0.0333\n",
      "Epoch 125/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.2159 - accuracy: 0.2095 - val_loss: 7.7393 - val_accuracy: 0.2778\n",
      "Epoch 126/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 3.0235 - accuracy: 0.2406 - val_loss: 4.2384 - val_accuracy: 0.2778\n",
      "Epoch 127/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6156 - accuracy: 0.2631 - val_loss: 5.5288 - val_accuracy: 0.0333\n",
      "Epoch 128/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.7317 - accuracy: 0.2207 - val_loss: 3.8565 - val_accuracy: 0.1111\n",
      "Epoch 129/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6852 - accuracy: 0.2406 - val_loss: 3.8821 - val_accuracy: 0.1889\n",
      "Epoch 130/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.9070 - accuracy: 0.2282 - val_loss: 5.3487 - val_accuracy: 0.1889\n",
      "Epoch 131/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.6056 - accuracy: 0.2706 - val_loss: 2.9405 - val_accuracy: 0.2778\n",
      "Epoch 132/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.5458 - accuracy: 0.2618 - val_loss: 8.0912 - val_accuracy: 0.2778\n",
      "Epoch 133/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 3.1264 - accuracy: 0.2506 - val_loss: 6.3782 - val_accuracy: 0.2778\n",
      "Epoch 134/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.9765 - accuracy: 0.2556 - val_loss: 3.6708 - val_accuracy: 0.1889\n",
      "Epoch 135/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.5069 - accuracy: 0.2706 - val_loss: 3.3652 - val_accuracy: 0.2778\n",
      "Epoch 136/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.4918 - accuracy: 0.2606 - val_loss: 2.3052 - val_accuracy: 0.2778\n",
      "Epoch 137/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.1419 - accuracy: 0.2855 - val_loss: 4.6342 - val_accuracy: 0.0333\n",
      "Epoch 138/150\n",
      "802/802 [==============================] - 0s 50us/step - loss: 2.5553 - accuracy: 0.2182 - val_loss: 2.9390 - val_accuracy: 0.2778\n",
      "Epoch 139/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.1215 - accuracy: 0.2781 - val_loss: 7.8147 - val_accuracy: 0.2778\n",
      "Epoch 140/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.7212 - accuracy: 0.3005 - val_loss: 4.3971 - val_accuracy: 0.2778\n",
      "Epoch 141/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3776 - accuracy: 0.2843 - val_loss: 7.0422 - val_accuracy: 0.2778\n",
      "Epoch 142/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5221 - accuracy: 0.3055 - val_loss: 3.0325 - val_accuracy: 0.2778\n",
      "Epoch 143/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.6225 - accuracy: 0.2643 - val_loss: 3.5535 - val_accuracy: 0.1889\n",
      "Epoch 144/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.7470 - accuracy: 0.2444 - val_loss: 2.6534 - val_accuracy: 0.2778\n",
      "Epoch 145/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2924 - accuracy: 0.2693 - val_loss: 4.3097 - val_accuracy: 0.0556\n",
      "Epoch 146/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2866 - accuracy: 0.2693 - val_loss: 4.2554 - val_accuracy: 0.0222\n",
      "Epoch 147/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.3483 - accuracy: 0.2581 - val_loss: 3.0581 - val_accuracy: 0.2778\n",
      "Epoch 148/150\n",
      "802/802 [==============================] - 0s 50us/step - loss: 2.3987 - accuracy: 0.2880 - val_loss: 3.8453 - val_accuracy: 0.1111\n",
      "Epoch 149/150\n",
      "802/802 [==============================] - 0s 50us/step - loss: 2.8240 - accuracy: 0.2506 - val_loss: 5.3905 - val_accuracy: 0.1111\n",
      "Epoch 150/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5977 - accuracy: 0.2481 - val_loss: 3.3672 - val_accuracy: 0.1889\n",
      "460/460 [==============================] - 0s 35us/step\n",
      "Loss: 3.36\n",
      "Accuracy 0.15\n",
      "Train on 802 samples, validate on 90 samples\n",
      "Epoch 1/150\n",
      "802/802 [==============================] - 0s 611us/step - loss: 1.9866 - accuracy: 0.3017 - val_loss: 4.6760 - val_accuracy: 0.1111\n",
      "Epoch 2/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.7064 - accuracy: 0.2581 - val_loss: 4.0814 - val_accuracy: 0.1111\n",
      "Epoch 3/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.3515 - accuracy: 0.2718 - val_loss: 8.2983 - val_accuracy: 0.1889\n",
      "Epoch 4/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 3.0569 - accuracy: 0.2544 - val_loss: 3.1333 - val_accuracy: 0.2778\n",
      "Epoch 5/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.6320 - accuracy: 0.2344 - val_loss: 9.8304 - val_accuracy: 0.1111\n",
      "Epoch 6/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 3.1807 - accuracy: 0.2431 - val_loss: 3.1431 - val_accuracy: 0.1889\n",
      "Epoch 7/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.1335 - accuracy: 0.2893 - val_loss: 4.7377 - val_accuracy: 0.2778\n",
      "Epoch 8/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.4548 - accuracy: 0.2569 - val_loss: 5.1449 - val_accuracy: 0.2778\n",
      "Epoch 9/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.7598 - accuracy: 0.2531 - val_loss: 3.6721 - val_accuracy: 0.2778\n",
      "Epoch 10/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.2060 - accuracy: 0.2943 - val_loss: 4.5886 - val_accuracy: 0.2778\n",
      "Epoch 11/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4166 - accuracy: 0.2930 - val_loss: 3.6039 - val_accuracy: 0.2778\n",
      "Epoch 12/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.2209 - accuracy: 0.2768 - val_loss: 5.5191 - val_accuracy: 0.2778\n",
      "Epoch 13/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.5041 - accuracy: 0.2880 - val_loss: 4.0841 - val_accuracy: 0.0333\n",
      "Epoch 14/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4110 - accuracy: 0.2718 - val_loss: 8.2574 - val_accuracy: 0.1889\n",
      "Epoch 15/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.9040 - accuracy: 0.2706 - val_loss: 3.9776 - val_accuracy: 0.2778\n",
      "Epoch 16/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.2187 - accuracy: 0.3080 - val_loss: 7.8286 - val_accuracy: 0.2778\n",
      "Epoch 17/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.7560 - accuracy: 0.2818 - val_loss: 9.5552 - val_accuracy: 0.1111\n",
      "Epoch 18/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 3.1047 - accuracy: 0.2556 - val_loss: 4.4029 - val_accuracy: 0.1111\n",
      "Epoch 19/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6690 - accuracy: 0.2307 - val_loss: 9.4320 - val_accuracy: 0.1889\n",
      "Epoch 20/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 3.1943 - accuracy: 0.2319 - val_loss: 4.7570 - val_accuracy: 0.2778\n",
      "Epoch 21/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6248 - accuracy: 0.2805 - val_loss: 7.6417 - val_accuracy: 0.2778\n",
      "Epoch 22/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.7342 - accuracy: 0.2880 - val_loss: 4.7514 - val_accuracy: 0.2778\n",
      "Epoch 23/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3774 - accuracy: 0.3005 - val_loss: 3.1567 - val_accuracy: 0.2778\n",
      "Epoch 24/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 1.9844 - accuracy: 0.3167 - val_loss: 3.0617 - val_accuracy: 0.2778\n",
      "Epoch 25/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.3675 - accuracy: 0.2768 - val_loss: 2.6375 - val_accuracy: 0.2778\n",
      "Epoch 26/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.1743 - accuracy: 0.2855 - val_loss: 4.7918 - val_accuracy: 0.1111\n",
      "Epoch 27/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.4205 - accuracy: 0.2781 - val_loss: 6.6002 - val_accuracy: 0.2778\n",
      "Epoch 28/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.8983 - accuracy: 0.2668 - val_loss: 4.1172 - val_accuracy: 0.0111\n",
      "Epoch 29/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.1320 - accuracy: 0.2444 - val_loss: 4.0217 - val_accuracy: 0.0111\n",
      "Epoch 30/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.7010 - accuracy: 0.2170 - val_loss: 3.7323 - val_accuracy: 0.1889\n",
      "Epoch 31/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.4308 - accuracy: 0.2631 - val_loss: 7.0871 - val_accuracy: 0.2778\n",
      "Epoch 32/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.6101 - accuracy: 0.3080 - val_loss: 6.1025 - val_accuracy: 0.2778\n",
      "Epoch 33/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5995 - accuracy: 0.2868 - val_loss: 2.1891 - val_accuracy: 0.2778\n",
      "Epoch 34/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.1406 - accuracy: 0.2656 - val_loss: 5.3106 - val_accuracy: 0.0556\n",
      "Epoch 35/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 61us/step - loss: 2.4877 - accuracy: 0.2531 - val_loss: 3.1688 - val_accuracy: 0.2778\n",
      "Epoch 36/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5971 - accuracy: 0.2681 - val_loss: 4.2909 - val_accuracy: 0.1889\n",
      "Epoch 37/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5956 - accuracy: 0.2706 - val_loss: 7.9984 - val_accuracy: 0.2778\n",
      "Epoch 38/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.9693 - accuracy: 0.2469 - val_loss: 8.9048 - val_accuracy: 0.1889\n",
      "Epoch 39/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 3.0947 - accuracy: 0.2693 - val_loss: 2.6386 - val_accuracy: 0.2778\n",
      "Epoch 40/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.1196 - accuracy: 0.2980 - val_loss: 3.5456 - val_accuracy: 0.0111\n",
      "Epoch 41/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.2168 - accuracy: 0.2706 - val_loss: 7.1165 - val_accuracy: 0.2778\n",
      "Epoch 42/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6174 - accuracy: 0.2893 - val_loss: 4.6180 - val_accuracy: 0.1111\n",
      "Epoch 43/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4236 - accuracy: 0.2793 - val_loss: 2.9324 - val_accuracy: 0.2778\n",
      "Epoch 44/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5049 - accuracy: 0.2768 - val_loss: 4.4772 - val_accuracy: 0.1111\n",
      "Epoch 45/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5695 - accuracy: 0.2581 - val_loss: 4.1592 - val_accuracy: 0.0556\n",
      "Epoch 46/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4238 - accuracy: 0.2569 - val_loss: 2.9659 - val_accuracy: 0.2778\n",
      "Epoch 47/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4819 - accuracy: 0.2531 - val_loss: 3.9175 - val_accuracy: 0.1889\n",
      "Epoch 48/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6903 - accuracy: 0.2643 - val_loss: 4.1450 - val_accuracy: 0.0556\n",
      "Epoch 49/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5839 - accuracy: 0.2145 - val_loss: 3.0541 - val_accuracy: 0.2778\n",
      "Epoch 50/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 1.9916 - accuracy: 0.2918 - val_loss: 4.4589 - val_accuracy: 0.1111\n",
      "Epoch 51/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.4147 - accuracy: 0.2731 - val_loss: 4.8215 - val_accuracy: 0.2778\n",
      "Epoch 52/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.2042 - accuracy: 0.3017 - val_loss: 3.3471 - val_accuracy: 0.2778\n",
      "Epoch 53/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5415 - accuracy: 0.2693 - val_loss: 7.9461 - val_accuracy: 0.2778\n",
      "Epoch 54/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.8065 - accuracy: 0.3005 - val_loss: 4.3549 - val_accuracy: 0.1111\n",
      "Epoch 55/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.3329 - accuracy: 0.2668 - val_loss: 5.2682 - val_accuracy: 0.2778\n",
      "Epoch 56/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5868 - accuracy: 0.2855 - val_loss: 4.6384 - val_accuracy: 0.1111\n",
      "Epoch 57/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4914 - accuracy: 0.2793 - val_loss: 2.8639 - val_accuracy: 0.2778\n",
      "Epoch 58/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.2819 - accuracy: 0.2843 - val_loss: 7.5295 - val_accuracy: 0.2778\n",
      "Epoch 59/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.6647 - accuracy: 0.2756 - val_loss: 2.9997 - val_accuracy: 0.2778\n",
      "Epoch 60/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5573 - accuracy: 0.2494 - val_loss: 2.8171 - val_accuracy: 0.2778\n",
      "Epoch 61/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5923 - accuracy: 0.2307 - val_loss: 3.5921 - val_accuracy: 0.2778\n",
      "Epoch 62/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5336 - accuracy: 0.2756 - val_loss: 3.0040 - val_accuracy: 0.2778\n",
      "Epoch 63/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5219 - accuracy: 0.2731 - val_loss: 3.4560 - val_accuracy: 0.1889\n",
      "Epoch 64/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5584 - accuracy: 0.2444 - val_loss: 6.2498 - val_accuracy: 0.2778\n",
      "Epoch 65/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6393 - accuracy: 0.2855 - val_loss: 2.9951 - val_accuracy: 0.2778\n",
      "Epoch 66/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.0996 - accuracy: 0.3017 - val_loss: 4.1235 - val_accuracy: 0.1111\n",
      "Epoch 67/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.5933 - accuracy: 0.2656 - val_loss: 2.8359 - val_accuracy: 0.0111\n",
      "Epoch 68/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.1267 - accuracy: 0.2419 - val_loss: 3.7680 - val_accuracy: 0.1889\n",
      "Epoch 69/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.2679 - accuracy: 0.2943 - val_loss: 3.7182 - val_accuracy: 0.0333\n",
      "Epoch 70/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2702 - accuracy: 0.2743 - val_loss: 6.5466 - val_accuracy: 0.2778\n",
      "Epoch 71/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5183 - accuracy: 0.2918 - val_loss: 3.4984 - val_accuracy: 0.1889\n",
      "Epoch 72/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.2136 - accuracy: 0.2843 - val_loss: 3.4417 - val_accuracy: 0.1889\n",
      "Epoch 73/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.7729 - accuracy: 0.2406 - val_loss: 4.9786 - val_accuracy: 0.2778\n",
      "Epoch 74/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5963 - accuracy: 0.2793 - val_loss: 4.4970 - val_accuracy: 0.2778\n",
      "Epoch 75/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5208 - accuracy: 0.2681 - val_loss: 3.0623 - val_accuracy: 0.1889\n",
      "Epoch 76/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.4183 - accuracy: 0.2531 - val_loss: 7.7390 - val_accuracy: 0.2778\n",
      "Epoch 77/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.8965 - accuracy: 0.2731 - val_loss: 4.7239 - val_accuracy: 0.1111\n",
      "Epoch 78/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.8748 - accuracy: 0.2419 - val_loss: 4.2687 - val_accuracy: 0.2778\n",
      "Epoch 79/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.2521 - accuracy: 0.3005 - val_loss: 3.8576 - val_accuracy: 0.1111\n",
      "Epoch 80/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 3.0943 - accuracy: 0.2195 - val_loss: 3.0205 - val_accuracy: 0.1889\n",
      "Epoch 81/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3187 - accuracy: 0.2668 - val_loss: 4.9547 - val_accuracy: 0.1889\n",
      "Epoch 82/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.5220 - accuracy: 0.2681 - val_loss: 6.0373 - val_accuracy: 0.1111\n",
      "Epoch 83/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6202 - accuracy: 0.2581 - val_loss: 4.7797 - val_accuracy: 0.2778\n",
      "Epoch 84/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.2452 - accuracy: 0.2943 - val_loss: 5.0805 - val_accuracy: 0.1111\n",
      "Epoch 85/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4732 - accuracy: 0.2681 - val_loss: 5.2753 - val_accuracy: 0.1889\n",
      "Epoch 86/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5046 - accuracy: 0.2855 - val_loss: 5.1114 - val_accuracy: 0.0556\n",
      "Epoch 87/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6107 - accuracy: 0.2494 - val_loss: 3.1833 - val_accuracy: 0.2778\n",
      "Epoch 88/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5417 - accuracy: 0.2494 - val_loss: 4.8241 - val_accuracy: 0.1889\n",
      "Epoch 89/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3895 - accuracy: 0.2681 - val_loss: 3.3853 - val_accuracy: 0.2778\n",
      "Epoch 90/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.8091 - accuracy: 0.2506 - val_loss: 5.8032 - val_accuracy: 0.0556\n",
      "Epoch 91/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5741 - accuracy: 0.2581 - val_loss: 8.3148 - val_accuracy: 0.2778\n",
      "Epoch 92/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.8527 - accuracy: 0.3017 - val_loss: 3.4578 - val_accuracy: 0.1889\n",
      "Epoch 93/150\n",
      "802/802 [==============================] - 0s 50us/step - loss: 2.2823 - accuracy: 0.2968 - val_loss: 4.4190 - val_accuracy: 0.1889\n",
      "Epoch 94/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.9459 - accuracy: 0.2145 - val_loss: 5.3358 - val_accuracy: 0.1111\n",
      "Epoch 95/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.8430 - accuracy: 0.2494 - val_loss: 3.3641 - val_accuracy: 0.1889\n",
      "Epoch 96/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6997 - accuracy: 0.2618 - val_loss: 4.0493 - val_accuracy: 0.1111\n",
      "Epoch 97/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3955 - accuracy: 0.2456 - val_loss: 3.8992 - val_accuracy: 0.1889\n",
      "Epoch 98/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6017 - accuracy: 0.2693 - val_loss: 7.8521 - val_accuracy: 0.2778\n",
      "Epoch 99/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 3.1008 - accuracy: 0.2693 - val_loss: 5.9396 - val_accuracy: 0.2778\n",
      "Epoch 100/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5717 - accuracy: 0.2968 - val_loss: 3.8679 - val_accuracy: 0.1111\n",
      "Epoch 101/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6638 - accuracy: 0.2481 - val_loss: 5.1502 - val_accuracy: 0.2778\n",
      "Epoch 102/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.4889 - accuracy: 0.2855 - val_loss: 4.8520 - val_accuracy: 0.1111\n",
      "Epoch 103/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.8665 - accuracy: 0.2406 - val_loss: 2.5005 - val_accuracy: 0.2778\n",
      "Epoch 104/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.1417 - accuracy: 0.2718 - val_loss: 5.3100 - val_accuracy: 0.1889\n",
      "Epoch 105/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.6205 - accuracy: 0.2170 - val_loss: 3.0732 - val_accuracy: 0.1889\n",
      "Epoch 106/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.2310 - accuracy: 0.2643 - val_loss: 4.2737 - val_accuracy: 0.1111\n",
      "Epoch 107/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4750 - accuracy: 0.2768 - val_loss: 4.1039 - val_accuracy: 0.0222\n",
      "Epoch 108/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4568 - accuracy: 0.2332 - val_loss: 4.4153 - val_accuracy: 0.0333\n",
      "Epoch 109/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.6989 - accuracy: 0.2469 - val_loss: 4.3988 - val_accuracy: 0.1111\n",
      "Epoch 110/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.7825 - accuracy: 0.2544 - val_loss: 4.0034 - val_accuracy: 0.0222\n",
      "Epoch 111/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.4357 - accuracy: 0.2506 - val_loss: 2.9999 - val_accuracy: 0.2778\n",
      "Epoch 112/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3826 - accuracy: 0.2793 - val_loss: 4.4418 - val_accuracy: 0.2778\n",
      "Epoch 113/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4338 - accuracy: 0.2731 - val_loss: 8.4449 - val_accuracy: 0.2778\n",
      "Epoch 114/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.9663 - accuracy: 0.2606 - val_loss: 3.9959 - val_accuracy: 0.0556\n",
      "Epoch 115/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6908 - accuracy: 0.2431 - val_loss: 2.7333 - val_accuracy: 0.2778\n",
      "Epoch 116/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3545 - accuracy: 0.2581 - val_loss: 7.4173 - val_accuracy: 0.2778\n",
      "Epoch 117/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.7156 - accuracy: 0.2930 - val_loss: 4.6413 - val_accuracy: 0.0333\n",
      "Epoch 118/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4338 - accuracy: 0.2519 - val_loss: 5.4159 - val_accuracy: 0.0222\n",
      "Epoch 119/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4147 - accuracy: 0.2743 - val_loss: 4.8423 - val_accuracy: 0.0556\n",
      "Epoch 120/150\n",
      "802/802 [==============================] - ETA: 0s - loss: 5.3450 - accuracy: 0.03 - 0s 54us/step - loss: 2.3945 - accuracy: 0.2519 - val_loss: 3.2948 - val_accuracy: 0.2778\n",
      "Epoch 121/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.6683 - accuracy: 0.2394 - val_loss: 4.5266 - val_accuracy: 0.0556\n",
      "Epoch 122/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.2944 - accuracy: 0.2406 - val_loss: 3.8281 - val_accuracy: 0.0556\n",
      "Epoch 123/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3569 - accuracy: 0.2606 - val_loss: 4.7719 - val_accuracy: 0.2778\n",
      "Epoch 124/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3859 - accuracy: 0.2955 - val_loss: 4.5248 - val_accuracy: 0.2778\n",
      "Epoch 125/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6180 - accuracy: 0.2469 - val_loss: 4.0559 - val_accuracy: 0.2778\n",
      "Epoch 126/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4032 - accuracy: 0.2693 - val_loss: 7.9809 - val_accuracy: 0.2778\n",
      "Epoch 127/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.7111 - accuracy: 0.3030 - val_loss: 9.9761 - val_accuracy: 0.1111\n",
      "Epoch 128/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 3.1303 - accuracy: 0.2643 - val_loss: 4.5854 - val_accuracy: 0.1111\n",
      "Epoch 129/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5693 - accuracy: 0.2581 - val_loss: 4.3660 - val_accuracy: 0.2778\n",
      "Epoch 130/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3216 - accuracy: 0.3005 - val_loss: 4.1398 - val_accuracy: 0.2778\n",
      "Epoch 131/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.2081 - accuracy: 0.2880 - val_loss: 3.9822 - val_accuracy: 0.1889\n",
      "Epoch 132/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.4426 - accuracy: 0.2718 - val_loss: 2.7350 - val_accuracy: 0.2778\n",
      "Epoch 133/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.3048 - accuracy: 0.2756 - val_loss: 3.8348 - val_accuracy: 0.2778\n",
      "Epoch 134/150\n",
      "802/802 [==============================] - 0s 51us/step - loss: 2.3713 - accuracy: 0.2805 - val_loss: 4.1363 - val_accuracy: 0.0111\n",
      "Epoch 135/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4075 - accuracy: 0.2481 - val_loss: 3.1435 - val_accuracy: 0.2778\n",
      "Epoch 136/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5219 - accuracy: 0.2706 - val_loss: 5.2952 - val_accuracy: 0.2778\n",
      "Epoch 137/150\n",
      "802/802 [==============================] - 0s 50us/step - loss: 2.4751 - accuracy: 0.2905 - val_loss: 4.4218 - val_accuracy: 0.2778\n",
      "Epoch 138/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3063 - accuracy: 0.2594 - val_loss: 4.8471 - val_accuracy: 0.0556\n",
      "Epoch 139/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5329 - accuracy: 0.2419 - val_loss: 6.7785 - val_accuracy: 0.1889\n",
      "Epoch 140/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5893 - accuracy: 0.2930 - val_loss: 2.8217 - val_accuracy: 0.2778\n",
      "Epoch 141/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.6938 - accuracy: 0.2519 - val_loss: 3.9609 - val_accuracy: 0.1889\n",
      "Epoch 142/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4557 - accuracy: 0.2805 - val_loss: 4.5953 - val_accuracy: 0.2778\n",
      "Epoch 143/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.2064 - accuracy: 0.2781 - val_loss: 9.0165 - val_accuracy: 0.1889\n",
      "Epoch 144/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.9711 - accuracy: 0.2768 - val_loss: 3.6327 - val_accuracy: 0.1889\n",
      "Epoch 145/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5251 - accuracy: 0.2444 - val_loss: 5.1926 - val_accuracy: 0.1889\n",
      "Epoch 146/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6837 - accuracy: 0.2569 - val_loss: 4.8580 - val_accuracy: 0.1111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.8733 - accuracy: 0.2294 - val_loss: 3.8026 - val_accuracy: 0.2778\n",
      "Epoch 148/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5298 - accuracy: 0.2556 - val_loss: 3.7940 - val_accuracy: 0.1889\n",
      "Epoch 149/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.2595 - accuracy: 0.2930 - val_loss: 2.9505 - val_accuracy: 0.2778\n",
      "Epoch 150/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.4142 - accuracy: 0.2693 - val_loss: 8.1142 - val_accuracy: 0.2778\n",
      "460/460 [==============================] - 0s 57us/step\n",
      "Loss: 7.49\n",
      "Accuracy 0.33\n",
      "Train on 802 samples, validate on 90 samples\n",
      "Epoch 1/150\n",
      "802/802 [==============================] - 1s 708us/step - loss: 2.1876 - accuracy: 0.3055 - val_loss: 3.2527 - val_accuracy: 0.1889\n",
      "Epoch 2/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.1349 - accuracy: 0.2805 - val_loss: 3.7669 - val_accuracy: 0.1889\n",
      "Epoch 3/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.6238 - accuracy: 0.2656 - val_loss: 6.7786 - val_accuracy: 0.2778\n",
      "Epoch 4/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.7546 - accuracy: 0.2594 - val_loss: 4.8083 - val_accuracy: 0.2778\n",
      "Epoch 5/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4481 - accuracy: 0.2855 - val_loss: 4.8179 - val_accuracy: 0.0222\n",
      "Epoch 6/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.5136 - accuracy: 0.2207 - val_loss: 3.0980 - val_accuracy: 0.2778\n",
      "Epoch 7/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4305 - accuracy: 0.2768 - val_loss: 3.9931 - val_accuracy: 0.2778\n",
      "Epoch 8/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.2833 - accuracy: 0.2718 - val_loss: 7.4073 - val_accuracy: 0.2778\n",
      "Epoch 9/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.7794 - accuracy: 0.2855 - val_loss: 2.6673 - val_accuracy: 0.2778\n",
      "Epoch 10/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.4622 - accuracy: 0.2805 - val_loss: 3.0385 - val_accuracy: 0.2778\n",
      "Epoch 11/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.0567 - accuracy: 0.2943 - val_loss: 4.7552 - val_accuracy: 0.1889\n",
      "Epoch 12/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4901 - accuracy: 0.2481 - val_loss: 3.6853 - val_accuracy: 0.1889\n",
      "Epoch 13/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5153 - accuracy: 0.2456 - val_loss: 3.1478 - val_accuracy: 0.2778\n",
      "Epoch 14/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.4399 - accuracy: 0.2594 - val_loss: 5.7443 - val_accuracy: 0.1111\n",
      "Epoch 15/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5554 - accuracy: 0.2631 - val_loss: 4.8019 - val_accuracy: 0.1889\n",
      "Epoch 16/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.7131 - accuracy: 0.2656 - val_loss: 4.5642 - val_accuracy: 0.1889\n",
      "Epoch 17/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5750 - accuracy: 0.2718 - val_loss: 2.9513 - val_accuracy: 0.2778\n",
      "Epoch 18/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.0098 - accuracy: 0.3142 - val_loss: 4.8440 - val_accuracy: 0.1889\n",
      "Epoch 19/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.6238 - accuracy: 0.2531 - val_loss: 6.0584 - val_accuracy: 0.1889\n",
      "Epoch 20/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.7102 - accuracy: 0.2195 - val_loss: 4.2477 - val_accuracy: 0.0111\n",
      "Epoch 21/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.3488 - accuracy: 0.2668 - val_loss: 4.0610 - val_accuracy: 0.1111\n",
      "Epoch 22/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5325 - accuracy: 0.2743 - val_loss: 5.5526 - val_accuracy: 0.0222\n",
      "Epoch 23/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.7148 - accuracy: 0.2282 - val_loss: 7.6986 - val_accuracy: 0.2778\n",
      "Epoch 24/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.8225 - accuracy: 0.2768 - val_loss: 4.3380 - val_accuracy: 0.1111\n",
      "Epoch 25/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4237 - accuracy: 0.2643 - val_loss: 3.0076 - val_accuracy: 0.2778\n",
      "Epoch 26/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.7056 - accuracy: 0.2781 - val_loss: 4.0403 - val_accuracy: 0.0556\n",
      "Epoch 27/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.6994 - accuracy: 0.2319 - val_loss: 3.4749 - val_accuracy: 0.1889\n",
      "Epoch 28/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.7679 - accuracy: 0.2581 - val_loss: 4.0157 - val_accuracy: 0.1111\n",
      "Epoch 29/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.7729 - accuracy: 0.2282 - val_loss: 5.0140 - val_accuracy: 0.1111\n",
      "Epoch 30/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.5602 - accuracy: 0.2656 - val_loss: 4.8214 - val_accuracy: 0.1889\n",
      "Epoch 31/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.4773 - accuracy: 0.2893 - val_loss: 5.0004 - val_accuracy: 0.2778\n",
      "Epoch 32/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.5451 - accuracy: 0.2805 - val_loss: 8.1113 - val_accuracy: 0.2778\n",
      "Epoch 33/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.9558 - accuracy: 0.2818 - val_loss: 4.0125 - val_accuracy: 0.1889\n",
      "Epoch 34/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.3148 - accuracy: 0.2581 - val_loss: 2.9856 - val_accuracy: 0.2778\n",
      "Epoch 35/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5870 - accuracy: 0.2893 - val_loss: 5.0012 - val_accuracy: 0.1111\n",
      "Epoch 36/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4602 - accuracy: 0.2656 - val_loss: 6.5631 - val_accuracy: 0.2778\n",
      "Epoch 37/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.7124 - accuracy: 0.2905 - val_loss: 5.0897 - val_accuracy: 0.2778\n",
      "Epoch 38/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4898 - accuracy: 0.2880 - val_loss: 7.5941 - val_accuracy: 0.2778\n",
      "Epoch 39/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.7593 - accuracy: 0.2943 - val_loss: 7.5440 - val_accuracy: 0.2778\n",
      "Epoch 40/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5283 - accuracy: 0.2980 - val_loss: 3.0671 - val_accuracy: 0.2778\n",
      "Epoch 41/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.4531 - accuracy: 0.2681 - val_loss: 5.0995 - val_accuracy: 0.1889\n",
      "Epoch 42/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6580 - accuracy: 0.2731 - val_loss: 7.3537 - val_accuracy: 0.2778\n",
      "Epoch 43/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.7462 - accuracy: 0.2868 - val_loss: 4.1032 - val_accuracy: 0.1889\n",
      "Epoch 44/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.5368 - accuracy: 0.2481 - val_loss: 3.1324 - val_accuracy: 0.2778\n",
      "Epoch 45/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5870 - accuracy: 0.2606 - val_loss: 5.4246 - val_accuracy: 0.1111\n",
      "Epoch 46/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.5469 - accuracy: 0.2544 - val_loss: 3.5234 - val_accuracy: 0.1889\n",
      "Epoch 47/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5158 - accuracy: 0.2781 - val_loss: 5.3177 - val_accuracy: 0.1111\n",
      "Epoch 48/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4910 - accuracy: 0.2606 - val_loss: 4.3956 - val_accuracy: 0.2778\n",
      "Epoch 49/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.4389 - accuracy: 0.2756 - val_loss: 3.8951 - val_accuracy: 0.0556\n",
      "Epoch 50/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.4532 - accuracy: 0.2544 - val_loss: 3.6023 - val_accuracy: 0.1889\n",
      "Epoch 51/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.4767 - accuracy: 0.2793 - val_loss: 4.5031 - val_accuracy: 0.2778\n",
      "Epoch 52/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5306 - accuracy: 0.2818 - val_loss: 4.2337 - val_accuracy: 0.1111\n",
      "Epoch 53/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4621 - accuracy: 0.2419 - val_loss: 6.0813 - val_accuracy: 0.1889\n",
      "Epoch 54/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6941 - accuracy: 0.2494 - val_loss: 5.1637 - val_accuracy: 0.2778\n",
      "Epoch 55/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5194 - accuracy: 0.2843 - val_loss: 4.0577 - val_accuracy: 0.2778\n",
      "Epoch 56/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4284 - accuracy: 0.2544 - val_loss: 3.0248 - val_accuracy: 0.2778\n",
      "Epoch 57/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.2705 - accuracy: 0.2731 - val_loss: 4.0753 - val_accuracy: 0.0111\n",
      "Epoch 58/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.7210 - accuracy: 0.2269 - val_loss: 4.4554 - val_accuracy: 0.0111\n",
      "Epoch 59/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3249 - accuracy: 0.2606 - val_loss: 3.8958 - val_accuracy: 0.1111\n",
      "Epoch 60/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 3.3776 - accuracy: 0.1908 - val_loss: 3.1237 - val_accuracy: 0.1889\n",
      "Epoch 61/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4066 - accuracy: 0.2170 - val_loss: 4.8977 - val_accuracy: 0.2778\n",
      "Epoch 62/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.5798 - accuracy: 0.2294 - val_loss: 5.5259 - val_accuracy: 0.1111\n",
      "Epoch 63/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.4864 - accuracy: 0.2494 - val_loss: 3.2674 - val_accuracy: 0.1889\n",
      "Epoch 64/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.4764 - accuracy: 0.2594 - val_loss: 4.4534 - val_accuracy: 0.1889\n",
      "Epoch 65/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.5045 - accuracy: 0.2843 - val_loss: 7.5528 - val_accuracy: 0.2778\n",
      "Epoch 66/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.7027 - accuracy: 0.2968 - val_loss: 6.4348 - val_accuracy: 0.2778\n",
      "Epoch 67/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.7471 - accuracy: 0.2830 - val_loss: 3.5526 - val_accuracy: 0.1889\n",
      "Epoch 68/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.7109 - accuracy: 0.2444 - val_loss: 3.0544 - val_accuracy: 0.2778\n",
      "Epoch 69/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.3656 - accuracy: 0.2706 - val_loss: 5.0430 - val_accuracy: 0.2778\n",
      "Epoch 70/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4289 - accuracy: 0.2556 - val_loss: 4.3561 - val_accuracy: 0.2778\n",
      "Epoch 71/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4021 - accuracy: 0.2668 - val_loss: 10.2345 - val_accuracy: 0.0111\n",
      "Epoch 72/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 3.1675 - accuracy: 0.2244 - val_loss: 4.2733 - val_accuracy: 0.2778\n",
      "Epoch 73/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.3052 - accuracy: 0.2805 - val_loss: 4.4294 - val_accuracy: 0.1111\n",
      "Epoch 74/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6137 - accuracy: 0.2519 - val_loss: 5.2027 - val_accuracy: 0.2778\n",
      "Epoch 75/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4626 - accuracy: 0.2993 - val_loss: 3.7615 - val_accuracy: 0.1889\n",
      "Epoch 76/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5598 - accuracy: 0.2781 - val_loss: 4.0227 - val_accuracy: 0.0556\n",
      "Epoch 77/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.2805 - accuracy: 0.2706 - val_loss: 4.1177 - val_accuracy: 0.0333\n",
      "Epoch 78/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.3499 - accuracy: 0.2731 - val_loss: 4.7833 - val_accuracy: 0.2778\n",
      "Epoch 79/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4580 - accuracy: 0.2731 - val_loss: 3.7229 - val_accuracy: 0.1889\n",
      "Epoch 80/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.6072 - accuracy: 0.2643 - val_loss: 3.1280 - val_accuracy: 0.2778\n",
      "Epoch 81/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4796 - accuracy: 0.2930 - val_loss: 4.2282 - val_accuracy: 0.2778\n",
      "Epoch 82/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.4157 - accuracy: 0.2905 - val_loss: 4.4049 - val_accuracy: 0.1889\n",
      "Epoch 83/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.9667 - accuracy: 0.2332 - val_loss: 3.8308 - val_accuracy: 0.1111\n",
      "Epoch 84/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5610 - accuracy: 0.2382 - val_loss: 4.0085 - val_accuracy: 0.0222\n",
      "Epoch 85/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.6396 - accuracy: 0.2444 - val_loss: 5.0215 - val_accuracy: 0.1889\n",
      "Epoch 86/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.5673 - accuracy: 0.2793 - val_loss: 4.3678 - val_accuracy: 0.0222\n",
      "Epoch 87/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3101 - accuracy: 0.2643 - val_loss: 3.1233 - val_accuracy: 0.2778\n",
      "Epoch 88/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.3082 - accuracy: 0.2893 - val_loss: 2.9299 - val_accuracy: 0.2778\n",
      "Epoch 89/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2154 - accuracy: 0.2868 - val_loss: 5.4098 - val_accuracy: 0.1889\n",
      "Epoch 90/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.5379 - accuracy: 0.2818 - val_loss: 3.1385 - val_accuracy: 0.2778\n",
      "Epoch 91/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.5415 - accuracy: 0.2756 - val_loss: 4.6209 - val_accuracy: 0.2778\n",
      "Epoch 92/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5968 - accuracy: 0.2718 - val_loss: 3.1620 - val_accuracy: 0.2778\n",
      "Epoch 93/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.4304 - accuracy: 0.2805 - val_loss: 4.1183 - val_accuracy: 0.0556\n",
      "Epoch 94/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 3.0611 - accuracy: 0.2170 - val_loss: 4.3112 - val_accuracy: 0.0333\n",
      "Epoch 95/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.3275 - accuracy: 0.2731 - val_loss: 5.5073 - val_accuracy: 0.2778\n",
      "Epoch 96/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.4626 - accuracy: 0.3042 - val_loss: 4.9025 - val_accuracy: 0.1111\n",
      "Epoch 97/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5148 - accuracy: 0.2718 - val_loss: 3.9067 - val_accuracy: 0.0111\n",
      "Epoch 98/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.3307 - accuracy: 0.2756 - val_loss: 4.7228 - val_accuracy: 0.2778\n",
      "Epoch 99/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.2927 - accuracy: 0.2980 - val_loss: 3.5111 - val_accuracy: 0.1889\n",
      "Epoch 100/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.4552 - accuracy: 0.2731 - val_loss: 4.2179 - val_accuracy: 0.0111\n",
      "Epoch 101/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4483 - accuracy: 0.2332 - val_loss: 4.1315 - val_accuracy: 0.0222\n",
      "Epoch 102/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.7714 - accuracy: 0.2307 - val_loss: 7.7808 - val_accuracy: 0.2778\n",
      "Epoch 103/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.8838 - accuracy: 0.2768 - val_loss: 3.5427 - val_accuracy: 0.1889\n",
      "Epoch 104/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.4713 - accuracy: 0.2893 - val_loss: 2.9036 - val_accuracy: 0.2778\n",
      "Epoch 105/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.6613 - accuracy: 0.2643 - val_loss: 4.0931 - val_accuracy: 0.1111\n",
      "Epoch 106/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.3403 - accuracy: 0.2444 - val_loss: 4.3117 - val_accuracy: 0.1111\n",
      "Epoch 107/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.7612 - accuracy: 0.2481 - val_loss: 4.3037 - val_accuracy: 0.0556\n",
      "Epoch 108/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 57us/step - loss: 2.2742 - accuracy: 0.2531 - val_loss: 3.5523 - val_accuracy: 0.1889\n",
      "Epoch 109/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.6540 - accuracy: 0.2668 - val_loss: 3.8455 - val_accuracy: 0.1889\n",
      "Epoch 110/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.9044 - accuracy: 0.2382 - val_loss: 5.4480 - val_accuracy: 0.1111\n",
      "Epoch 111/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5931 - accuracy: 0.2444 - val_loss: 7.7478 - val_accuracy: 0.2778\n",
      "Epoch 112/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6817 - accuracy: 0.2643 - val_loss: 4.7012 - val_accuracy: 0.1111\n",
      "Epoch 113/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.9347 - accuracy: 0.2369 - val_loss: 4.3854 - val_accuracy: 0.1889\n",
      "Epoch 114/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.5490 - accuracy: 0.2818 - val_loss: 2.9023 - val_accuracy: 0.2778\n",
      "Epoch 115/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.4053 - accuracy: 0.2506 - val_loss: 5.5585 - val_accuracy: 0.2778\n",
      "Epoch 116/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.6487 - accuracy: 0.2743 - val_loss: 2.7333 - val_accuracy: 0.2778\n",
      "Epoch 117/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.1387 - accuracy: 0.2606 - val_loss: 3.3956 - val_accuracy: 0.2778\n",
      "Epoch 118/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5203 - accuracy: 0.2581 - val_loss: 4.1631 - val_accuracy: 0.1889\n",
      "Epoch 119/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.7569 - accuracy: 0.2494 - val_loss: 4.1892 - val_accuracy: 0.0556\n",
      "Epoch 120/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.3573 - accuracy: 0.2494 - val_loss: 5.6812 - val_accuracy: 0.2778\n",
      "Epoch 121/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6514 - accuracy: 0.2843 - val_loss: 7.5739 - val_accuracy: 0.2778\n",
      "Epoch 122/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.9735 - accuracy: 0.2294 - val_loss: 3.0630 - val_accuracy: 0.2778\n",
      "Epoch 123/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4037 - accuracy: 0.2743 - val_loss: 4.1426 - val_accuracy: 0.1111\n",
      "Epoch 124/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.8327 - accuracy: 0.2531 - val_loss: 5.1602 - val_accuracy: 0.2778\n",
      "Epoch 125/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.4520 - accuracy: 0.2706 - val_loss: 2.7641 - val_accuracy: 0.2778\n",
      "Epoch 126/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.2432 - accuracy: 0.2818 - val_loss: 5.6236 - val_accuracy: 0.1111\n",
      "Epoch 127/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.3546 - accuracy: 0.2993 - val_loss: 5.0954 - val_accuracy: 0.1889\n",
      "Epoch 128/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.3435 - accuracy: 0.2905 - val_loss: 4.5865 - val_accuracy: 0.2778\n",
      "Epoch 129/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.3996 - accuracy: 0.2793 - val_loss: 6.1728 - val_accuracy: 0.2778\n",
      "Epoch 130/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5675 - accuracy: 0.2968 - val_loss: 7.7912 - val_accuracy: 0.2778\n",
      "Epoch 131/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.6404 - accuracy: 0.2843 - val_loss: 4.9536 - val_accuracy: 0.1889\n",
      "Epoch 132/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5894 - accuracy: 0.2294 - val_loss: 3.0653 - val_accuracy: 0.2778\n",
      "Epoch 133/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.6552 - accuracy: 0.2556 - val_loss: 8.1000 - val_accuracy: 0.2778\n",
      "Epoch 134/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.8860 - accuracy: 0.2880 - val_loss: 5.0349 - val_accuracy: 0.2778\n",
      "Epoch 135/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5483 - accuracy: 0.2930 - val_loss: 3.9558 - val_accuracy: 0.1111\n",
      "Epoch 136/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5937 - accuracy: 0.2569 - val_loss: 3.6744 - val_accuracy: 0.2778\n",
      "Epoch 137/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4339 - accuracy: 0.2394 - val_loss: 3.1554 - val_accuracy: 0.2778\n",
      "Epoch 138/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5071 - accuracy: 0.2643 - val_loss: 2.5292 - val_accuracy: 0.2778\n",
      "Epoch 139/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.3948 - accuracy: 0.2768 - val_loss: 4.3007 - val_accuracy: 0.1111\n",
      "Epoch 140/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.6453 - accuracy: 0.2431 - val_loss: 4.7497 - val_accuracy: 0.2778\n",
      "Epoch 141/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.3308 - accuracy: 0.2743 - val_loss: 4.0437 - val_accuracy: 0.1889\n",
      "Epoch 142/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.3079 - accuracy: 0.3042 - val_loss: 7.4187 - val_accuracy: 0.1889\n",
      "Epoch 143/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.9311 - accuracy: 0.2631 - val_loss: 4.9566 - val_accuracy: 0.1111\n",
      "Epoch 144/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5654 - accuracy: 0.2556 - val_loss: 3.8198 - val_accuracy: 0.0333\n",
      "Epoch 145/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.4243 - accuracy: 0.2519 - val_loss: 5.0955 - val_accuracy: 0.1111\n",
      "Epoch 146/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.3829 - accuracy: 0.2569 - val_loss: 7.8266 - val_accuracy: 0.2778\n",
      "Epoch 147/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.9042 - accuracy: 0.2681 - val_loss: 4.3975 - val_accuracy: 0.1111\n",
      "Epoch 148/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4742 - accuracy: 0.2681 - val_loss: 5.6747 - val_accuracy: 0.2778\n",
      "Epoch 149/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.6441 - accuracy: 0.2843 - val_loss: 4.8612 - val_accuracy: 0.2778\n",
      "Epoch 150/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.6340 - accuracy: 0.2544 - val_loss: 3.8300 - val_accuracy: 0.1111\n",
      "460/460 [==============================] - 0s 37us/step\n",
      "Loss: 3.61\n",
      "Accuracy 0.12\n",
      "Train on 802 samples, validate on 90 samples\n",
      "Epoch 1/150\n",
      "802/802 [==============================] - 1s 811us/step - loss: 2.2167 - accuracy: 0.2606 - val_loss: 2.8925 - val_accuracy: 0.2778\n",
      "Epoch 2/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.3000 - accuracy: 0.2868 - val_loss: 3.3198 - val_accuracy: 0.2778\n",
      "Epoch 3/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4185 - accuracy: 0.2781 - val_loss: 7.4935 - val_accuracy: 0.2778\n",
      "Epoch 4/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.7667 - accuracy: 0.2805 - val_loss: 6.8716 - val_accuracy: 0.2778\n",
      "Epoch 5/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5247 - accuracy: 0.2893 - val_loss: 4.9238 - val_accuracy: 0.1889\n",
      "Epoch 6/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4911 - accuracy: 0.2344 - val_loss: 2.7013 - val_accuracy: 0.2778\n",
      "Epoch 7/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3526 - accuracy: 0.2768 - val_loss: 3.6311 - val_accuracy: 0.1889\n",
      "Epoch 8/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5885 - accuracy: 0.2681 - val_loss: 3.7338 - val_accuracy: 0.0111\n",
      "Epoch 9/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.1708 - accuracy: 0.2544 - val_loss: 8.2332 - val_accuracy: 0.2778\n",
      "Epoch 10/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 3.1802 - accuracy: 0.2681 - val_loss: 2.9679 - val_accuracy: 0.2778\n",
      "Epoch 11/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.1657 - accuracy: 0.2993 - val_loss: 8.0895 - val_accuracy: 0.1889\n",
      "Epoch 12/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.8571 - accuracy: 0.2556 - val_loss: 9.7978 - val_accuracy: 0.1111\n",
      "Epoch 13/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 3.1880 - accuracy: 0.2531 - val_loss: 4.8889 - val_accuracy: 0.2778\n",
      "Epoch 14/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5820 - accuracy: 0.2394 - val_loss: 5.5497 - val_accuracy: 0.2778\n",
      "Epoch 15/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.7050 - accuracy: 0.2693 - val_loss: 5.1227 - val_accuracy: 0.1111\n",
      "Epoch 16/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5541 - accuracy: 0.2718 - val_loss: 2.9093 - val_accuracy: 0.2778\n",
      "Epoch 17/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.2221 - accuracy: 0.2731 - val_loss: 8.7194 - val_accuracy: 0.1889\n",
      "Epoch 18/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 3.0138 - accuracy: 0.2668 - val_loss: 8.2606 - val_accuracy: 0.2778\n",
      "Epoch 19/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.9691 - accuracy: 0.2843 - val_loss: 4.2676 - val_accuracy: 0.1111\n",
      "Epoch 20/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6437 - accuracy: 0.2569 - val_loss: 3.7199 - val_accuracy: 0.2778\n",
      "Epoch 21/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2644 - accuracy: 0.2668 - val_loss: 4.4123 - val_accuracy: 0.1889\n",
      "Epoch 22/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3827 - accuracy: 0.2693 - val_loss: 4.4268 - val_accuracy: 0.2778\n",
      "Epoch 23/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4682 - accuracy: 0.2681 - val_loss: 4.4033 - val_accuracy: 0.1889\n",
      "Epoch 24/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.9845 - accuracy: 0.2357 - val_loss: 5.2845 - val_accuracy: 0.1111\n",
      "Epoch 25/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3682 - accuracy: 0.2830 - val_loss: 3.0375 - val_accuracy: 0.2778\n",
      "Epoch 26/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3051 - accuracy: 0.2793 - val_loss: 4.7815 - val_accuracy: 0.2778\n",
      "Epoch 27/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5070 - accuracy: 0.2743 - val_loss: 3.1387 - val_accuracy: 0.1889\n",
      "Epoch 28/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.2906 - accuracy: 0.2643 - val_loss: 4.0174 - val_accuracy: 0.0333\n",
      "Epoch 29/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3233 - accuracy: 0.2494 - val_loss: 7.6923 - val_accuracy: 0.2778\n",
      "Epoch 30/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.7161 - accuracy: 0.2943 - val_loss: 3.1204 - val_accuracy: 0.2778\n",
      "Epoch 31/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5830 - accuracy: 0.2481 - val_loss: 8.0503 - val_accuracy: 0.2778\n",
      "Epoch 32/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 3.1331 - accuracy: 0.2594 - val_loss: 5.0130 - val_accuracy: 0.2778\n",
      "Epoch 33/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5202 - accuracy: 0.2768 - val_loss: 5.7431 - val_accuracy: 0.2778\n",
      "Epoch 34/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5353 - accuracy: 0.2756 - val_loss: 3.5311 - val_accuracy: 0.2778\n",
      "Epoch 35/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3416 - accuracy: 0.2781 - val_loss: 5.5556 - val_accuracy: 0.1111\n",
      "Epoch 36/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.4395 - accuracy: 0.2581 - val_loss: 3.0137 - val_accuracy: 0.2778\n",
      "Epoch 37/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5233 - accuracy: 0.2718 - val_loss: 3.5272 - val_accuracy: 0.2778\n",
      "Epoch 38/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.1434 - accuracy: 0.3304 - val_loss: 3.5028 - val_accuracy: 0.2778\n",
      "Epoch 39/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.2074 - accuracy: 0.3017 - val_loss: 4.5251 - val_accuracy: 0.1111\n",
      "Epoch 40/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3729 - accuracy: 0.2494 - val_loss: 3.6280 - val_accuracy: 0.1889\n",
      "Epoch 41/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4888 - accuracy: 0.2656 - val_loss: 5.6683 - val_accuracy: 0.0556\n",
      "Epoch 42/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.7309 - accuracy: 0.2269 - val_loss: 3.7034 - val_accuracy: 0.1889\n",
      "Epoch 43/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5721 - accuracy: 0.2606 - val_loss: 3.8168 - val_accuracy: 0.1889\n",
      "Epoch 44/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2774 - accuracy: 0.2880 - val_loss: 5.1154 - val_accuracy: 0.0556\n",
      "Epoch 45/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4592 - accuracy: 0.2594 - val_loss: 3.2119 - val_accuracy: 0.2778\n",
      "Epoch 46/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.3717 - accuracy: 0.2893 - val_loss: 4.4076 - val_accuracy: 0.2778\n",
      "Epoch 47/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.2921 - accuracy: 0.3155 - val_loss: 2.9037 - val_accuracy: 0.2778\n",
      "Epoch 48/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3182 - accuracy: 0.2830 - val_loss: 4.9230 - val_accuracy: 0.1111\n",
      "Epoch 49/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6486 - accuracy: 0.2531 - val_loss: 2.8662 - val_accuracy: 0.2778\n",
      "Epoch 50/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2131 - accuracy: 0.2781 - val_loss: 3.8318 - val_accuracy: 0.1889\n",
      "Epoch 51/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.7001 - accuracy: 0.2269 - val_loss: 3.0520 - val_accuracy: 0.2778\n",
      "Epoch 52/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3553 - accuracy: 0.2718 - val_loss: 3.4834 - val_accuracy: 0.1889\n",
      "Epoch 53/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4350 - accuracy: 0.2693 - val_loss: 3.8402 - val_accuracy: 0.1111\n",
      "Epoch 54/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5237 - accuracy: 0.2481 - val_loss: 4.2409 - val_accuracy: 0.0556\n",
      "Epoch 55/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4720 - accuracy: 0.2456 - val_loss: 3.0133 - val_accuracy: 0.2778\n",
      "Epoch 56/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6733 - accuracy: 0.2431 - val_loss: 4.3385 - val_accuracy: 0.1111\n",
      "Epoch 57/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4244 - accuracy: 0.2531 - val_loss: 3.9380 - val_accuracy: 0.1889\n",
      "Epoch 58/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.2078 - accuracy: 0.2968 - val_loss: 5.3437 - val_accuracy: 0.1111\n",
      "Epoch 59/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3891 - accuracy: 0.2805 - val_loss: 4.1144 - val_accuracy: 0.2778\n",
      "Epoch 60/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.2729 - accuracy: 0.3092 - val_loss: 3.3717 - val_accuracy: 0.2778\n",
      "Epoch 61/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.3394 - accuracy: 0.2718 - val_loss: 2.9797 - val_accuracy: 0.2778\n",
      "Epoch 62/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.8549 - accuracy: 0.2382 - val_loss: 2.1723 - val_accuracy: 0.2778\n",
      "Epoch 63/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.1326 - accuracy: 0.2718 - val_loss: 3.8721 - val_accuracy: 0.2778\n",
      "Epoch 64/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3882 - accuracy: 0.2968 - val_loss: 4.4491 - val_accuracy: 0.2778\n",
      "Epoch 65/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5411 - accuracy: 0.2718 - val_loss: 3.9360 - val_accuracy: 0.1111\n",
      "Epoch 66/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.1423 - accuracy: 0.2793 - val_loss: 4.0685 - val_accuracy: 0.1889\n",
      "Epoch 67/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5634 - accuracy: 0.2394 - val_loss: 3.2090 - val_accuracy: 0.2778\n",
      "Epoch 68/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.3093 - accuracy: 0.2955 - val_loss: 3.9667 - val_accuracy: 0.0556\n",
      "Epoch 69/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 57us/step - loss: 2.2809 - accuracy: 0.2743 - val_loss: 5.1206 - val_accuracy: 0.1889\n",
      "Epoch 70/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2977 - accuracy: 0.2868 - val_loss: 3.9377 - val_accuracy: 0.2778\n",
      "Epoch 71/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2837 - accuracy: 0.2843 - val_loss: 2.9942 - val_accuracy: 0.2778\n",
      "Epoch 72/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5535 - accuracy: 0.2544 - val_loss: 3.0198 - val_accuracy: 0.1889\n",
      "Epoch 73/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.0580 - accuracy: 0.3042 - val_loss: 8.9656 - val_accuracy: 0.1889\n",
      "Epoch 74/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.9999 - accuracy: 0.2643 - val_loss: 8.5840 - val_accuracy: 0.2778\n",
      "Epoch 75/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 3.1958 - accuracy: 0.2581 - val_loss: 3.0050 - val_accuracy: 0.2778\n",
      "Epoch 76/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3028 - accuracy: 0.2793 - val_loss: 6.2579 - val_accuracy: 0.2778\n",
      "Epoch 77/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5760 - accuracy: 0.2918 - val_loss: 4.6338 - val_accuracy: 0.1111\n",
      "Epoch 78/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3624 - accuracy: 0.2544 - val_loss: 4.6990 - val_accuracy: 0.0333\n",
      "Epoch 79/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2935 - accuracy: 0.2668 - val_loss: 3.0130 - val_accuracy: 0.2778\n",
      "Epoch 80/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3068 - accuracy: 0.2905 - val_loss: 3.3079 - val_accuracy: 0.2778\n",
      "Epoch 81/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4305 - accuracy: 0.2756 - val_loss: 4.6529 - val_accuracy: 0.2778\n",
      "Epoch 82/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3743 - accuracy: 0.2731 - val_loss: 4.4740 - val_accuracy: 0.1889\n",
      "Epoch 83/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6246 - accuracy: 0.2706 - val_loss: 9.4556 - val_accuracy: 0.1111\n",
      "Epoch 84/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.9291 - accuracy: 0.2731 - val_loss: 3.2389 - val_accuracy: 0.2778\n",
      "Epoch 85/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.3211 - accuracy: 0.2643 - val_loss: 10.3315 - val_accuracy: 0.0111\n",
      "Epoch 86/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 3.1885 - accuracy: 0.2456 - val_loss: 7.8153 - val_accuracy: 0.2778\n",
      "Epoch 87/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.9644 - accuracy: 0.2818 - val_loss: 3.8651 - val_accuracy: 0.1111\n",
      "Epoch 88/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4266 - accuracy: 0.2556 - val_loss: 4.7458 - val_accuracy: 0.0556\n",
      "Epoch 89/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5789 - accuracy: 0.2369 - val_loss: 5.1653 - val_accuracy: 0.2778\n",
      "Epoch 90/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3149 - accuracy: 0.3167 - val_loss: 3.5461 - val_accuracy: 0.1889\n",
      "Epoch 91/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.8539 - accuracy: 0.2207 - val_loss: 3.4185 - val_accuracy: 0.1889\n",
      "Epoch 92/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5921 - accuracy: 0.2469 - val_loss: 4.9049 - val_accuracy: 0.1111\n",
      "Epoch 93/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5597 - accuracy: 0.2594 - val_loss: 4.6279 - val_accuracy: 0.2778\n",
      "Epoch 94/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.1912 - accuracy: 0.2930 - val_loss: 4.0212 - val_accuracy: 0.2778\n",
      "Epoch 95/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5213 - accuracy: 0.2506 - val_loss: 5.2751 - val_accuracy: 0.1889\n",
      "Epoch 96/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5015 - accuracy: 0.2830 - val_loss: 3.8452 - val_accuracy: 0.0111\n",
      "Epoch 97/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3310 - accuracy: 0.2456 - val_loss: 4.3794 - val_accuracy: 0.1889\n",
      "Epoch 98/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.9141 - accuracy: 0.2145 - val_loss: 5.3289 - val_accuracy: 0.0556\n",
      "Epoch 99/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.9608 - accuracy: 0.2431 - val_loss: 4.4941 - val_accuracy: 0.2778\n",
      "Epoch 100/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5163 - accuracy: 0.2668 - val_loss: 5.8190 - val_accuracy: 0.1889\n",
      "Epoch 101/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6454 - accuracy: 0.2656 - val_loss: 4.8159 - val_accuracy: 0.1111\n",
      "Epoch 102/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.7009 - accuracy: 0.2531 - val_loss: 2.7509 - val_accuracy: 0.2778\n",
      "Epoch 103/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.0586 - accuracy: 0.2805 - val_loss: 4.9420 - val_accuracy: 0.2778\n",
      "Epoch 104/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.2964 - accuracy: 0.3055 - val_loss: 5.3291 - val_accuracy: 0.1111\n",
      "Epoch 105/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.7392 - accuracy: 0.2519 - val_loss: 4.4877 - val_accuracy: 0.0333\n",
      "Epoch 106/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.2939 - accuracy: 0.2606 - val_loss: 7.8090 - val_accuracy: 0.2778\n",
      "Epoch 107/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.9536 - accuracy: 0.2618 - val_loss: 7.8077 - val_accuracy: 0.2778\n",
      "Epoch 108/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.7995 - accuracy: 0.2893 - val_loss: 3.9104 - val_accuracy: 0.0333\n",
      "Epoch 109/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4586 - accuracy: 0.2656 - val_loss: 5.4922 - val_accuracy: 0.1111\n",
      "Epoch 110/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.9012 - accuracy: 0.2444 - val_loss: 5.3766 - val_accuracy: 0.1111\n",
      "Epoch 111/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5849 - accuracy: 0.2643 - val_loss: 3.8297 - val_accuracy: 0.1111\n",
      "Epoch 112/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.9176 - accuracy: 0.2382 - val_loss: 6.1165 - val_accuracy: 0.2778\n",
      "Epoch 113/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.7578 - accuracy: 0.2643 - val_loss: 4.5233 - val_accuracy: 0.0222\n",
      "Epoch 114/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3316 - accuracy: 0.2544 - val_loss: 5.4639 - val_accuracy: 0.0556\n",
      "Epoch 115/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.6457 - accuracy: 0.2357 - val_loss: 3.2192 - val_accuracy: 0.2778\n",
      "Epoch 116/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4255 - accuracy: 0.2631 - val_loss: 4.2297 - val_accuracy: 0.1111\n",
      "Epoch 117/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.4486 - accuracy: 0.2818 - val_loss: 4.4374 - val_accuracy: 0.1111\n",
      "Epoch 118/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.7279 - accuracy: 0.2643 - val_loss: 4.5409 - val_accuracy: 0.0333\n",
      "Epoch 119/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.3161 - accuracy: 0.2494 - val_loss: 3.7254 - val_accuracy: 0.1889\n",
      "Epoch 120/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5996 - accuracy: 0.2419 - val_loss: 3.9104 - val_accuracy: 0.1889\n",
      "Epoch 121/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4348 - accuracy: 0.2569 - val_loss: 5.4674 - val_accuracy: 0.1111\n",
      "Epoch 122/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3298 - accuracy: 0.2519 - val_loss: 3.5221 - val_accuracy: 0.2778\n",
      "Epoch 123/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2057 - accuracy: 0.2793 - val_loss: 4.0901 - val_accuracy: 0.1111\n",
      "Epoch 124/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5057 - accuracy: 0.2506 - val_loss: 7.4418 - val_accuracy: 0.2778\n",
      "Epoch 125/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.8950 - accuracy: 0.2643 - val_loss: 4.2419 - val_accuracy: 0.1111\n",
      "Epoch 126/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.6420 - accuracy: 0.2556 - val_loss: 4.5191 - val_accuracy: 0.0556\n",
      "Epoch 127/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5566 - accuracy: 0.2219 - val_loss: 4.4077 - val_accuracy: 0.1111\n",
      "Epoch 128/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5993 - accuracy: 0.2431 - val_loss: 4.7010 - val_accuracy: 0.2778\n",
      "Epoch 129/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4337 - accuracy: 0.2855 - val_loss: 3.0303 - val_accuracy: 0.2778\n",
      "Epoch 130/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5089 - accuracy: 0.2706 - val_loss: 2.8557 - val_accuracy: 0.2778\n",
      "Epoch 131/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.1114 - accuracy: 0.2930 - val_loss: 4.2827 - val_accuracy: 0.1111\n",
      "Epoch 132/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5820 - accuracy: 0.2618 - val_loss: 5.8081 - val_accuracy: 0.1111\n",
      "Epoch 133/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4722 - accuracy: 0.2594 - val_loss: 4.4169 - val_accuracy: 0.1111\n",
      "Epoch 134/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6060 - accuracy: 0.2481 - val_loss: 3.1265 - val_accuracy: 0.2778\n",
      "Epoch 135/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6783 - accuracy: 0.2382 - val_loss: 3.3603 - val_accuracy: 0.2778\n",
      "Epoch 136/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2911 - accuracy: 0.2706 - val_loss: 3.1065 - val_accuracy: 0.1889\n",
      "Epoch 137/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.2658 - accuracy: 0.2843 - val_loss: 7.0482 - val_accuracy: 0.2778\n",
      "Epoch 138/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5221 - accuracy: 0.2830 - val_loss: 3.1237 - val_accuracy: 0.2778\n",
      "Epoch 139/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3160 - accuracy: 0.2618 - val_loss: 6.2878 - val_accuracy: 0.2778\n",
      "Epoch 140/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6661 - accuracy: 0.2918 - val_loss: 3.9772 - val_accuracy: 0.0556\n",
      "Epoch 141/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4587 - accuracy: 0.2369 - val_loss: 2.9254 - val_accuracy: 0.2778\n",
      "Epoch 142/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3014 - accuracy: 0.2843 - val_loss: 3.0281 - val_accuracy: 0.2778\n",
      "Epoch 143/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4191 - accuracy: 0.2594 - val_loss: 3.0052 - val_accuracy: 0.2778\n",
      "Epoch 144/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3461 - accuracy: 0.2930 - val_loss: 4.0530 - val_accuracy: 0.0556\n",
      "Epoch 145/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4727 - accuracy: 0.2681 - val_loss: 4.1606 - val_accuracy: 0.2778\n",
      "Epoch 146/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5318 - accuracy: 0.2731 - val_loss: 3.1991 - val_accuracy: 0.1889\n",
      "Epoch 147/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6352 - accuracy: 0.2618 - val_loss: 6.6806 - val_accuracy: 0.2778\n",
      "Epoch 148/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6540 - accuracy: 0.2768 - val_loss: 6.3420 - val_accuracy: 0.1889\n",
      "Epoch 149/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 3.0929 - accuracy: 0.2232 - val_loss: 4.5170 - val_accuracy: 0.1111\n",
      "Epoch 150/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5385 - accuracy: 0.2494 - val_loss: 3.9310 - val_accuracy: 0.0556\n",
      "460/460 [==============================] - 0s 43us/step\n",
      "Loss: 3.99\n",
      "Accuracy 0.03\n",
      "Train on 802 samples, validate on 90 samples\n",
      "Epoch 1/150\n",
      "802/802 [==============================] - 0s 616us/step - loss: 3.1023 - accuracy: 0.2419 - val_loss: 4.6015 - val_accuracy: 0.1111\n",
      "Epoch 2/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.8377 - accuracy: 0.2357 - val_loss: 2.1630 - val_accuracy: 0.2778\n",
      "Epoch 3/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3767 - accuracy: 0.2793 - val_loss: 3.8798 - val_accuracy: 0.1111\n",
      "Epoch 4/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.3434 - accuracy: 0.2781 - val_loss: 2.6864 - val_accuracy: 0.2778\n",
      "Epoch 5/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.2816 - accuracy: 0.3017 - val_loss: 4.2181 - val_accuracy: 0.1111\n",
      "Epoch 6/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.2582 - accuracy: 0.2855 - val_loss: 7.6732 - val_accuracy: 0.2778\n",
      "Epoch 7/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.9264 - accuracy: 0.2781 - val_loss: 2.7571 - val_accuracy: 0.2778\n",
      "Epoch 8/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.4093 - accuracy: 0.2594 - val_loss: 3.0587 - val_accuracy: 0.2778\n",
      "Epoch 9/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.3653 - accuracy: 0.2731 - val_loss: 3.2383 - val_accuracy: 0.1889\n",
      "Epoch 10/150\n",
      "802/802 [==============================] - 0s 86us/step - loss: 2.2679 - accuracy: 0.2569 - val_loss: 4.1780 - val_accuracy: 0.0333\n",
      "Epoch 11/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4009 - accuracy: 0.2070 - val_loss: 4.2862 - val_accuracy: 0.0556\n",
      "Epoch 12/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4205 - accuracy: 0.2643 - val_loss: 6.0214 - val_accuracy: 0.1111\n",
      "Epoch 13/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.5469 - accuracy: 0.2319 - val_loss: 2.8324 - val_accuracy: 0.2778\n",
      "Epoch 14/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3208 - accuracy: 0.2631 - val_loss: 3.9078 - val_accuracy: 0.0111\n",
      "Epoch 15/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.4956 - accuracy: 0.2469 - val_loss: 2.9663 - val_accuracy: 0.2778\n",
      "Epoch 16/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4880 - accuracy: 0.2843 - val_loss: 3.1996 - val_accuracy: 0.2778\n",
      "Epoch 17/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.5610 - accuracy: 0.2693 - val_loss: 4.2996 - val_accuracy: 0.1889\n",
      "Epoch 18/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.2794 - accuracy: 0.2793 - val_loss: 4.9897 - val_accuracy: 0.1111\n",
      "Epoch 19/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.6880 - accuracy: 0.2469 - val_loss: 4.1467 - val_accuracy: 0.1111\n",
      "Epoch 20/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.4742 - accuracy: 0.2631 - val_loss: 3.8400 - val_accuracy: 0.1111\n",
      "Epoch 21/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.3593 - accuracy: 0.2830 - val_loss: 3.4563 - val_accuracy: 0.2778\n",
      "Epoch 22/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.8365 - accuracy: 0.2481 - val_loss: 2.8899 - val_accuracy: 0.2778\n",
      "Epoch 23/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3520 - accuracy: 0.2793 - val_loss: 4.1707 - val_accuracy: 0.2778\n",
      "Epoch 24/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4509 - accuracy: 0.2805 - val_loss: 4.4797 - val_accuracy: 0.1111\n",
      "Epoch 25/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.6806 - accuracy: 0.2382 - val_loss: 2.5698 - val_accuracy: 0.2778\n",
      "Epoch 26/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.0479 - accuracy: 0.2868 - val_loss: 4.5213 - val_accuracy: 0.0556\n",
      "Epoch 27/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5636 - accuracy: 0.2145 - val_loss: 7.7911 - val_accuracy: 0.2778\n",
      "Epoch 28/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.8002 - accuracy: 0.2731 - val_loss: 7.7738 - val_accuracy: 0.2778\n",
      "Epoch 29/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.5471 - accuracy: 0.2793 - val_loss: 5.4468 - val_accuracy: 0.2778\n",
      "Epoch 30/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 64us/step - loss: 2.4517 - accuracy: 0.2668 - val_loss: 4.2009 - val_accuracy: 0.1111\n",
      "Epoch 31/150\n",
      "802/802 [==============================] - 0s 85us/step - loss: 2.6946 - accuracy: 0.2444 - val_loss: 6.1498 - val_accuracy: 0.2778\n",
      "Epoch 32/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4420 - accuracy: 0.2943 - val_loss: 2.4765 - val_accuracy: 0.2778\n",
      "Epoch 33/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.2789 - accuracy: 0.2781 - val_loss: 5.0571 - val_accuracy: 0.2778\n",
      "Epoch 34/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.3143 - accuracy: 0.3017 - val_loss: 3.9024 - val_accuracy: 0.1889\n",
      "Epoch 35/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4774 - accuracy: 0.2768 - val_loss: 4.0216 - val_accuracy: 0.0333\n",
      "Epoch 36/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.4644 - accuracy: 0.2419 - val_loss: 3.3064 - val_accuracy: 0.2778\n",
      "Epoch 37/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.1592 - accuracy: 0.3142 - val_loss: 5.2832 - val_accuracy: 0.1111\n",
      "Epoch 38/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5459 - accuracy: 0.2656 - val_loss: 3.0204 - val_accuracy: 0.2778\n",
      "Epoch 39/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.7044 - accuracy: 0.2668 - val_loss: 4.8910 - val_accuracy: 0.1889\n",
      "Epoch 40/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.3904 - accuracy: 0.2618 - val_loss: 4.3390 - val_accuracy: 0.1111\n",
      "Epoch 41/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.2468 - accuracy: 0.2830 - val_loss: 3.7507 - val_accuracy: 0.1889\n",
      "Epoch 42/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.7239 - accuracy: 0.2656 - val_loss: 2.7761 - val_accuracy: 0.2778\n",
      "Epoch 43/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.2709 - accuracy: 0.2855 - val_loss: 4.5233 - val_accuracy: 0.1111\n",
      "Epoch 44/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4206 - accuracy: 0.2756 - val_loss: 3.2259 - val_accuracy: 0.1889\n",
      "Epoch 45/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3454 - accuracy: 0.2905 - val_loss: 3.6165 - val_accuracy: 0.1889\n",
      "Epoch 46/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6405 - accuracy: 0.2406 - val_loss: 8.1518 - val_accuracy: 0.1889\n",
      "Epoch 47/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 3.1339 - accuracy: 0.2456 - val_loss: 3.4034 - val_accuracy: 0.1889\n",
      "Epoch 48/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3805 - accuracy: 0.2431 - val_loss: 5.0897 - val_accuracy: 0.1889\n",
      "Epoch 49/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6028 - accuracy: 0.2544 - val_loss: 3.9042 - val_accuracy: 0.1889\n",
      "Epoch 50/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4427 - accuracy: 0.2743 - val_loss: 3.7824 - val_accuracy: 0.1889\n",
      "Epoch 51/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5598 - accuracy: 0.2606 - val_loss: 7.5080 - val_accuracy: 0.2778\n",
      "Epoch 52/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 3.0088 - accuracy: 0.2731 - val_loss: 3.0560 - val_accuracy: 0.2778\n",
      "Epoch 53/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.2359 - accuracy: 0.2905 - val_loss: 7.5761 - val_accuracy: 0.2778\n",
      "Epoch 54/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.8453 - accuracy: 0.2656 - val_loss: 4.6255 - val_accuracy: 0.2778\n",
      "Epoch 55/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.4770 - accuracy: 0.2805 - val_loss: 5.3333 - val_accuracy: 0.2778\n",
      "Epoch 56/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4361 - accuracy: 0.2756 - val_loss: 3.7084 - val_accuracy: 0.0111\n",
      "Epoch 57/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4965 - accuracy: 0.2544 - val_loss: 7.2635 - val_accuracy: 0.2778\n",
      "Epoch 58/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.7661 - accuracy: 0.2830 - val_loss: 5.0647 - val_accuracy: 0.1111\n",
      "Epoch 59/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5925 - accuracy: 0.2419 - val_loss: 3.7034 - val_accuracy: 0.1889\n",
      "Epoch 60/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.4028 - accuracy: 0.2818 - val_loss: 3.8726 - val_accuracy: 0.2778\n",
      "Epoch 61/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3721 - accuracy: 0.2731 - val_loss: 4.3072 - val_accuracy: 0.1111\n",
      "Epoch 62/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3788 - accuracy: 0.2606 - val_loss: 5.6339 - val_accuracy: 0.1111\n",
      "Epoch 63/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.7735 - accuracy: 0.2269 - val_loss: 4.6366 - val_accuracy: 0.2778\n",
      "Epoch 64/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4079 - accuracy: 0.2382 - val_loss: 4.3401 - val_accuracy: 0.1889\n",
      "Epoch 65/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4702 - accuracy: 0.2768 - val_loss: 3.1156 - val_accuracy: 0.2778\n",
      "Epoch 66/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.5664 - accuracy: 0.2805 - val_loss: 3.1793 - val_accuracy: 0.2778\n",
      "Epoch 67/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.0767 - accuracy: 0.3017 - val_loss: 5.8331 - val_accuracy: 0.2778\n",
      "Epoch 68/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.3496 - accuracy: 0.2930 - val_loss: 4.4091 - val_accuracy: 0.1889\n",
      "Epoch 69/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5394 - accuracy: 0.2706 - val_loss: 4.1189 - val_accuracy: 0.0111\n",
      "Epoch 70/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6312 - accuracy: 0.2344 - val_loss: 3.9962 - val_accuracy: 0.1889\n",
      "Epoch 71/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.4037 - accuracy: 0.2781 - val_loss: 3.0528 - val_accuracy: 0.1889\n",
      "Epoch 72/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.3153 - accuracy: 0.2768 - val_loss: 3.5153 - val_accuracy: 0.1889\n",
      "Epoch 73/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.3478 - accuracy: 0.2519 - val_loss: 4.0878 - val_accuracy: 0.2778\n",
      "Epoch 74/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.2733 - accuracy: 0.2868 - val_loss: 3.3990 - val_accuracy: 0.2778\n",
      "Epoch 75/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.8371 - accuracy: 0.2294 - val_loss: 3.2930 - val_accuracy: 0.1889\n",
      "Epoch 76/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.3859 - accuracy: 0.2643 - val_loss: 4.1722 - val_accuracy: 0.1111\n",
      "Epoch 77/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.2139 - accuracy: 0.2681 - val_loss: 3.3183 - val_accuracy: 0.1889\n",
      "Epoch 78/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.8267 - accuracy: 0.2319 - val_loss: 2.7012 - val_accuracy: 0.2778\n",
      "Epoch 79/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.1238 - accuracy: 0.2955 - val_loss: 4.6780 - val_accuracy: 0.1111\n",
      "Epoch 80/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.6926 - accuracy: 0.2444 - val_loss: 4.1676 - val_accuracy: 0.1889\n",
      "Epoch 81/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 3.0743 - accuracy: 0.2232 - val_loss: 3.0258 - val_accuracy: 0.1889\n",
      "Epoch 82/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.2335 - accuracy: 0.2706 - val_loss: 3.8363 - val_accuracy: 0.2778\n",
      "Epoch 83/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.2781 - accuracy: 0.2756 - val_loss: 5.5149 - val_accuracy: 0.0556\n",
      "Epoch 84/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.6571 - accuracy: 0.2419 - val_loss: 3.6717 - val_accuracy: 0.1111\n",
      "Epoch 85/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.3397 - accuracy: 0.2681 - val_loss: 8.1487 - val_accuracy: 0.2778\n",
      "Epoch 86/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.7043 - accuracy: 0.2818 - val_loss: 4.0062 - val_accuracy: 0.1889\n",
      "Epoch 87/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6706 - accuracy: 0.2394 - val_loss: 3.9286 - val_accuracy: 0.0556\n",
      "Epoch 88/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5873 - accuracy: 0.2531 - val_loss: 4.8150 - val_accuracy: 0.1111\n",
      "Epoch 89/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4145 - accuracy: 0.2631 - val_loss: 5.0979 - val_accuracy: 0.2778\n",
      "Epoch 90/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5565 - accuracy: 0.2818 - val_loss: 3.0766 - val_accuracy: 0.1889\n",
      "Epoch 91/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4292 - accuracy: 0.2244 - val_loss: 3.4047 - val_accuracy: 0.1889\n",
      "Epoch 92/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6417 - accuracy: 0.2506 - val_loss: 6.5344 - val_accuracy: 0.2778\n",
      "Epoch 93/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6381 - accuracy: 0.2731 - val_loss: 4.9997 - val_accuracy: 0.2778\n",
      "Epoch 94/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.3549 - accuracy: 0.2781 - val_loss: 4.9247 - val_accuracy: 0.1111\n",
      "Epoch 95/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 3.0359 - accuracy: 0.2182 - val_loss: 4.0724 - val_accuracy: 0.0556\n",
      "Epoch 96/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4537 - accuracy: 0.2631 - val_loss: 6.7447 - val_accuracy: 0.2778\n",
      "Epoch 97/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6607 - accuracy: 0.2656 - val_loss: 4.2110 - val_accuracy: 0.1889\n",
      "Epoch 98/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6660 - accuracy: 0.2569 - val_loss: 3.3124 - val_accuracy: 0.2778\n",
      "Epoch 99/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6444 - accuracy: 0.2693 - val_loss: 7.9023 - val_accuracy: 0.2778\n",
      "Epoch 100/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.9552 - accuracy: 0.2569 - val_loss: 4.0943 - val_accuracy: 0.0556\n",
      "Epoch 101/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5792 - accuracy: 0.2481 - val_loss: 8.6916 - val_accuracy: 0.1889\n",
      "Epoch 102/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 3.4032 - accuracy: 0.2357 - val_loss: 3.0880 - val_accuracy: 0.2778\n",
      "Epoch 103/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3578 - accuracy: 0.2880 - val_loss: 3.0041 - val_accuracy: 0.2778\n",
      "Epoch 104/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.4119 - accuracy: 0.2706 - val_loss: 10.3389 - val_accuracy: 0.0556\n",
      "Epoch 105/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 3.2123 - accuracy: 0.2431 - val_loss: 7.3097 - val_accuracy: 0.2778\n",
      "Epoch 106/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 3.0609 - accuracy: 0.2581 - val_loss: 3.2358 - val_accuracy: 0.2778\n",
      "Epoch 107/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2223 - accuracy: 0.2756 - val_loss: 3.0432 - val_accuracy: 0.2778\n",
      "Epoch 108/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.8188 - accuracy: 0.2481 - val_loss: 4.6604 - val_accuracy: 0.1111\n",
      "Epoch 109/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5054 - accuracy: 0.2693 - val_loss: 3.6282 - val_accuracy: 0.1889\n",
      "Epoch 110/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4662 - accuracy: 0.2805 - val_loss: 4.0558 - val_accuracy: 0.1111\n",
      "Epoch 111/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.3873 - accuracy: 0.2556 - val_loss: 4.1385 - val_accuracy: 0.1111\n",
      "Epoch 112/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.7088 - accuracy: 0.2319 - val_loss: 3.9655 - val_accuracy: 0.1889\n",
      "Epoch 113/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.5470 - accuracy: 0.2581 - val_loss: 3.8784 - val_accuracy: 0.0111\n",
      "Epoch 114/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.6684 - accuracy: 0.2107 - val_loss: 4.3026 - val_accuracy: 0.2778\n",
      "Epoch 115/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.1634 - accuracy: 0.3329 - val_loss: 3.0414 - val_accuracy: 0.2778\n",
      "Epoch 116/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4679 - accuracy: 0.2631 - val_loss: 3.5377 - val_accuracy: 0.1889\n",
      "Epoch 117/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5842 - accuracy: 0.2444 - val_loss: 4.6255 - val_accuracy: 0.2778\n",
      "Epoch 118/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.4394 - accuracy: 0.2743 - val_loss: 5.1653 - val_accuracy: 0.1889\n",
      "Epoch 119/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.6086 - accuracy: 0.2369 - val_loss: 4.0791 - val_accuracy: 0.1889\n",
      "Epoch 120/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.5594 - accuracy: 0.2706 - val_loss: 8.0075 - val_accuracy: 0.2778\n",
      "Epoch 121/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 3.1662 - accuracy: 0.2544 - val_loss: 5.5915 - val_accuracy: 0.2778\n",
      "Epoch 122/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3255 - accuracy: 0.2905 - val_loss: 6.8014 - val_accuracy: 0.2778\n",
      "Epoch 123/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.7540 - accuracy: 0.2781 - val_loss: 3.6659 - val_accuracy: 0.1889\n",
      "Epoch 124/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.6326 - accuracy: 0.2406 - val_loss: 8.0848 - val_accuracy: 0.2778\n",
      "Epoch 125/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.7984 - accuracy: 0.2905 - val_loss: 7.9154 - val_accuracy: 0.2778\n",
      "Epoch 126/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.7224 - accuracy: 0.2681 - val_loss: 5.5569 - val_accuracy: 0.2778\n",
      "Epoch 127/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.7917 - accuracy: 0.2718 - val_loss: 4.6698 - val_accuracy: 0.2778\n",
      "Epoch 128/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4057 - accuracy: 0.2905 - val_loss: 4.3625 - val_accuracy: 0.1889\n",
      "Epoch 129/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.3998 - accuracy: 0.2618 - val_loss: 4.5251 - val_accuracy: 0.1889\n",
      "Epoch 130/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5862 - accuracy: 0.2681 - val_loss: 9.3081 - val_accuracy: 0.1111\n",
      "Epoch 131/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.9333 - accuracy: 0.2731 - val_loss: 5.6699 - val_accuracy: 0.0222\n",
      "Epoch 132/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.5291 - accuracy: 0.2618 - val_loss: 9.2927 - val_accuracy: 0.1889\n",
      "Epoch 133/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.9557 - accuracy: 0.2930 - val_loss: 4.3144 - val_accuracy: 0.2778\n",
      "Epoch 134/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.2136 - accuracy: 0.2955 - val_loss: 3.8111 - val_accuracy: 0.2778\n",
      "Epoch 135/150\n",
      "802/802 [==============================] - 0s 52us/step - loss: 2.5553 - accuracy: 0.2556 - val_loss: 8.1624 - val_accuracy: 0.1889\n",
      "Epoch 136/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 3.0391 - accuracy: 0.2244 - val_loss: 4.1725 - val_accuracy: 0.0222\n",
      "Epoch 137/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5863 - accuracy: 0.2369 - val_loss: 4.4376 - val_accuracy: 0.0556\n",
      "Epoch 138/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.5519 - accuracy: 0.2519 - val_loss: 7.2216 - val_accuracy: 0.2778\n",
      "Epoch 139/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5308 - accuracy: 0.3005 - val_loss: 3.0764 - val_accuracy: 0.2778\n",
      "Epoch 140/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.4203 - accuracy: 0.2693 - val_loss: 4.8653 - val_accuracy: 0.0111\n",
      "Epoch 141/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.4035 - accuracy: 0.2643 - val_loss: 7.5627 - val_accuracy: 0.2778\n",
      "Epoch 142/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 56us/step - loss: 2.8029 - accuracy: 0.2880 - val_loss: 4.0228 - val_accuracy: 0.0556\n",
      "Epoch 143/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.6170 - accuracy: 0.2382 - val_loss: 3.2335 - val_accuracy: 0.1889\n",
      "Epoch 144/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5180 - accuracy: 0.2618 - val_loss: 2.4499 - val_accuracy: 0.2778\n",
      "Epoch 145/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.2108 - accuracy: 0.2668 - val_loss: 5.4418 - val_accuracy: 0.2778\n",
      "Epoch 146/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4098 - accuracy: 0.3042 - val_loss: 4.5004 - val_accuracy: 0.1111\n",
      "Epoch 147/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.8780 - accuracy: 0.2556 - val_loss: 3.1157 - val_accuracy: 0.2778\n",
      "Epoch 148/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6205 - accuracy: 0.2756 - val_loss: 3.5703 - val_accuracy: 0.1889\n",
      "Epoch 149/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5635 - accuracy: 0.2332 - val_loss: 4.6518 - val_accuracy: 0.2778\n",
      "Epoch 150/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3953 - accuracy: 0.2668 - val_loss: 10.4127 - val_accuracy: 0.1889\n",
      "460/460 [==============================] - 0s 37us/step\n",
      "Loss: 11.06\n",
      "Accuracy 0.15\n",
      "Train on 802 samples, validate on 90 samples\n",
      "Epoch 1/150\n",
      "802/802 [==============================] - 1s 701us/step - loss: 2.3868 - accuracy: 0.2531 - val_loss: 3.2936 - val_accuracy: 0.2778\n",
      "Epoch 2/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.2814 - accuracy: 0.2880 - val_loss: 4.6729 - val_accuracy: 0.2778\n",
      "Epoch 3/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5310 - accuracy: 0.2656 - val_loss: 5.2138 - val_accuracy: 0.2778\n",
      "Epoch 4/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4310 - accuracy: 0.2955 - val_loss: 4.4984 - val_accuracy: 0.2778\n",
      "Epoch 5/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.3548 - accuracy: 0.2743 - val_loss: 3.1050 - val_accuracy: 0.2778\n",
      "Epoch 6/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.5515 - accuracy: 0.2668 - val_loss: 8.0721 - val_accuracy: 0.2778\n",
      "Epoch 7/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.9143 - accuracy: 0.2556 - val_loss: 6.2929 - val_accuracy: 0.2778\n",
      "Epoch 8/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4944 - accuracy: 0.2756 - val_loss: 4.0959 - val_accuracy: 0.1111\n",
      "Epoch 9/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.2502 - accuracy: 0.2905 - val_loss: 3.9565 - val_accuracy: 0.0222\n",
      "Epoch 10/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.2324 - accuracy: 0.2544 - val_loss: 8.6203 - val_accuracy: 0.1889\n",
      "Epoch 11/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.7816 - accuracy: 0.2618 - val_loss: 9.7417 - val_accuracy: 0.1111\n",
      "Epoch 12/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 3.1532 - accuracy: 0.2581 - val_loss: 3.2557 - val_accuracy: 0.2778\n",
      "Epoch 13/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4622 - accuracy: 0.2793 - val_loss: 4.9488 - val_accuracy: 0.2778\n",
      "Epoch 14/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.2578 - accuracy: 0.2893 - val_loss: 6.0036 - val_accuracy: 0.2778\n",
      "Epoch 15/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4845 - accuracy: 0.2830 - val_loss: 9.3295 - val_accuracy: 0.1889\n",
      "Epoch 16/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 3.0229 - accuracy: 0.2781 - val_loss: 3.5802 - val_accuracy: 0.1889\n",
      "Epoch 17/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6538 - accuracy: 0.2519 - val_loss: 5.8527 - val_accuracy: 0.0222\n",
      "Epoch 18/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6768 - accuracy: 0.2257 - val_loss: 4.6604 - val_accuracy: 0.1889\n",
      "Epoch 19/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5342 - accuracy: 0.2718 - val_loss: 3.6624 - val_accuracy: 0.2778\n",
      "Epoch 20/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5406 - accuracy: 0.2618 - val_loss: 2.9547 - val_accuracy: 0.2778\n",
      "Epoch 21/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4457 - accuracy: 0.2668 - val_loss: 4.1081 - val_accuracy: 0.1111\n",
      "Epoch 22/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 3.4026 - accuracy: 0.2070 - val_loss: 4.2640 - val_accuracy: 0.0111\n",
      "Epoch 23/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3868 - accuracy: 0.2594 - val_loss: 4.1265 - val_accuracy: 0.1889\n",
      "Epoch 24/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.3592 - accuracy: 0.2793 - val_loss: 5.3130 - val_accuracy: 0.2778\n",
      "Epoch 25/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5168 - accuracy: 0.2818 - val_loss: 3.8277 - val_accuracy: 0.0111\n",
      "Epoch 26/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2223 - accuracy: 0.2344 - val_loss: 3.8280 - val_accuracy: 0.0556\n",
      "Epoch 27/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.7762 - accuracy: 0.2456 - val_loss: 5.5794 - val_accuracy: 0.1111\n",
      "Epoch 28/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.7027 - accuracy: 0.2531 - val_loss: 3.8728 - val_accuracy: 0.2778\n",
      "Epoch 29/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.3107 - accuracy: 0.2818 - val_loss: 4.2776 - val_accuracy: 0.0222\n",
      "Epoch 30/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3777 - accuracy: 0.2294 - val_loss: 8.2015 - val_accuracy: 0.2778\n",
      "Epoch 31/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 3.0359 - accuracy: 0.2805 - val_loss: 2.6164 - val_accuracy: 0.2778\n",
      "Epoch 32/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5270 - accuracy: 0.2693 - val_loss: 7.9786 - val_accuracy: 0.2778\n",
      "Epoch 33/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.7564 - accuracy: 0.2993 - val_loss: 9.0322 - val_accuracy: 0.1889\n",
      "Epoch 34/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.9456 - accuracy: 0.2793 - val_loss: 9.6655 - val_accuracy: 0.1889\n",
      "Epoch 35/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 3.1016 - accuracy: 0.2681 - val_loss: 2.9779 - val_accuracy: 0.2778\n",
      "Epoch 36/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.5787 - accuracy: 0.2506 - val_loss: 7.5351 - val_accuracy: 0.2778\n",
      "Epoch 37/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6040 - accuracy: 0.2943 - val_loss: 5.1086 - val_accuracy: 0.2778\n",
      "Epoch 38/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4594 - accuracy: 0.2930 - val_loss: 3.8414 - val_accuracy: 0.0556\n",
      "Epoch 39/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3083 - accuracy: 0.2656 - val_loss: 3.9474 - val_accuracy: 0.2778\n",
      "Epoch 40/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3516 - accuracy: 0.2793 - val_loss: 3.7602 - val_accuracy: 0.1889\n",
      "Epoch 41/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5256 - accuracy: 0.2569 - val_loss: 5.8239 - val_accuracy: 0.1889\n",
      "Epoch 42/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4652 - accuracy: 0.2868 - val_loss: 4.1484 - val_accuracy: 0.1111\n",
      "Epoch 43/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5787 - accuracy: 0.2581 - val_loss: 3.6470 - val_accuracy: 0.2778\n",
      "Epoch 44/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5579 - accuracy: 0.2793 - val_loss: 4.0497 - val_accuracy: 0.1889\n",
      "Epoch 45/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.4475 - accuracy: 0.2793 - val_loss: 3.0922 - val_accuracy: 0.2778\n",
      "Epoch 46/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.3772 - accuracy: 0.2756 - val_loss: 4.0875 - val_accuracy: 0.1111\n",
      "Epoch 47/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.6346 - accuracy: 0.2394 - val_loss: 2.9873 - val_accuracy: 0.2778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.2769 - accuracy: 0.2631 - val_loss: 4.7485 - val_accuracy: 0.2778\n",
      "Epoch 49/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4272 - accuracy: 0.2968 - val_loss: 3.9340 - val_accuracy: 0.1111\n",
      "Epoch 50/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5422 - accuracy: 0.2693 - val_loss: 4.5507 - val_accuracy: 0.1111\n",
      "Epoch 51/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4055 - accuracy: 0.2631 - val_loss: 8.9279 - val_accuracy: 0.1889\n",
      "Epoch 52/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 3.1850 - accuracy: 0.2581 - val_loss: 7.8021 - val_accuracy: 0.2778\n",
      "Epoch 53/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.7734 - accuracy: 0.3105 - val_loss: 3.6878 - val_accuracy: 0.2778\n",
      "Epoch 54/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.2953 - accuracy: 0.2768 - val_loss: 4.7411 - val_accuracy: 0.2778\n",
      "Epoch 55/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.6793 - accuracy: 0.2706 - val_loss: 3.0206 - val_accuracy: 0.1889\n",
      "Epoch 56/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.1783 - accuracy: 0.2955 - val_loss: 4.6226 - val_accuracy: 0.2778\n",
      "Epoch 57/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3746 - accuracy: 0.2880 - val_loss: 5.2477 - val_accuracy: 0.2778\n",
      "Epoch 58/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5982 - accuracy: 0.2606 - val_loss: 6.8160 - val_accuracy: 0.2778\n",
      "Epoch 59/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6118 - accuracy: 0.2706 - val_loss: 4.0893 - val_accuracy: 0.1111\n",
      "Epoch 60/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.4753 - accuracy: 0.2431 - val_loss: 8.0028 - val_accuracy: 0.2778\n",
      "Epoch 61/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6806 - accuracy: 0.2880 - val_loss: 7.0842 - val_accuracy: 0.2778\n",
      "Epoch 62/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4691 - accuracy: 0.2905 - val_loss: 3.6544 - val_accuracy: 0.1889\n",
      "Epoch 63/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.7396 - accuracy: 0.2494 - val_loss: 3.2984 - val_accuracy: 0.1889\n",
      "Epoch 64/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4704 - accuracy: 0.2643 - val_loss: 2.7683 - val_accuracy: 0.2778\n",
      "Epoch 65/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.2277 - accuracy: 0.2968 - val_loss: 4.6448 - val_accuracy: 0.1111\n",
      "Epoch 66/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4343 - accuracy: 0.2643 - val_loss: 7.2575 - val_accuracy: 0.2778\n",
      "Epoch 67/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5858 - accuracy: 0.3017 - val_loss: 4.8423 - val_accuracy: 0.2778\n",
      "Epoch 68/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.4953 - accuracy: 0.2880 - val_loss: 2.9643 - val_accuracy: 0.2778\n",
      "Epoch 69/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3194 - accuracy: 0.2818 - val_loss: 6.6603 - val_accuracy: 0.2778\n",
      "Epoch 70/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5895 - accuracy: 0.2818 - val_loss: 3.1649 - val_accuracy: 0.1889\n",
      "Epoch 71/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3446 - accuracy: 0.2656 - val_loss: 9.2350 - val_accuracy: 0.1889\n",
      "Epoch 72/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 3.3465 - accuracy: 0.2419 - val_loss: 4.6843 - val_accuracy: 0.1889\n",
      "Epoch 73/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.7432 - accuracy: 0.2594 - val_loss: 4.3334 - val_accuracy: 0.1889\n",
      "Epoch 74/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4916 - accuracy: 0.2606 - val_loss: 3.3059 - val_accuracy: 0.2778\n",
      "Epoch 75/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.4345 - accuracy: 0.2893 - val_loss: 3.9831 - val_accuracy: 0.1111\n",
      "Epoch 76/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4842 - accuracy: 0.2444 - val_loss: 4.8960 - val_accuracy: 0.2778\n",
      "Epoch 77/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5621 - accuracy: 0.2431 - val_loss: 4.5448 - val_accuracy: 0.1111\n",
      "Epoch 78/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6218 - accuracy: 0.2431 - val_loss: 5.3686 - val_accuracy: 0.1889\n",
      "Epoch 79/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.3760 - accuracy: 0.2606 - val_loss: 3.1869 - val_accuracy: 0.2778\n",
      "Epoch 80/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.5871 - accuracy: 0.2868 - val_loss: 7.4735 - val_accuracy: 0.2778\n",
      "Epoch 81/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5767 - accuracy: 0.2880 - val_loss: 6.6426 - val_accuracy: 0.2778\n",
      "Epoch 82/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.8084 - accuracy: 0.2718 - val_loss: 3.7661 - val_accuracy: 0.0111\n",
      "Epoch 83/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.3385 - accuracy: 0.2294 - val_loss: 3.8469 - val_accuracy: 0.1889\n",
      "Epoch 84/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.5900 - accuracy: 0.2581 - val_loss: 2.8683 - val_accuracy: 0.2778\n",
      "Epoch 85/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4121 - accuracy: 0.2581 - val_loss: 5.0510 - val_accuracy: 0.2778\n",
      "Epoch 86/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5721 - accuracy: 0.2693 - val_loss: 4.6210 - val_accuracy: 0.2778\n",
      "Epoch 87/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4890 - accuracy: 0.2070 - val_loss: 3.3898 - val_accuracy: 0.2778\n",
      "Epoch 88/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2033 - accuracy: 0.2805 - val_loss: 4.8447 - val_accuracy: 0.1111\n",
      "Epoch 89/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5511 - accuracy: 0.2419 - val_loss: 3.1046 - val_accuracy: 0.2778\n",
      "Epoch 90/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.8025 - accuracy: 0.2406 - val_loss: 7.1513 - val_accuracy: 0.2778\n",
      "Epoch 91/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.7592 - accuracy: 0.2905 - val_loss: 3.0264 - val_accuracy: 0.2778\n",
      "Epoch 92/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3057 - accuracy: 0.2668 - val_loss: 4.3558 - val_accuracy: 0.2778\n",
      "Epoch 93/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.2844 - accuracy: 0.2594 - val_loss: 3.0332 - val_accuracy: 0.2778\n",
      "Epoch 94/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4909 - accuracy: 0.2756 - val_loss: 5.3225 - val_accuracy: 0.1111\n",
      "Epoch 95/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.7117 - accuracy: 0.2431 - val_loss: 3.8898 - val_accuracy: 0.1889\n",
      "Epoch 96/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.6212 - accuracy: 0.2207 - val_loss: 3.4213 - val_accuracy: 0.1889\n",
      "Epoch 97/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.3441 - accuracy: 0.2768 - val_loss: 5.2012 - val_accuracy: 0.1889\n",
      "Epoch 98/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4956 - accuracy: 0.2706 - val_loss: 4.2970 - val_accuracy: 0.2778\n",
      "Epoch 99/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2060 - accuracy: 0.2693 - val_loss: 7.7614 - val_accuracy: 0.2778\n",
      "Epoch 100/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 3.0588 - accuracy: 0.2880 - val_loss: 4.4397 - val_accuracy: 0.1111\n",
      "Epoch 101/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.7797 - accuracy: 0.2431 - val_loss: 6.6328 - val_accuracy: 0.2778\n",
      "Epoch 102/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5941 - accuracy: 0.2818 - val_loss: 3.1052 - val_accuracy: 0.2778\n",
      "Epoch 103/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6376 - accuracy: 0.2581 - val_loss: 3.1480 - val_accuracy: 0.2778\n",
      "Epoch 104/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.5496 - accuracy: 0.2618 - val_loss: 4.3449 - val_accuracy: 0.0111\n",
      "Epoch 105/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.4367 - accuracy: 0.2307 - val_loss: 3.1642 - val_accuracy: 0.1889\n",
      "Epoch 106/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.3302 - accuracy: 0.2693 - val_loss: 4.9748 - val_accuracy: 0.1111\n",
      "Epoch 107/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4639 - accuracy: 0.2444 - val_loss: 2.6544 - val_accuracy: 0.2778\n",
      "Epoch 108/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.0551 - accuracy: 0.3042 - val_loss: 3.1642 - val_accuracy: 0.1889\n",
      "Epoch 109/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6489 - accuracy: 0.2369 - val_loss: 2.8950 - val_accuracy: 0.2778\n",
      "Epoch 110/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4196 - accuracy: 0.2980 - val_loss: 3.7090 - val_accuracy: 0.1889\n",
      "Epoch 111/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.1382 - accuracy: 0.2955 - val_loss: 3.0261 - val_accuracy: 0.2778\n",
      "Epoch 112/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.1355 - accuracy: 0.3242 - val_loss: 2.8740 - val_accuracy: 0.2778\n",
      "Epoch 113/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.2012 - accuracy: 0.2731 - val_loss: 3.8972 - val_accuracy: 0.1111\n",
      "Epoch 114/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.5721 - accuracy: 0.2307 - val_loss: 6.3078 - val_accuracy: 0.2778\n",
      "Epoch 115/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.6825 - accuracy: 0.2830 - val_loss: 3.0940 - val_accuracy: 0.2778\n",
      "Epoch 116/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4230 - accuracy: 0.2843 - val_loss: 5.3460 - val_accuracy: 0.1889\n",
      "Epoch 117/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4518 - accuracy: 0.2968 - val_loss: 4.0810 - val_accuracy: 0.1111\n",
      "Epoch 118/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.1624 - accuracy: 0.2519 - val_loss: 7.4331 - val_accuracy: 0.2778\n",
      "Epoch 119/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6912 - accuracy: 0.2968 - val_loss: 6.5332 - val_accuracy: 0.2778\n",
      "Epoch 120/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4420 - accuracy: 0.3042 - val_loss: 4.2796 - val_accuracy: 0.0556\n",
      "Epoch 121/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 3.0232 - accuracy: 0.2307 - val_loss: 4.5487 - val_accuracy: 0.2778\n",
      "Epoch 122/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.1873 - accuracy: 0.2805 - val_loss: 3.9728 - val_accuracy: 0.1889\n",
      "Epoch 123/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4057 - accuracy: 0.2606 - val_loss: 4.9440 - val_accuracy: 0.1111\n",
      "Epoch 124/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.7571 - accuracy: 0.2431 - val_loss: 4.3445 - val_accuracy: 0.1889\n",
      "Epoch 125/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.2947 - accuracy: 0.2893 - val_loss: 4.3466 - val_accuracy: 0.0111\n",
      "Epoch 126/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.1654 - accuracy: 0.2519 - val_loss: 4.0554 - val_accuracy: 0.2778\n",
      "Epoch 127/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3766 - accuracy: 0.2868 - val_loss: 6.9212 - val_accuracy: 0.2778\n",
      "Epoch 128/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6596 - accuracy: 0.2731 - val_loss: 5.2446 - val_accuracy: 0.2778\n",
      "Epoch 129/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4605 - accuracy: 0.2631 - val_loss: 7.7944 - val_accuracy: 0.2778\n",
      "Epoch 130/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.7844 - accuracy: 0.2606 - val_loss: 8.0853 - val_accuracy: 0.2778\n",
      "Epoch 131/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.6874 - accuracy: 0.3080 - val_loss: 3.0263 - val_accuracy: 0.2778\n",
      "Epoch 132/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3696 - accuracy: 0.2606 - val_loss: 4.8470 - val_accuracy: 0.0333\n",
      "Epoch 133/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.6313 - accuracy: 0.2294 - val_loss: 4.8465 - val_accuracy: 0.1111\n",
      "Epoch 134/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.7952 - accuracy: 0.2269 - val_loss: 4.1266 - val_accuracy: 0.2778\n",
      "Epoch 135/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3753 - accuracy: 0.2805 - val_loss: 4.0781 - val_accuracy: 0.1111\n",
      "Epoch 136/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.8146 - accuracy: 0.2382 - val_loss: 3.9441 - val_accuracy: 0.2778\n",
      "Epoch 137/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4445 - accuracy: 0.2718 - val_loss: 3.2010 - val_accuracy: 0.2778\n",
      "Epoch 138/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4496 - accuracy: 0.2606 - val_loss: 2.7879 - val_accuracy: 0.2778\n",
      "Epoch 139/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.2307 - accuracy: 0.2656 - val_loss: 4.5702 - val_accuracy: 0.2778\n",
      "Epoch 140/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.3005 - accuracy: 0.2756 - val_loss: 5.2932 - val_accuracy: 0.1889\n",
      "Epoch 141/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6404 - accuracy: 0.2469 - val_loss: 4.0326 - val_accuracy: 0.1111\n",
      "Epoch 142/150\n",
      "802/802 [==============================] - 0s 55us/step - loss: 2.2915 - accuracy: 0.2544 - val_loss: 2.7831 - val_accuracy: 0.2778\n",
      "Epoch 143/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3330 - accuracy: 0.2743 - val_loss: 8.2952 - val_accuracy: 0.2778\n",
      "Epoch 144/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.8707 - accuracy: 0.2581 - val_loss: 4.2510 - val_accuracy: 0.0333\n",
      "Epoch 145/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4035 - accuracy: 0.2394 - val_loss: 3.3787 - val_accuracy: 0.2778\n",
      "Epoch 146/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.2965 - accuracy: 0.3105 - val_loss: 3.8059 - val_accuracy: 0.2778\n",
      "Epoch 147/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.0392 - accuracy: 0.3105 - val_loss: 3.1395 - val_accuracy: 0.2778\n",
      "Epoch 148/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.7769 - accuracy: 0.2668 - val_loss: 4.1567 - val_accuracy: 0.2778\n",
      "Epoch 149/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.4259 - accuracy: 0.2743 - val_loss: 6.1725 - val_accuracy: 0.2778\n",
      "Epoch 150/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.4368 - accuracy: 0.3092 - val_loss: 2.9522 - val_accuracy: 0.2778\n",
      "460/460 [==============================] - 0s 39us/step\n",
      "Loss: 2.73\n",
      "Accuracy 0.29\n",
      "Train on 802 samples, validate on 90 samples\n",
      "Epoch 1/150\n",
      "802/802 [==============================] - 1s 798us/step - loss: 2.1943 - accuracy: 0.2531 - val_loss: 3.4173 - val_accuracy: 0.1889\n",
      "Epoch 2/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.7041 - accuracy: 0.2581 - val_loss: 3.9212 - val_accuracy: 0.0556\n",
      "Epoch 3/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.2605 - accuracy: 0.2656 - val_loss: 3.8447 - val_accuracy: 0.2778\n",
      "Epoch 4/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.2803 - accuracy: 0.2905 - val_loss: 7.2078 - val_accuracy: 0.2778\n",
      "Epoch 5/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.6172 - accuracy: 0.3130 - val_loss: 4.0439 - val_accuracy: 0.2778\n",
      "Epoch 6/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.1161 - accuracy: 0.3055 - val_loss: 3.9858 - val_accuracy: 0.1111\n",
      "Epoch 7/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.5051 - accuracy: 0.2781 - val_loss: 3.1404 - val_accuracy: 0.1889\n",
      "Epoch 8/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.1323 - accuracy: 0.2955 - val_loss: 3.5337 - val_accuracy: 0.2778\n",
      "Epoch 9/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 61us/step - loss: 2.3536 - accuracy: 0.2631 - val_loss: 4.6314 - val_accuracy: 0.1111\n",
      "Epoch 10/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5977 - accuracy: 0.2643 - val_loss: 3.3156 - val_accuracy: 0.2778\n",
      "Epoch 11/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.1691 - accuracy: 0.2930 - val_loss: 4.6018 - val_accuracy: 0.1889\n",
      "Epoch 12/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.6750 - accuracy: 0.2656 - val_loss: 4.2355 - val_accuracy: 0.1889\n",
      "Epoch 13/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.7431 - accuracy: 0.2556 - val_loss: 5.8546 - val_accuracy: 0.1889\n",
      "Epoch 14/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6244 - accuracy: 0.2868 - val_loss: 6.4786 - val_accuracy: 0.2778\n",
      "Epoch 15/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3763 - accuracy: 0.3067 - val_loss: 4.5185 - val_accuracy: 0.2778\n",
      "Epoch 16/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3969 - accuracy: 0.2768 - val_loss: 4.6510 - val_accuracy: 0.1111\n",
      "Epoch 17/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.9564 - accuracy: 0.2195 - val_loss: 3.4331 - val_accuracy: 0.1889\n",
      "Epoch 18/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.4123 - accuracy: 0.2606 - val_loss: 7.6364 - val_accuracy: 0.2778\n",
      "Epoch 19/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.9382 - accuracy: 0.2431 - val_loss: 5.7093 - val_accuracy: 0.2778\n",
      "Epoch 20/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6285 - accuracy: 0.2918 - val_loss: 2.8078 - val_accuracy: 0.2778\n",
      "Epoch 21/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4346 - accuracy: 0.2581 - val_loss: 2.9010 - val_accuracy: 0.2778\n",
      "Epoch 22/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3348 - accuracy: 0.2893 - val_loss: 4.1095 - val_accuracy: 0.0333\n",
      "Epoch 23/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4099 - accuracy: 0.2307 - val_loss: 4.2869 - val_accuracy: 0.1111\n",
      "Epoch 24/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.7039 - accuracy: 0.2307 - val_loss: 2.8862 - val_accuracy: 0.2778\n",
      "Epoch 25/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.1423 - accuracy: 0.2893 - val_loss: 3.6435 - val_accuracy: 0.1889\n",
      "Epoch 26/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.8145 - accuracy: 0.2332 - val_loss: 3.7271 - val_accuracy: 0.2778\n",
      "Epoch 27/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3508 - accuracy: 0.2830 - val_loss: 6.7285 - val_accuracy: 0.2778\n",
      "Epoch 28/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.8630 - accuracy: 0.2718 - val_loss: 7.6836 - val_accuracy: 0.2778\n",
      "Epoch 29/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.8020 - accuracy: 0.2805 - val_loss: 5.3596 - val_accuracy: 0.2778\n",
      "Epoch 30/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5788 - accuracy: 0.2781 - val_loss: 3.4074 - val_accuracy: 0.2778\n",
      "Epoch 31/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4203 - accuracy: 0.2631 - val_loss: 5.6674 - val_accuracy: 0.1111\n",
      "Epoch 32/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.7095 - accuracy: 0.2544 - val_loss: 4.1030 - val_accuracy: 0.0556\n",
      "Epoch 33/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3888 - accuracy: 0.2456 - val_loss: 4.2075 - val_accuracy: 0.1111\n",
      "Epoch 34/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6219 - accuracy: 0.2406 - val_loss: 3.1620 - val_accuracy: 0.1889\n",
      "Epoch 35/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.3104 - accuracy: 0.2855 - val_loss: 4.7213 - val_accuracy: 0.1111\n",
      "Epoch 36/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4494 - accuracy: 0.2631 - val_loss: 7.7705 - val_accuracy: 0.2778\n",
      "Epoch 37/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.8182 - accuracy: 0.2855 - val_loss: 4.2521 - val_accuracy: 0.1889\n",
      "Epoch 38/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4819 - accuracy: 0.2419 - val_loss: 3.8643 - val_accuracy: 0.1889\n",
      "Epoch 39/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5370 - accuracy: 0.2631 - val_loss: 3.9472 - val_accuracy: 0.1111\n",
      "Epoch 40/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6239 - accuracy: 0.2456 - val_loss: 4.9744 - val_accuracy: 0.0333\n",
      "Epoch 41/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.3789 - accuracy: 0.2419 - val_loss: 4.8772 - val_accuracy: 0.2778\n",
      "Epoch 42/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.7865 - accuracy: 0.2382 - val_loss: 7.9803 - val_accuracy: 0.2778\n",
      "Epoch 43/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.7240 - accuracy: 0.2731 - val_loss: 6.5233 - val_accuracy: 0.1111\n",
      "Epoch 44/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.8251 - accuracy: 0.2307 - val_loss: 5.4385 - val_accuracy: 0.1111\n",
      "Epoch 45/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4630 - accuracy: 0.2781 - val_loss: 2.9733 - val_accuracy: 0.2778\n",
      "Epoch 46/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3599 - accuracy: 0.2731 - val_loss: 5.4492 - val_accuracy: 0.2778\n",
      "Epoch 47/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.4939 - accuracy: 0.3005 - val_loss: 7.6673 - val_accuracy: 0.2778\n",
      "Epoch 48/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6473 - accuracy: 0.3055 - val_loss: 8.4658 - val_accuracy: 0.1889\n",
      "Epoch 49/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 3.0685 - accuracy: 0.2531 - val_loss: 3.6619 - val_accuracy: 0.1889\n",
      "Epoch 50/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.6799 - accuracy: 0.2531 - val_loss: 5.8860 - val_accuracy: 0.0556\n",
      "Epoch 51/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.4292 - accuracy: 0.2569 - val_loss: 3.8274 - val_accuracy: 0.1889\n",
      "Epoch 52/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4136 - accuracy: 0.2818 - val_loss: 4.1227 - val_accuracy: 0.1111\n",
      "Epoch 53/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.7764 - accuracy: 0.2406 - val_loss: 5.7867 - val_accuracy: 0.2778\n",
      "Epoch 54/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.5220 - accuracy: 0.2918 - val_loss: 3.6440 - val_accuracy: 0.1889\n",
      "Epoch 55/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.4287 - accuracy: 0.2993 - val_loss: 5.8424 - val_accuracy: 0.1111\n",
      "Epoch 56/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4217 - accuracy: 0.2793 - val_loss: 4.1992 - val_accuracy: 0.2778\n",
      "Epoch 57/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.5071 - accuracy: 0.2656 - val_loss: 4.9628 - val_accuracy: 0.2778\n",
      "Epoch 58/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.4351 - accuracy: 0.2918 - val_loss: 8.9799 - val_accuracy: 0.1889\n",
      "Epoch 59/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 3.1755 - accuracy: 0.2469 - val_loss: 7.9492 - val_accuracy: 0.2778\n",
      "Epoch 60/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.9040 - accuracy: 0.2768 - val_loss: 4.7759 - val_accuracy: 0.2778\n",
      "Epoch 61/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.3003 - accuracy: 0.3055 - val_loss: 5.9014 - val_accuracy: 0.0556\n",
      "Epoch 62/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.6861 - accuracy: 0.2481 - val_loss: 3.5785 - val_accuracy: 0.1889\n",
      "Epoch 63/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.5762 - accuracy: 0.2319 - val_loss: 3.8115 - val_accuracy: 0.1889\n",
      "Epoch 64/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5552 - accuracy: 0.2656 - val_loss: 4.7172 - val_accuracy: 0.1111\n",
      "Epoch 65/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.9918 - accuracy: 0.2257 - val_loss: 5.3771 - val_accuracy: 0.0333\n",
      "Epoch 66/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.6566 - accuracy: 0.2444 - val_loss: 4.3787 - val_accuracy: 0.1889\n",
      "Epoch 67/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.3555 - accuracy: 0.2843 - val_loss: 6.4821 - val_accuracy: 0.2778\n",
      "Epoch 68/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.7287 - accuracy: 0.2818 - val_loss: 3.0840 - val_accuracy: 0.2778\n",
      "Epoch 69/150\n",
      "802/802 [==============================] - 0s 85us/step - loss: 2.3608 - accuracy: 0.2980 - val_loss: 4.0669 - val_accuracy: 0.2778\n",
      "Epoch 70/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.2600 - accuracy: 0.3055 - val_loss: 4.8991 - val_accuracy: 0.1889\n",
      "Epoch 71/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.2342 - accuracy: 0.3067 - val_loss: 3.6252 - val_accuracy: 0.1889\n",
      "Epoch 72/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.9411 - accuracy: 0.2382 - val_loss: 5.3519 - val_accuracy: 0.1111\n",
      "Epoch 73/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.6025 - accuracy: 0.2431 - val_loss: 3.0329 - val_accuracy: 0.2778\n",
      "Epoch 74/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.6664 - accuracy: 0.2668 - val_loss: 4.7359 - val_accuracy: 0.1111\n",
      "Epoch 75/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4563 - accuracy: 0.2731 - val_loss: 3.4390 - val_accuracy: 0.2778\n",
      "Epoch 76/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5201 - accuracy: 0.2643 - val_loss: 4.4895 - val_accuracy: 0.1111\n",
      "Epoch 77/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6436 - accuracy: 0.2419 - val_loss: 3.7468 - val_accuracy: 0.2778\n",
      "Epoch 78/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.2030 - accuracy: 0.2731 - val_loss: 4.3463 - val_accuracy: 0.1111\n",
      "Epoch 79/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6742 - accuracy: 0.2531 - val_loss: 2.8474 - val_accuracy: 0.2778\n",
      "Epoch 80/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3616 - accuracy: 0.2718 - val_loss: 4.0351 - val_accuracy: 0.1111\n",
      "Epoch 81/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.8046 - accuracy: 0.2257 - val_loss: 3.6318 - val_accuracy: 0.0111\n",
      "Epoch 82/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3145 - accuracy: 0.2431 - val_loss: 3.0066 - val_accuracy: 0.2778\n",
      "Epoch 83/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.2569 - accuracy: 0.2893 - val_loss: 3.9846 - val_accuracy: 0.0111\n",
      "Epoch 84/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3718 - accuracy: 0.2456 - val_loss: 4.0161 - val_accuracy: 0.1889\n",
      "Epoch 85/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.5678 - accuracy: 0.2618 - val_loss: 5.1288 - val_accuracy: 0.1889\n",
      "Epoch 86/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5604 - accuracy: 0.2731 - val_loss: 3.2285 - val_accuracy: 0.1889\n",
      "Epoch 87/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.1847 - accuracy: 0.2980 - val_loss: 6.1622 - val_accuracy: 0.2778\n",
      "Epoch 88/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5413 - accuracy: 0.3067 - val_loss: 3.0345 - val_accuracy: 0.2778\n",
      "Epoch 89/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.4951 - accuracy: 0.2805 - val_loss: 3.8314 - val_accuracy: 0.1111\n",
      "Epoch 90/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.4731 - accuracy: 0.2594 - val_loss: 3.2253 - val_accuracy: 0.2778\n",
      "Epoch 91/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.2762 - accuracy: 0.2469 - val_loss: 5.0049 - val_accuracy: 0.1111\n",
      "Epoch 92/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6240 - accuracy: 0.2519 - val_loss: 5.7661 - val_accuracy: 0.2778\n",
      "Epoch 93/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.6281 - accuracy: 0.2805 - val_loss: 8.5726 - val_accuracy: 0.1889\n",
      "Epoch 94/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 3.1259 - accuracy: 0.2145 - val_loss: 7.5022 - val_accuracy: 0.2778\n",
      "Epoch 95/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.8325 - accuracy: 0.2993 - val_loss: 3.4817 - val_accuracy: 0.2778\n",
      "Epoch 96/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4883 - accuracy: 0.2643 - val_loss: 2.7748 - val_accuracy: 0.2778\n",
      "Epoch 97/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.4107 - accuracy: 0.2905 - val_loss: 3.7337 - val_accuracy: 0.2778\n",
      "Epoch 98/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.1229 - accuracy: 0.3130 - val_loss: 4.3415 - val_accuracy: 0.0222\n",
      "Epoch 99/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.2599 - accuracy: 0.2594 - val_loss: 4.8297 - val_accuracy: 0.0556\n",
      "Epoch 100/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.7141 - accuracy: 0.2631 - val_loss: 4.4055 - val_accuracy: 0.0333\n",
      "Epoch 101/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.3561 - accuracy: 0.2494 - val_loss: 3.0918 - val_accuracy: 0.2778\n",
      "Epoch 102/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3229 - accuracy: 0.2818 - val_loss: 9.9053 - val_accuracy: 0.0556\n",
      "Epoch 103/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 3.1026 - accuracy: 0.2556 - val_loss: 2.9209 - val_accuracy: 0.2778\n",
      "Epoch 104/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5255 - accuracy: 0.2631 - val_loss: 3.4200 - val_accuracy: 0.2778\n",
      "Epoch 105/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.7742 - accuracy: 0.2431 - val_loss: 4.8195 - val_accuracy: 0.1111\n",
      "Epoch 106/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.4590 - accuracy: 0.2431 - val_loss: 4.2417 - val_accuracy: 0.0222\n",
      "Epoch 107/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2434 - accuracy: 0.2793 - val_loss: 4.3220 - val_accuracy: 0.1111\n",
      "Epoch 108/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.6033 - accuracy: 0.2606 - val_loss: 3.6265 - val_accuracy: 0.1889\n",
      "Epoch 109/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5194 - accuracy: 0.2781 - val_loss: 2.6611 - val_accuracy: 0.2778\n",
      "Epoch 110/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.1772 - accuracy: 0.2893 - val_loss: 3.9104 - val_accuracy: 0.0111\n",
      "Epoch 111/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.4809 - accuracy: 0.2195 - val_loss: 4.1974 - val_accuracy: 0.1111\n",
      "Epoch 112/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 3.0182 - accuracy: 0.2294 - val_loss: 3.0568 - val_accuracy: 0.1889\n",
      "Epoch 113/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.2158 - accuracy: 0.2731 - val_loss: 2.6760 - val_accuracy: 0.2778\n",
      "Epoch 114/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.1237 - accuracy: 0.3155 - val_loss: 3.2377 - val_accuracy: 0.2778\n",
      "Epoch 115/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3105 - accuracy: 0.2668 - val_loss: 5.6403 - val_accuracy: 0.1889\n",
      "Epoch 116/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 3.0589 - accuracy: 0.2294 - val_loss: 3.9631 - val_accuracy: 0.1889\n",
      "Epoch 117/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.6760 - accuracy: 0.2431 - val_loss: 4.8934 - val_accuracy: 0.1889\n",
      "Epoch 118/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.8927 - accuracy: 0.2406 - val_loss: 2.6866 - val_accuracy: 0.2778\n",
      "Epoch 119/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.1963 - accuracy: 0.2805 - val_loss: 4.4715 - val_accuracy: 0.2778\n",
      "Epoch 120/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4346 - accuracy: 0.2718 - val_loss: 5.0495 - val_accuracy: 0.1889\n",
      "Epoch 121/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 62us/step - loss: 2.4572 - accuracy: 0.2793 - val_loss: 3.7569 - val_accuracy: 0.1111\n",
      "Epoch 122/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.4077 - accuracy: 0.2818 - val_loss: 2.8009 - val_accuracy: 0.2778\n",
      "Epoch 123/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.2338 - accuracy: 0.2930 - val_loss: 6.6464 - val_accuracy: 0.2778\n",
      "Epoch 124/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6386 - accuracy: 0.2693 - val_loss: 3.4560 - val_accuracy: 0.1889\n",
      "Epoch 125/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3740 - accuracy: 0.2893 - val_loss: 3.7305 - val_accuracy: 0.1889\n",
      "Epoch 126/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3436 - accuracy: 0.2756 - val_loss: 4.6047 - val_accuracy: 0.1111\n",
      "Epoch 127/150\n",
      "802/802 [==============================] - 0s 82us/step - loss: 2.5210 - accuracy: 0.2594 - val_loss: 4.6815 - val_accuracy: 0.0111\n",
      "Epoch 128/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.2787 - accuracy: 0.2643 - val_loss: 4.2353 - val_accuracy: 0.2778\n",
      "Epoch 129/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4236 - accuracy: 0.2643 - val_loss: 3.9180 - val_accuracy: 0.2778\n",
      "Epoch 130/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3794 - accuracy: 0.2818 - val_loss: 4.7171 - val_accuracy: 0.1111\n",
      "Epoch 131/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4878 - accuracy: 0.2643 - val_loss: 4.1593 - val_accuracy: 0.2778\n",
      "Epoch 132/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.3091 - accuracy: 0.2768 - val_loss: 7.8945 - val_accuracy: 0.2778\n",
      "Epoch 133/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.9596 - accuracy: 0.2369 - val_loss: 2.7248 - val_accuracy: 0.0111\n",
      "Epoch 134/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.0778 - accuracy: 0.2344 - val_loss: 4.0408 - val_accuracy: 0.1111\n",
      "Epoch 135/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.8472 - accuracy: 0.2319 - val_loss: 3.7211 - val_accuracy: 0.1111\n",
      "Epoch 136/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4221 - accuracy: 0.2419 - val_loss: 5.3608 - val_accuracy: 0.0556\n",
      "Epoch 137/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.2721 - accuracy: 0.2581 - val_loss: 8.7934 - val_accuracy: 0.1889\n",
      "Epoch 138/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.8153 - accuracy: 0.2980 - val_loss: 4.7978 - val_accuracy: 0.1889\n",
      "Epoch 139/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5010 - accuracy: 0.2357 - val_loss: 5.6154 - val_accuracy: 0.1889\n",
      "Epoch 140/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6344 - accuracy: 0.2357 - val_loss: 4.7302 - val_accuracy: 0.1111\n",
      "Epoch 141/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3601 - accuracy: 0.2519 - val_loss: 2.9805 - val_accuracy: 0.2778\n",
      "Epoch 142/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3230 - accuracy: 0.2955 - val_loss: 3.9147 - val_accuracy: 0.0556\n",
      "Epoch 143/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3145 - accuracy: 0.2569 - val_loss: 5.0369 - val_accuracy: 0.1889\n",
      "Epoch 144/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6319 - accuracy: 0.2506 - val_loss: 6.9666 - val_accuracy: 0.2778\n",
      "Epoch 145/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.8508 - accuracy: 0.2606 - val_loss: 4.7201 - val_accuracy: 0.1889\n",
      "Epoch 146/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5469 - accuracy: 0.2618 - val_loss: 3.7631 - val_accuracy: 0.0333\n",
      "Epoch 147/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.2834 - accuracy: 0.2382 - val_loss: 4.0404 - val_accuracy: 0.1889\n",
      "Epoch 148/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6712 - accuracy: 0.2581 - val_loss: 3.1329 - val_accuracy: 0.2778\n",
      "Epoch 149/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4423 - accuracy: 0.2656 - val_loss: 3.2068 - val_accuracy: 0.1889\n",
      "Epoch 150/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.5504 - accuracy: 0.2431 - val_loss: 2.5714 - val_accuracy: 0.2778\n",
      "460/460 [==============================] - 0s 41us/step\n",
      "Loss: 2.32\n",
      "Accuracy 0.33\n",
      "Train on 802 samples, validate on 90 samples\n",
      "Epoch 1/150\n",
      "802/802 [==============================] - 1s 1ms/step - loss: 2.1223 - accuracy: 0.2569 - val_loss: 3.0872 - val_accuracy: 0.2778\n",
      "Epoch 2/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.5038 - accuracy: 0.2718 - val_loss: 3.3181 - val_accuracy: 0.2778\n",
      "Epoch 3/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.4152 - accuracy: 0.2818 - val_loss: 4.9820 - val_accuracy: 0.2778\n",
      "Epoch 4/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.4442 - accuracy: 0.2631 - val_loss: 3.0282 - val_accuracy: 0.2778\n",
      "Epoch 5/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.3680 - accuracy: 0.2706 - val_loss: 3.0627 - val_accuracy: 0.2778\n",
      "Epoch 6/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.2729 - accuracy: 0.2930 - val_loss: 6.7787 - val_accuracy: 0.2778\n",
      "Epoch 7/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.7795 - accuracy: 0.2556 - val_loss: 3.3268 - val_accuracy: 0.2778\n",
      "Epoch 8/150\n",
      "802/802 [==============================] - 0s 80us/step - loss: 2.5266 - accuracy: 0.2743 - val_loss: 3.7903 - val_accuracy: 0.0111\n",
      "Epoch 9/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.8956 - accuracy: 0.2070 - val_loss: 7.2064 - val_accuracy: 0.2778\n",
      "Epoch 10/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.7888 - accuracy: 0.2419 - val_loss: 4.3848 - val_accuracy: 0.1111\n",
      "Epoch 11/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.7848 - accuracy: 0.2606 - val_loss: 4.0060 - val_accuracy: 0.1111\n",
      "Epoch 12/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.5616 - accuracy: 0.2357 - val_loss: 2.5499 - val_accuracy: 0.2778\n",
      "Epoch 13/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.2448 - accuracy: 0.2768 - val_loss: 3.6316 - val_accuracy: 0.2778\n",
      "Epoch 14/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.6019 - accuracy: 0.2556 - val_loss: 3.9398 - val_accuracy: 0.2778\n",
      "Epoch 15/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.1564 - accuracy: 0.2980 - val_loss: 9.6851 - val_accuracy: 0.1111\n",
      "Epoch 16/150\n",
      "802/802 [==============================] - 0s 177us/step - loss: 3.0010 - accuracy: 0.2369 - val_loss: 9.4791 - val_accuracy: 0.1889\n",
      "Epoch 17/150\n",
      "802/802 [==============================] - 0s 208us/step - loss: 3.0083 - accuracy: 0.2357 - val_loss: 4.6212 - val_accuracy: 0.1111\n",
      "Epoch 18/150\n",
      "802/802 [==============================] - 0s 181us/step - loss: 2.8340 - accuracy: 0.2431 - val_loss: 3.8271 - val_accuracy: 0.2778\n",
      "Epoch 19/150\n",
      "802/802 [==============================] - 0s 121us/step - loss: 2.4534 - accuracy: 0.2743 - val_loss: 4.2217 - val_accuracy: 0.1111\n",
      "Epoch 20/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.9127 - accuracy: 0.2369 - val_loss: 3.0365 - val_accuracy: 0.2778\n",
      "Epoch 21/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.2488 - accuracy: 0.2731 - val_loss: 4.7988 - val_accuracy: 0.0111\n",
      "Epoch 22/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.5223 - accuracy: 0.2531 - val_loss: 7.0550 - val_accuracy: 0.2778\n",
      "Epoch 23/150\n",
      "802/802 [==============================] - 0s 80us/step - loss: 2.7233 - accuracy: 0.2681 - val_loss: 3.0219 - val_accuracy: 0.2778\n",
      "Epoch 24/150\n",
      "802/802 [==============================] - 0s 87us/step - loss: 2.6785 - accuracy: 0.2269 - val_loss: 4.7659 - val_accuracy: 0.1111\n",
      "Epoch 25/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.5593 - accuracy: 0.2718 - val_loss: 3.9517 - val_accuracy: 0.1111\n",
      "Epoch 26/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.2201 - accuracy: 0.2244 - val_loss: 5.5536 - val_accuracy: 0.0556\n",
      "Epoch 27/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.5592 - accuracy: 0.2718 - val_loss: 9.0523 - val_accuracy: 0.1889\n",
      "Epoch 28/150\n",
      "802/802 [==============================] - 0s 92us/step - loss: 2.8956 - accuracy: 0.2668 - val_loss: 4.0425 - val_accuracy: 0.1889\n",
      "Epoch 29/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.7891 - accuracy: 0.2643 - val_loss: 2.9843 - val_accuracy: 0.1889\n",
      "Epoch 30/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.1555 - accuracy: 0.2805 - val_loss: 3.0450 - val_accuracy: 0.2778\n",
      "Epoch 31/150\n",
      "802/802 [==============================] - 0s 138us/step - loss: 2.5251 - accuracy: 0.2581 - val_loss: 6.6340 - val_accuracy: 0.2778\n",
      "Epoch 32/150\n",
      "802/802 [==============================] - 0s 153us/step - loss: 2.6774 - accuracy: 0.2631 - val_loss: 3.1692 - val_accuracy: 0.2778\n",
      "Epoch 33/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.1019 - accuracy: 0.3017 - val_loss: 3.9298 - val_accuracy: 0.0333\n",
      "Epoch 34/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.6500 - accuracy: 0.2219 - val_loss: 4.5038 - val_accuracy: 0.0111\n",
      "Epoch 35/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.4523 - accuracy: 0.2406 - val_loss: 3.0603 - val_accuracy: 0.2778\n",
      "Epoch 36/150\n",
      "802/802 [==============================] - 0s 126us/step - loss: 2.2606 - accuracy: 0.2868 - val_loss: 3.4292 - val_accuracy: 0.2778\n",
      "Epoch 37/150\n",
      "802/802 [==============================] - 0s 156us/step - loss: 2.6156 - accuracy: 0.2332 - val_loss: 3.3951 - val_accuracy: 0.1889\n",
      "Epoch 38/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.2594 - accuracy: 0.2643 - val_loss: 4.4798 - val_accuracy: 0.0333\n",
      "Epoch 39/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.5774 - accuracy: 0.2344 - val_loss: 3.9685 - val_accuracy: 0.1111\n",
      "Epoch 40/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.5993 - accuracy: 0.2269 - val_loss: 3.2673 - val_accuracy: 0.2778\n",
      "Epoch 41/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.9734 - accuracy: 0.2419 - val_loss: 4.8310 - val_accuracy: 0.2778\n",
      "Epoch 42/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.5635 - accuracy: 0.2893 - val_loss: 4.5565 - val_accuracy: 0.0333\n",
      "Epoch 43/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.3652 - accuracy: 0.2731 - val_loss: 4.2216 - val_accuracy: 0.0111\n",
      "Epoch 44/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.5333 - accuracy: 0.2406 - val_loss: 4.9106 - val_accuracy: 0.0333\n",
      "Epoch 45/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.5903 - accuracy: 0.2481 - val_loss: 2.7079 - val_accuracy: 0.2778\n",
      "Epoch 46/150\n",
      "802/802 [==============================] - 0s 80us/step - loss: 2.1409 - accuracy: 0.2818 - val_loss: 3.0032 - val_accuracy: 0.2778\n",
      "Epoch 47/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.3237 - accuracy: 0.2905 - val_loss: 6.4172 - val_accuracy: 0.2778\n",
      "Epoch 48/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.8620 - accuracy: 0.2606 - val_loss: 4.1612 - val_accuracy: 0.0111\n",
      "Epoch 49/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.2129 - accuracy: 0.2618 - val_loss: 4.0495 - val_accuracy: 0.0333\n",
      "Epoch 50/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.4868 - accuracy: 0.2406 - val_loss: 4.6015 - val_accuracy: 0.1111\n",
      "Epoch 51/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.7103 - accuracy: 0.2643 - val_loss: 5.0323 - val_accuracy: 0.2778\n",
      "Epoch 52/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.5456 - accuracy: 0.2905 - val_loss: 3.7484 - val_accuracy: 0.2778\n",
      "Epoch 53/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.4275 - accuracy: 0.2718 - val_loss: 2.8541 - val_accuracy: 0.2778\n",
      "Epoch 54/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.1086 - accuracy: 0.3030 - val_loss: 3.3153 - val_accuracy: 0.1889\n",
      "Epoch 55/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.9014 - accuracy: 0.2307 - val_loss: 5.1317 - val_accuracy: 0.0222\n",
      "Epoch 56/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.5754 - accuracy: 0.2244 - val_loss: 2.9626 - val_accuracy: 0.2778\n",
      "Epoch 57/150\n",
      "802/802 [==============================] - 0s 172us/step - loss: 2.5581 - accuracy: 0.2656 - val_loss: 9.3024 - val_accuracy: 0.1111\n",
      "Epoch 58/150\n",
      "802/802 [==============================] - 0s 175us/step - loss: 3.2094 - accuracy: 0.2394 - val_loss: 3.5985 - val_accuracy: 0.2778\n",
      "Epoch 59/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.4086 - accuracy: 0.2494 - val_loss: 3.6054 - val_accuracy: 0.1889\n",
      "Epoch 60/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.7761 - accuracy: 0.2444 - val_loss: 3.7401 - val_accuracy: 0.2778\n",
      "Epoch 61/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2102 - accuracy: 0.2905 - val_loss: 7.5106 - val_accuracy: 0.2778\n",
      "Epoch 62/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6685 - accuracy: 0.2980 - val_loss: 4.2192 - val_accuracy: 0.1111\n",
      "Epoch 63/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5646 - accuracy: 0.2581 - val_loss: 2.8130 - val_accuracy: 0.2778\n",
      "Epoch 64/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4505 - accuracy: 0.2743 - val_loss: 5.1755 - val_accuracy: 0.1889\n",
      "Epoch 65/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6564 - accuracy: 0.2606 - val_loss: 4.4659 - val_accuracy: 0.2778\n",
      "Epoch 66/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2783 - accuracy: 0.2893 - val_loss: 4.6857 - val_accuracy: 0.0222\n",
      "Epoch 67/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.4468 - accuracy: 0.2581 - val_loss: 5.5087 - val_accuracy: 0.2778\n",
      "Epoch 68/150\n",
      "802/802 [==============================] - 0s 132us/step - loss: 2.3857 - accuracy: 0.2793 - val_loss: 3.7472 - val_accuracy: 0.1889\n",
      "Epoch 69/150\n",
      "802/802 [==============================] - 0s 197us/step - loss: 2.3322 - accuracy: 0.2569 - val_loss: 3.0201 - val_accuracy: 0.2778\n",
      "Epoch 70/150\n",
      "802/802 [==============================] - 0s 181us/step - loss: 2.3870 - accuracy: 0.2668 - val_loss: 4.7633 - val_accuracy: 0.2778\n",
      "Epoch 71/150\n",
      "802/802 [==============================] - 0s 190us/step - loss: 2.5024 - accuracy: 0.2756 - val_loss: 6.9195 - val_accuracy: 0.2778\n",
      "Epoch 72/150\n",
      "802/802 [==============================] - 0s 217us/step - loss: 2.5577 - accuracy: 0.2743 - val_loss: 4.7085 - val_accuracy: 0.2778\n",
      "Epoch 73/150\n",
      "802/802 [==============================] - 0s 140us/step - loss: 2.5485 - accuracy: 0.2643 - val_loss: 4.4489 - val_accuracy: 0.1111\n",
      "Epoch 74/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.3871 - accuracy: 0.2606 - val_loss: 3.0667 - val_accuracy: 0.2778\n",
      "Epoch 75/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5840 - accuracy: 0.2531 - val_loss: 2.9725 - val_accuracy: 0.2778\n",
      "Epoch 76/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.2089 - accuracy: 0.2756 - val_loss: 3.2915 - val_accuracy: 0.2778\n",
      "Epoch 77/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.1632 - accuracy: 0.2581 - val_loss: 4.0679 - val_accuracy: 0.1889\n",
      "Epoch 78/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.6489 - accuracy: 0.2768 - val_loss: 6.1574 - val_accuracy: 0.2778\n",
      "Epoch 79/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.5862 - accuracy: 0.2805 - val_loss: 3.9903 - val_accuracy: 0.1889\n",
      "Epoch 80/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4874 - accuracy: 0.2556 - val_loss: 3.6058 - val_accuracy: 0.2778\n",
      "Epoch 81/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5796 - accuracy: 0.2643 - val_loss: 3.9610 - val_accuracy: 0.1111\n",
      "Epoch 82/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 62us/step - loss: 2.4298 - accuracy: 0.2681 - val_loss: 4.3729 - val_accuracy: 0.0111\n",
      "Epoch 83/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.7637 - accuracy: 0.2419 - val_loss: 4.5125 - val_accuracy: 0.1111\n",
      "Epoch 84/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.7191 - accuracy: 0.2656 - val_loss: 3.6480 - val_accuracy: 0.1889\n",
      "Epoch 85/150\n",
      "802/802 [==============================] - 0s 157us/step - loss: 2.4876 - accuracy: 0.2481 - val_loss: 3.0758 - val_accuracy: 0.2778\n",
      "Epoch 86/150\n",
      "802/802 [==============================] - 0s 219us/step - loss: 2.7601 - accuracy: 0.2481 - val_loss: 7.9690 - val_accuracy: 0.2778\n",
      "Epoch 87/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.8622 - accuracy: 0.2556 - val_loss: 3.1430 - val_accuracy: 0.2778\n",
      "Epoch 88/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.3655 - accuracy: 0.2693 - val_loss: 4.7242 - val_accuracy: 0.1889\n",
      "Epoch 89/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.6641 - accuracy: 0.2743 - val_loss: 5.6736 - val_accuracy: 0.1889\n",
      "Epoch 90/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.6565 - accuracy: 0.2494 - val_loss: 5.1889 - val_accuracy: 0.2778\n",
      "Epoch 91/150\n",
      "802/802 [==============================] - 0s 155us/step - loss: 2.3506 - accuracy: 0.3017 - val_loss: 5.8419 - val_accuracy: 0.2778\n",
      "Epoch 92/150\n",
      "802/802 [==============================] - 0s 233us/step - loss: 2.6326 - accuracy: 0.2805 - val_loss: 2.4911 - val_accuracy: 0.2778\n",
      "Epoch 93/150\n",
      "802/802 [==============================] - 0s 208us/step - loss: 2.1681 - accuracy: 0.2556 - val_loss: 7.1259 - val_accuracy: 0.2778\n",
      "Epoch 94/150\n",
      "802/802 [==============================] - 0s 157us/step - loss: 2.9277 - accuracy: 0.2431 - val_loss: 10.2257 - val_accuracy: 0.1111\n",
      "Epoch 95/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 3.3459 - accuracy: 0.2531 - val_loss: 3.7546 - val_accuracy: 0.1889\n",
      "Epoch 96/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3299 - accuracy: 0.2531 - val_loss: 3.3893 - val_accuracy: 0.2778\n",
      "Epoch 97/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.1482 - accuracy: 0.2880 - val_loss: 4.6641 - val_accuracy: 0.1889\n",
      "Epoch 98/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.8690 - accuracy: 0.2469 - val_loss: 4.1397 - val_accuracy: 0.1111\n",
      "Epoch 99/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3649 - accuracy: 0.2681 - val_loss: 4.3672 - val_accuracy: 0.1111\n",
      "Epoch 100/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.8730 - accuracy: 0.2456 - val_loss: 3.7923 - val_accuracy: 0.0111\n",
      "Epoch 101/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.1953 - accuracy: 0.2731 - val_loss: 4.7183 - val_accuracy: 0.2778\n",
      "Epoch 102/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.4101 - accuracy: 0.2905 - val_loss: 3.3432 - val_accuracy: 0.2778\n",
      "Epoch 103/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.4411 - accuracy: 0.2905 - val_loss: 4.9794 - val_accuracy: 0.1889\n",
      "Epoch 104/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.5005 - accuracy: 0.2706 - val_loss: 4.0494 - val_accuracy: 0.0556\n",
      "Epoch 105/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.4241 - accuracy: 0.2444 - val_loss: 4.5538 - val_accuracy: 0.2778\n",
      "Epoch 106/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.4591 - accuracy: 0.2893 - val_loss: 4.1249 - val_accuracy: 0.0333\n",
      "Epoch 107/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5352 - accuracy: 0.2656 - val_loss: 3.4233 - val_accuracy: 0.1889\n",
      "Epoch 108/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4350 - accuracy: 0.2756 - val_loss: 5.8115 - val_accuracy: 0.2778\n",
      "Epoch 109/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4964 - accuracy: 0.2930 - val_loss: 9.4685 - val_accuracy: 0.1889\n",
      "Epoch 110/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 3.2180 - accuracy: 0.2569 - val_loss: 7.7769 - val_accuracy: 0.2778\n",
      "Epoch 111/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.8889 - accuracy: 0.2793 - val_loss: 4.4691 - val_accuracy: 0.1111\n",
      "Epoch 112/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.4882 - accuracy: 0.2244 - val_loss: 5.9593 - val_accuracy: 0.1889\n",
      "Epoch 113/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.4829 - accuracy: 0.2968 - val_loss: 5.5427 - val_accuracy: 0.2778\n",
      "Epoch 114/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5923 - accuracy: 0.2805 - val_loss: 2.8010 - val_accuracy: 0.2778\n",
      "Epoch 115/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.2072 - accuracy: 0.2643 - val_loss: 6.9174 - val_accuracy: 0.2778\n",
      "Epoch 116/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5816 - accuracy: 0.3005 - val_loss: 4.3206 - val_accuracy: 0.2778\n",
      "Epoch 117/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5085 - accuracy: 0.2581 - val_loss: 4.4947 - val_accuracy: 0.1889\n",
      "Epoch 118/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.6400 - accuracy: 0.2718 - val_loss: 5.4981 - val_accuracy: 0.0556\n",
      "Epoch 119/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.5029 - accuracy: 0.2718 - val_loss: 3.8271 - val_accuracy: 0.1111\n",
      "Epoch 120/150\n",
      "802/802 [==============================] - 0s 133us/step - loss: 2.6233 - accuracy: 0.2282 - val_loss: 5.8976 - val_accuracy: 0.0556\n",
      "Epoch 121/150\n",
      "802/802 [==============================] - 0s 177us/step - loss: 2.7569 - accuracy: 0.2207 - val_loss: 3.8818 - val_accuracy: 0.1111\n",
      "Epoch 122/150\n",
      "802/802 [==============================] - 0s 177us/step - loss: 2.4455 - accuracy: 0.2531 - val_loss: 3.1423 - val_accuracy: 0.2778\n",
      "Epoch 123/150\n",
      "802/802 [==============================] - 0s 122us/step - loss: 2.3095 - accuracy: 0.2681 - val_loss: 8.5737 - val_accuracy: 0.1889\n",
      "Epoch 124/150\n",
      "802/802 [==============================] - 0s 151us/step - loss: 2.8168 - accuracy: 0.2706 - val_loss: 2.7938 - val_accuracy: 0.2778\n",
      "Epoch 125/150\n",
      "802/802 [==============================] - 0s 180us/step - loss: 2.4806 - accuracy: 0.2805 - val_loss: 5.7698 - val_accuracy: 0.0111\n",
      "Epoch 126/150\n",
      "802/802 [==============================] - 0s 191us/step - loss: 2.7258 - accuracy: 0.2406 - val_loss: 3.8242 - val_accuracy: 0.1889\n",
      "Epoch 127/150\n",
      "802/802 [==============================] - 0s 133us/step - loss: 2.3409 - accuracy: 0.2880 - val_loss: 3.3904 - val_accuracy: 0.2778\n",
      "Epoch 128/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.4411 - accuracy: 0.2656 - val_loss: 4.1642 - val_accuracy: 0.0556\n",
      "Epoch 129/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.3837 - accuracy: 0.2369 - val_loss: 4.2523 - val_accuracy: 0.1111\n",
      "Epoch 130/150\n",
      "802/802 [==============================] - 0s 165us/step - loss: 2.7737 - accuracy: 0.2743 - val_loss: 5.3543 - val_accuracy: 0.1111\n",
      "Epoch 131/150\n",
      "802/802 [==============================] - 0s 150us/step - loss: 2.6118 - accuracy: 0.2731 - val_loss: 3.5115 - val_accuracy: 0.2778\n",
      "Epoch 132/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.5371 - accuracy: 0.2618 - val_loss: 7.5899 - val_accuracy: 0.2778\n",
      "Epoch 133/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.9218 - accuracy: 0.2494 - val_loss: 4.0932 - val_accuracy: 0.1111\n",
      "Epoch 134/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.7886 - accuracy: 0.2357 - val_loss: 3.7038 - val_accuracy: 0.1889\n",
      "Epoch 135/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6692 - accuracy: 0.2731 - val_loss: 3.4189 - val_accuracy: 0.2778\n",
      "Epoch 136/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.2962 - accuracy: 0.2768 - val_loss: 3.7833 - val_accuracy: 0.1889\n",
      "Epoch 137/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.5285 - accuracy: 0.2793 - val_loss: 8.2741 - val_accuracy: 0.2778\n",
      "Epoch 138/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.8576 - accuracy: 0.2581 - val_loss: 4.7973 - val_accuracy: 0.1889\n",
      "Epoch 139/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.7342 - accuracy: 0.2544 - val_loss: 4.6857 - val_accuracy: 0.0111\n",
      "Epoch 140/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6060 - accuracy: 0.2456 - val_loss: 3.7420 - val_accuracy: 0.1111\n",
      "Epoch 141/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5747 - accuracy: 0.2643 - val_loss: 4.1360 - val_accuracy: 0.0111\n",
      "Epoch 142/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.7681 - accuracy: 0.2307 - val_loss: 3.8237 - val_accuracy: 0.1889\n",
      "Epoch 143/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6002 - accuracy: 0.2481 - val_loss: 3.2004 - val_accuracy: 0.2778\n",
      "Epoch 144/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6739 - accuracy: 0.2756 - val_loss: 3.1030 - val_accuracy: 0.2778\n",
      "Epoch 145/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.3277 - accuracy: 0.2843 - val_loss: 7.6068 - val_accuracy: 0.2778\n",
      "Epoch 146/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.8626 - accuracy: 0.2743 - val_loss: 3.5443 - val_accuracy: 0.2778\n",
      "Epoch 147/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4664 - accuracy: 0.2519 - val_loss: 8.1810 - val_accuracy: 0.2778\n",
      "Epoch 148/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 3.1441 - accuracy: 0.2656 - val_loss: 2.0930 - val_accuracy: 0.2778\n",
      "Epoch 149/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.0353 - accuracy: 0.2793 - val_loss: 2.9067 - val_accuracy: 0.1889\n",
      "Epoch 150/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.1881 - accuracy: 0.2581 - val_loss: 3.6746 - val_accuracy: 0.1889\n",
      "460/460 [==============================] - 0s 48us/step\n",
      "Loss: 3.73\n",
      "Accuracy 0.15\n",
      "Train on 802 samples, validate on 90 samples\n",
      "Epoch 1/150\n",
      "802/802 [==============================] - 1s 933us/step - loss: 2.1445 - accuracy: 0.2868 - val_loss: 4.3529 - val_accuracy: 0.0556\n",
      "Epoch 2/150\n",
      "802/802 [==============================] - 0s 125us/step - loss: 2.4349 - accuracy: 0.2668 - val_loss: 4.1384 - val_accuracy: 0.1889\n",
      "Epoch 3/150\n",
      "802/802 [==============================] - 0s 213us/step - loss: 2.5189 - accuracy: 0.2544 - val_loss: 3.4817 - val_accuracy: 0.2778\n",
      "Epoch 4/150\n",
      "802/802 [==============================] - 0s 192us/step - loss: 2.4989 - accuracy: 0.2444 - val_loss: 3.5406 - val_accuracy: 0.2778\n",
      "Epoch 5/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.4014 - accuracy: 0.2743 - val_loss: 5.7221 - val_accuracy: 0.0556\n",
      "Epoch 6/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.5065 - accuracy: 0.2656 - val_loss: 4.1332 - val_accuracy: 0.1111\n",
      "Epoch 7/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.6040 - accuracy: 0.2481 - val_loss: 4.4679 - val_accuracy: 0.1111\n",
      "Epoch 8/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.4865 - accuracy: 0.2756 - val_loss: 3.3751 - val_accuracy: 0.1889\n",
      "Epoch 9/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4928 - accuracy: 0.2805 - val_loss: 7.5820 - val_accuracy: 0.2778\n",
      "Epoch 10/150\n",
      "802/802 [==============================] - 0s 101us/step - loss: 2.5146 - accuracy: 0.3030 - val_loss: 4.5767 - val_accuracy: 0.1111\n",
      "Epoch 11/150\n",
      "802/802 [==============================] - 0s 203us/step - loss: 2.5491 - accuracy: 0.2431 - val_loss: 8.0852 - val_accuracy: 0.2778\n",
      "Epoch 12/150\n",
      "802/802 [==============================] - 0s 175us/step - loss: 2.7471 - accuracy: 0.3092 - val_loss: 5.7199 - val_accuracy: 0.2778\n",
      "Epoch 13/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.2985 - accuracy: 0.3005 - val_loss: 4.1754 - val_accuracy: 0.1111\n",
      "Epoch 14/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5616 - accuracy: 0.2307 - val_loss: 3.3894 - val_accuracy: 0.1889\n",
      "Epoch 15/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.8315 - accuracy: 0.2157 - val_loss: 4.1582 - val_accuracy: 0.0333\n",
      "Epoch 16/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3398 - accuracy: 0.2494 - val_loss: 4.2187 - val_accuracy: 0.2778\n",
      "Epoch 17/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5762 - accuracy: 0.2581 - val_loss: 5.8234 - val_accuracy: 0.1889\n",
      "Epoch 18/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.4900 - accuracy: 0.2618 - val_loss: 7.7282 - val_accuracy: 0.2778\n",
      "Epoch 19/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.6808 - accuracy: 0.3080 - val_loss: 2.9925 - val_accuracy: 0.2778\n",
      "Epoch 20/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.3422 - accuracy: 0.2905 - val_loss: 2.8987 - val_accuracy: 0.2778\n",
      "Epoch 21/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.3615 - accuracy: 0.2793 - val_loss: 4.9145 - val_accuracy: 0.1111\n",
      "Epoch 22/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6581 - accuracy: 0.2631 - val_loss: 3.5480 - val_accuracy: 0.1889\n",
      "Epoch 23/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6633 - accuracy: 0.2531 - val_loss: 2.7040 - val_accuracy: 0.2778\n",
      "Epoch 24/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.2466 - accuracy: 0.2830 - val_loss: 4.9710 - val_accuracy: 0.1111\n",
      "Epoch 25/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.6344 - accuracy: 0.2207 - val_loss: 5.2295 - val_accuracy: 0.1111\n",
      "Epoch 26/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5898 - accuracy: 0.2556 - val_loss: 9.4466 - val_accuracy: 0.1889\n",
      "Epoch 27/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 3.0247 - accuracy: 0.2668 - val_loss: 4.7869 - val_accuracy: 0.2778\n",
      "Epoch 28/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3103 - accuracy: 0.2893 - val_loss: 3.3667 - val_accuracy: 0.2778\n",
      "Epoch 29/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.2673 - accuracy: 0.2544 - val_loss: 3.5811 - val_accuracy: 0.1889\n",
      "Epoch 30/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.4828 - accuracy: 0.2718 - val_loss: 3.9506 - val_accuracy: 0.1889\n",
      "Epoch 31/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.3062 - accuracy: 0.2656 - val_loss: 4.1079 - val_accuracy: 0.2778\n",
      "Epoch 32/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.4733 - accuracy: 0.2556 - val_loss: 3.4478 - val_accuracy: 0.1889\n",
      "Epoch 33/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.4757 - accuracy: 0.2830 - val_loss: 5.8106 - val_accuracy: 0.2778\n",
      "Epoch 34/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.5229 - accuracy: 0.3092 - val_loss: 4.1342 - val_accuracy: 0.1111\n",
      "Epoch 35/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.3875 - accuracy: 0.2406 - val_loss: 6.2941 - val_accuracy: 0.0333\n",
      "Epoch 36/150\n",
      "802/802 [==============================] - 0s 120us/step - loss: 2.5986 - accuracy: 0.2494 - val_loss: 4.3447 - val_accuracy: 0.1111\n",
      "Epoch 37/150\n",
      "802/802 [==============================] - 0s 110us/step - loss: 2.3201 - accuracy: 0.2581 - val_loss: 5.2244 - val_accuracy: 0.1111\n",
      "Epoch 38/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3087 - accuracy: 0.2830 - val_loss: 3.3263 - val_accuracy: 0.1111\n",
      "Epoch 39/150\n",
      "802/802 [==============================] - 0s 105us/step - loss: 2.6545 - accuracy: 0.2132 - val_loss: 6.7252 - val_accuracy: 0.2778\n",
      "Epoch 40/150\n",
      "802/802 [==============================] - 0s 128us/step - loss: 2.6634 - accuracy: 0.2905 - val_loss: 5.6184 - val_accuracy: 0.1889\n",
      "Epoch 41/150\n",
      "802/802 [==============================] - 0s 132us/step - loss: 2.7008 - accuracy: 0.2431 - val_loss: 7.7797 - val_accuracy: 0.2778\n",
      "Epoch 42/150\n",
      "802/802 [==============================] - 0s 145us/step - loss: 2.7560 - accuracy: 0.2830 - val_loss: 7.2246 - val_accuracy: 0.2778\n",
      "Epoch 43/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 136us/step - loss: 2.9162 - accuracy: 0.2606 - val_loss: 4.1477 - val_accuracy: 0.0556\n",
      "Epoch 44/150\n",
      "802/802 [==============================] - 0s 136us/step - loss: 2.5581 - accuracy: 0.2032 - val_loss: 3.0103 - val_accuracy: 0.2778\n",
      "Epoch 45/150\n",
      "802/802 [==============================] - 0s 133us/step - loss: 2.5006 - accuracy: 0.2431 - val_loss: 5.1174 - val_accuracy: 0.1111\n",
      "Epoch 46/150\n",
      "802/802 [==============================] - 0s 125us/step - loss: 2.4056 - accuracy: 0.2768 - val_loss: 5.6171 - val_accuracy: 0.0556\n",
      "Epoch 47/150\n",
      "802/802 [==============================] - 0s 140us/step - loss: 2.5360 - accuracy: 0.2643 - val_loss: 3.7073 - val_accuracy: 0.2778\n",
      "Epoch 48/150\n",
      "802/802 [==============================] - 0s 127us/step - loss: 2.5682 - accuracy: 0.2618 - val_loss: 6.9398 - val_accuracy: 0.2778\n",
      "Epoch 49/150\n",
      "802/802 [==============================] - 0s 126us/step - loss: 2.7578 - accuracy: 0.2930 - val_loss: 4.0051 - val_accuracy: 0.0333\n",
      "Epoch 50/150\n",
      "802/802 [==============================] - 0s 130us/step - loss: 2.9168 - accuracy: 0.2145 - val_loss: 4.0443 - val_accuracy: 0.2778\n",
      "Epoch 51/150\n",
      "802/802 [==============================] - 0s 118us/step - loss: 2.4368 - accuracy: 0.2893 - val_loss: 8.1590 - val_accuracy: 0.2778\n",
      "Epoch 52/150\n",
      "802/802 [==============================] - 0s 183us/step - loss: 2.9782 - accuracy: 0.2756 - val_loss: 2.6486 - val_accuracy: 0.2778\n",
      "Epoch 53/150\n",
      "802/802 [==============================] - 0s 146us/step - loss: 2.2940 - accuracy: 0.2706 - val_loss: 8.1869 - val_accuracy: 0.2778\n",
      "Epoch 54/150\n",
      "802/802 [==============================] - 0s 133us/step - loss: 2.8677 - accuracy: 0.2930 - val_loss: 4.6907 - val_accuracy: 0.1111\n",
      "Epoch 55/150\n",
      "802/802 [==============================] - 0s 138us/step - loss: 2.4216 - accuracy: 0.2768 - val_loss: 5.0662 - val_accuracy: 0.2778\n",
      "Epoch 56/150\n",
      "802/802 [==============================] - 0s 125us/step - loss: 2.4564 - accuracy: 0.2855 - val_loss: 4.5039 - val_accuracy: 0.1111\n",
      "Epoch 57/150\n",
      "802/802 [==============================] - 0s 127us/step - loss: 2.2067 - accuracy: 0.2581 - val_loss: 4.0098 - val_accuracy: 0.1111\n",
      "Epoch 58/150\n",
      "802/802 [==============================] - 0s 126us/step - loss: 2.8424 - accuracy: 0.2269 - val_loss: 3.9026 - val_accuracy: 0.1889\n",
      "Epoch 59/150\n",
      "802/802 [==============================] - 0s 125us/step - loss: 2.4570 - accuracy: 0.2556 - val_loss: 4.5771 - val_accuracy: 0.2778\n",
      "Epoch 60/150\n",
      "802/802 [==============================] - 0s 132us/step - loss: 2.6665 - accuracy: 0.2594 - val_loss: 4.4203 - val_accuracy: 0.1111\n",
      "Epoch 61/150\n",
      "802/802 [==============================] - 0s 140us/step - loss: 2.7362 - accuracy: 0.2170 - val_loss: 4.0819 - val_accuracy: 0.1889\n",
      "Epoch 62/150\n",
      "802/802 [==============================] - 0s 128us/step - loss: 2.5330 - accuracy: 0.2781 - val_loss: 3.9529 - val_accuracy: 0.1889\n",
      "Epoch 63/150\n",
      "802/802 [==============================] - 0s 122us/step - loss: 2.8191 - accuracy: 0.2456 - val_loss: 9.1944 - val_accuracy: 0.1111\n",
      "Epoch 64/150\n",
      "802/802 [==============================] - 0s 141us/step - loss: 2.9533 - accuracy: 0.2544 - val_loss: 3.6505 - val_accuracy: 0.1889\n",
      "Epoch 65/150\n",
      "802/802 [==============================] - 0s 133us/step - loss: 2.5663 - accuracy: 0.2594 - val_loss: 7.8010 - val_accuracy: 0.2778\n",
      "Epoch 66/150\n",
      "802/802 [==============================] - 0s 148us/step - loss: 2.8948 - accuracy: 0.2818 - val_loss: 4.1243 - val_accuracy: 0.1889\n",
      "Epoch 67/150\n",
      "802/802 [==============================] - 0s 128us/step - loss: 2.4440 - accuracy: 0.2793 - val_loss: 2.2605 - val_accuracy: 0.2778\n",
      "Epoch 68/150\n",
      "802/802 [==============================] - 0s 132us/step - loss: 2.0811 - accuracy: 0.2868 - val_loss: 5.3877 - val_accuracy: 0.2778\n",
      "Epoch 69/150\n",
      "802/802 [==============================] - 0s 130us/step - loss: 2.5881 - accuracy: 0.2706 - val_loss: 5.0695 - val_accuracy: 0.1889\n",
      "Epoch 70/150\n",
      "802/802 [==============================] - 0s 130us/step - loss: 2.4990 - accuracy: 0.2718 - val_loss: 3.3086 - val_accuracy: 0.2778\n",
      "Epoch 71/150\n",
      "802/802 [==============================] - 0s 130us/step - loss: 2.3796 - accuracy: 0.2656 - val_loss: 7.9238 - val_accuracy: 0.2778\n",
      "Epoch 72/150\n",
      "802/802 [==============================] - 0s 128us/step - loss: 2.7779 - accuracy: 0.3005 - val_loss: 5.4429 - val_accuracy: 0.1111\n",
      "Epoch 73/150\n",
      "802/802 [==============================] - 0s 128us/step - loss: 2.5842 - accuracy: 0.2419 - val_loss: 3.6018 - val_accuracy: 0.1889\n",
      "Epoch 74/150\n",
      "802/802 [==============================] - 0s 145us/step - loss: 2.3824 - accuracy: 0.2756 - val_loss: 3.9340 - val_accuracy: 0.0556\n",
      "Epoch 75/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.4394 - accuracy: 0.2569 - val_loss: 4.8532 - val_accuracy: 0.1111\n",
      "Epoch 76/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4994 - accuracy: 0.2918 - val_loss: 3.0791 - val_accuracy: 0.1889\n",
      "Epoch 77/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.2490 - accuracy: 0.2731 - val_loss: 2.7499 - val_accuracy: 0.2778\n",
      "Epoch 78/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4322 - accuracy: 0.2594 - val_loss: 3.4131 - val_accuracy: 0.1889\n",
      "Epoch 79/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.6779 - accuracy: 0.2444 - val_loss: 7.9581 - val_accuracy: 0.2778\n",
      "Epoch 80/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.7057 - accuracy: 0.2656 - val_loss: 4.1518 - val_accuracy: 0.2778\n",
      "Epoch 81/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.5160 - accuracy: 0.2968 - val_loss: 8.0452 - val_accuracy: 0.2778\n",
      "Epoch 82/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.8460 - accuracy: 0.2918 - val_loss: 3.2935 - val_accuracy: 0.2778\n",
      "Epoch 83/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.0779 - accuracy: 0.3005 - val_loss: 8.4938 - val_accuracy: 0.1889\n",
      "Epoch 84/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.9198 - accuracy: 0.2743 - val_loss: 3.6934 - val_accuracy: 0.1889\n",
      "Epoch 85/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.6270 - accuracy: 0.2693 - val_loss: 3.7056 - val_accuracy: 0.1889\n",
      "Epoch 86/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.5868 - accuracy: 0.2706 - val_loss: 4.1364 - val_accuracy: 0.1889\n",
      "Epoch 87/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.3873 - accuracy: 0.2781 - val_loss: 7.2162 - val_accuracy: 0.2778\n",
      "Epoch 88/150\n",
      "802/802 [==============================] - 0s 84us/step - loss: 2.7270 - accuracy: 0.2918 - val_loss: 3.1618 - val_accuracy: 0.1889\n",
      "Epoch 89/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.3029 - accuracy: 0.2681 - val_loss: 3.1063 - val_accuracy: 0.2778\n",
      "Epoch 90/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.7067 - accuracy: 0.2531 - val_loss: 4.8195 - val_accuracy: 0.2778\n",
      "Epoch 91/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4479 - accuracy: 0.2544 - val_loss: 6.6988 - val_accuracy: 0.2778\n",
      "Epoch 92/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.6946 - accuracy: 0.2955 - val_loss: 2.9107 - val_accuracy: 0.2778\n",
      "Epoch 93/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.2995 - accuracy: 0.2681 - val_loss: 5.5030 - val_accuracy: 0.2778\n",
      "Epoch 94/150\n",
      "802/802 [==============================] - 0s 99us/step - loss: 2.7493 - accuracy: 0.2431 - val_loss: 5.0004 - val_accuracy: 0.2778\n",
      "Epoch 95/150\n",
      "802/802 [==============================] - 0s 84us/step - loss: 2.4842 - accuracy: 0.2793 - val_loss: 9.5174 - val_accuracy: 0.1889\n",
      "Epoch 96/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 3.0198 - accuracy: 0.2706 - val_loss: 4.9024 - val_accuracy: 0.1889\n",
      "Epoch 97/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.7405 - accuracy: 0.2706 - val_loss: 4.4918 - val_accuracy: 0.2778\n",
      "Epoch 98/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4787 - accuracy: 0.2681 - val_loss: 5.7612 - val_accuracy: 0.0111\n",
      "Epoch 99/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6025 - accuracy: 0.2095 - val_loss: 4.6845 - val_accuracy: 0.2778\n",
      "Epoch 100/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3091 - accuracy: 0.2631 - val_loss: 3.2928 - val_accuracy: 0.1889\n",
      "Epoch 101/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3366 - accuracy: 0.2731 - val_loss: 3.5812 - val_accuracy: 0.1889\n",
      "Epoch 102/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4634 - accuracy: 0.2594 - val_loss: 4.1362 - val_accuracy: 0.1889\n",
      "Epoch 103/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.3691 - accuracy: 0.2781 - val_loss: 9.6456 - val_accuracy: 0.1111\n",
      "Epoch 104/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 3.0073 - accuracy: 0.2581 - val_loss: 3.9317 - val_accuracy: 0.1889\n",
      "Epoch 105/150\n",
      "802/802 [==============================] - 0s 56us/step - loss: 2.5746 - accuracy: 0.2569 - val_loss: 4.7083 - val_accuracy: 0.0556\n",
      "Epoch 106/150\n",
      "802/802 [==============================] - 0s 94us/step - loss: 2.5125 - accuracy: 0.2668 - val_loss: 2.4220 - val_accuracy: 0.2778\n",
      "Epoch 107/150\n",
      "802/802 [==============================] - 0s 140us/step - loss: 2.0759 - accuracy: 0.2606 - val_loss: 3.9566 - val_accuracy: 0.2778\n",
      "Epoch 108/150\n",
      "802/802 [==============================] - 0s 128us/step - loss: 2.3611 - accuracy: 0.2818 - val_loss: 8.7552 - val_accuracy: 0.1889\n",
      "Epoch 109/150\n",
      "802/802 [==============================] - 0s 136us/step - loss: 3.2192 - accuracy: 0.2569 - val_loss: 4.5652 - val_accuracy: 0.0556\n",
      "Epoch 110/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.5236 - accuracy: 0.2419 - val_loss: 7.8074 - val_accuracy: 0.2778\n",
      "Epoch 111/150\n",
      "802/802 [==============================] - 0s 91us/step - loss: 2.8414 - accuracy: 0.2805 - val_loss: 4.5349 - val_accuracy: 0.1111\n",
      "Epoch 112/150\n",
      "802/802 [==============================] - 0s 99us/step - loss: 2.8443 - accuracy: 0.2406 - val_loss: 3.9348 - val_accuracy: 0.0222\n",
      "Epoch 113/150\n",
      "802/802 [==============================] - 0s 99us/step - loss: 2.3848 - accuracy: 0.2556 - val_loss: 3.1379 - val_accuracy: 0.2778\n",
      "Epoch 114/150\n",
      "802/802 [==============================] - 0s 87us/step - loss: 2.2827 - accuracy: 0.2731 - val_loss: 4.0394 - val_accuracy: 0.1111\n",
      "Epoch 115/150\n",
      "802/802 [==============================] - 0s 87us/step - loss: 2.6549 - accuracy: 0.2569 - val_loss: 2.9438 - val_accuracy: 0.2778\n",
      "Epoch 116/150\n",
      "802/802 [==============================] - 0s 95us/step - loss: 2.2700 - accuracy: 0.2631 - val_loss: 4.1990 - val_accuracy: 0.1889\n",
      "Epoch 117/150\n",
      "802/802 [==============================] - 0s 85us/step - loss: 2.5897 - accuracy: 0.2494 - val_loss: 4.5201 - val_accuracy: 0.1111\n",
      "Epoch 118/150\n",
      "802/802 [==============================] - 0s 85us/step - loss: 2.5685 - accuracy: 0.2456 - val_loss: 7.2211 - val_accuracy: 0.2778\n",
      "Epoch 119/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 3.0158 - accuracy: 0.2606 - val_loss: 2.9160 - val_accuracy: 0.2778\n",
      "Epoch 120/150\n",
      "802/802 [==============================] - 0s 87us/step - loss: 2.1847 - accuracy: 0.3042 - val_loss: 4.9259 - val_accuracy: 0.1889\n",
      "Epoch 121/150\n",
      "802/802 [==============================] - 0s 90us/step - loss: 2.5433 - accuracy: 0.2618 - val_loss: 4.1585 - val_accuracy: 0.1889\n",
      "Epoch 122/150\n",
      "802/802 [==============================] - 0s 105us/step - loss: 2.3778 - accuracy: 0.2606 - val_loss: 4.5909 - val_accuracy: 0.1111\n",
      "Epoch 123/150\n",
      "802/802 [==============================] - 0s 87us/step - loss: 2.2894 - accuracy: 0.2868 - val_loss: 3.5319 - val_accuracy: 0.2778\n",
      "Epoch 124/150\n",
      "802/802 [==============================] - 0s 97us/step - loss: 2.1075 - accuracy: 0.2993 - val_loss: 4.6273 - val_accuracy: 0.1889\n",
      "Epoch 125/150\n",
      "802/802 [==============================] - 0s 84us/step - loss: 2.6470 - accuracy: 0.2569 - val_loss: 3.8742 - val_accuracy: 0.0333\n",
      "Epoch 126/150\n",
      "802/802 [==============================] - 0s 91us/step - loss: 2.4351 - accuracy: 0.2282 - val_loss: 4.9393 - val_accuracy: 0.1889\n",
      "Epoch 127/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.4343 - accuracy: 0.2781 - val_loss: 4.6327 - val_accuracy: 0.0556\n",
      "Epoch 128/150\n",
      "802/802 [==============================] - 0s 85us/step - loss: 2.4978 - accuracy: 0.2693 - val_loss: 5.9589 - val_accuracy: 0.2778\n",
      "Epoch 129/150\n",
      "802/802 [==============================] - 0s 101us/step - loss: 2.4862 - accuracy: 0.2618 - val_loss: 4.3601 - val_accuracy: 0.0556\n",
      "Epoch 130/150\n",
      "802/802 [==============================] - 0s 101us/step - loss: 2.5494 - accuracy: 0.2668 - val_loss: 4.2280 - val_accuracy: 0.2778\n",
      "Epoch 131/150\n",
      "802/802 [==============================] - 0s 89us/step - loss: 2.3083 - accuracy: 0.2793 - val_loss: 10.5923 - val_accuracy: 0.1111\n",
      "Epoch 132/150\n",
      "802/802 [==============================] - 0s 96us/step - loss: 3.3688 - accuracy: 0.2382 - val_loss: 5.8492 - val_accuracy: 0.2778\n",
      "Epoch 133/150\n",
      "802/802 [==============================] - 0s 90us/step - loss: 2.5598 - accuracy: 0.3005 - val_loss: 3.0967 - val_accuracy: 0.2778\n",
      "Epoch 134/150\n",
      "802/802 [==============================] - 0s 95us/step - loss: 2.4325 - accuracy: 0.2731 - val_loss: 4.0190 - val_accuracy: 0.0111\n",
      "Epoch 135/150\n",
      "802/802 [==============================] - 0s 100us/step - loss: 2.2826 - accuracy: 0.2531 - val_loss: 6.2911 - val_accuracy: 0.2778\n",
      "Epoch 136/150\n",
      "802/802 [==============================] - 0s 87us/step - loss: 2.9696 - accuracy: 0.2556 - val_loss: 8.7071 - val_accuracy: 0.2778\n",
      "Epoch 137/150\n",
      "802/802 [==============================] - 0s 100us/step - loss: 3.1420 - accuracy: 0.2843 - val_loss: 6.9562 - val_accuracy: 0.2778\n",
      "Epoch 138/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.5950 - accuracy: 0.2805 - val_loss: 4.1660 - val_accuracy: 0.0222\n",
      "Epoch 139/150\n",
      "802/802 [==============================] - 0s 110us/step - loss: 2.7614 - accuracy: 0.2219 - val_loss: 3.7660 - val_accuracy: 0.1889\n",
      "Epoch 140/150\n",
      "802/802 [==============================] - 0s 145us/step - loss: 2.3544 - accuracy: 0.2469 - val_loss: 9.2022 - val_accuracy: 0.1889\n",
      "Epoch 141/150\n",
      "802/802 [==============================] - 0s 131us/step - loss: 3.3326 - accuracy: 0.2294 - val_loss: 9.0836 - val_accuracy: 0.1889\n",
      "Epoch 142/150\n",
      "802/802 [==============================] - 0s 108us/step - loss: 2.9373 - accuracy: 0.2668 - val_loss: 5.7647 - val_accuracy: 0.1111\n",
      "Epoch 143/150\n",
      "802/802 [==============================] - 0s 87us/step - loss: 2.6004 - accuracy: 0.2781 - val_loss: 7.5747 - val_accuracy: 0.2778\n",
      "Epoch 144/150\n",
      "802/802 [==============================] - 0s 94us/step - loss: 2.7554 - accuracy: 0.2843 - val_loss: 3.4954 - val_accuracy: 0.1889\n",
      "Epoch 145/150\n",
      "802/802 [==============================] - 0s 89us/step - loss: 2.6803 - accuracy: 0.2581 - val_loss: 3.6080 - val_accuracy: 0.1889\n",
      "Epoch 146/150\n",
      "802/802 [==============================] - 0s 99us/step - loss: 2.3050 - accuracy: 0.2781 - val_loss: 4.9859 - val_accuracy: 0.2778\n",
      "Epoch 147/150\n",
      "802/802 [==============================] - 0s 90us/step - loss: 2.3202 - accuracy: 0.2706 - val_loss: 3.1776 - val_accuracy: 0.2778\n",
      "Epoch 148/150\n",
      "802/802 [==============================] - 0s 101us/step - loss: 2.2372 - accuracy: 0.2955 - val_loss: 5.6218 - val_accuracy: 0.1111\n",
      "Epoch 149/150\n",
      "802/802 [==============================] - 0s 91us/step - loss: 2.8155 - accuracy: 0.2007 - val_loss: 3.9129 - val_accuracy: 0.2778\n",
      "Epoch 150/150\n",
      "802/802 [==============================] - 0s 121us/step - loss: 2.4691 - accuracy: 0.2444 - val_loss: 6.6044 - val_accuracy: 0.2778\n",
      "460/460 [==============================] - 0s 115us/step\n",
      "Loss: 6.21\n",
      "Accuracy 0.33\n",
      "Train on 802 samples, validate on 90 samples\n",
      "Epoch 1/150\n",
      "802/802 [==============================] - 1s 797us/step - loss: 2.7939 - accuracy: 0.2456 - val_loss: 7.1898 - val_accuracy: 0.1889\n",
      "Epoch 2/150\n",
      "802/802 [==============================] - 0s 91us/step - loss: 2.8742 - accuracy: 0.2656 - val_loss: 4.0446 - val_accuracy: 0.0333\n",
      "Epoch 3/150\n",
      "802/802 [==============================] - 0s 90us/step - loss: 2.8812 - accuracy: 0.2282 - val_loss: 3.9271 - val_accuracy: 0.1111\n",
      "Epoch 4/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 102us/step - loss: 2.6807 - accuracy: 0.2743 - val_loss: 3.4427 - val_accuracy: 0.1889\n",
      "Epoch 5/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.9042 - accuracy: 0.2307 - val_loss: 4.9771 - val_accuracy: 0.2778\n",
      "Epoch 6/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5095 - accuracy: 0.2868 - val_loss: 7.5865 - val_accuracy: 0.2778\n",
      "Epoch 7/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.8306 - accuracy: 0.2893 - val_loss: 3.6868 - val_accuracy: 0.0222\n",
      "Epoch 8/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3679 - accuracy: 0.2656 - val_loss: 5.6211 - val_accuracy: 0.2778\n",
      "Epoch 9/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4109 - accuracy: 0.3055 - val_loss: 2.9413 - val_accuracy: 0.2778\n",
      "Epoch 10/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3848 - accuracy: 0.2506 - val_loss: 3.3784 - val_accuracy: 0.1889\n",
      "Epoch 11/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.4702 - accuracy: 0.2693 - val_loss: 3.5733 - val_accuracy: 0.1889\n",
      "Epoch 12/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.5729 - accuracy: 0.2668 - val_loss: 3.6252 - val_accuracy: 0.1889\n",
      "Epoch 13/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.2340 - accuracy: 0.2631 - val_loss: 3.0337 - val_accuracy: 0.2778\n",
      "Epoch 14/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3418 - accuracy: 0.2943 - val_loss: 4.1588 - val_accuracy: 0.1111\n",
      "Epoch 15/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3063 - accuracy: 0.2643 - val_loss: 3.9378 - val_accuracy: 0.1889\n",
      "Epoch 16/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.2318 - accuracy: 0.2843 - val_loss: 4.3171 - val_accuracy: 0.2778\n",
      "Epoch 17/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4030 - accuracy: 0.2743 - val_loss: 2.9477 - val_accuracy: 0.2778\n",
      "Epoch 18/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.3145 - accuracy: 0.2768 - val_loss: 3.9466 - val_accuracy: 0.1889\n",
      "Epoch 19/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.4124 - accuracy: 0.2431 - val_loss: 4.0860 - val_accuracy: 0.0556\n",
      "Epoch 20/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6139 - accuracy: 0.2406 - val_loss: 4.2522 - val_accuracy: 0.1889\n",
      "Epoch 21/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4342 - accuracy: 0.3092 - val_loss: 4.9890 - val_accuracy: 0.1889\n",
      "Epoch 22/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6558 - accuracy: 0.2481 - val_loss: 2.9842 - val_accuracy: 0.2778\n",
      "Epoch 23/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.2758 - accuracy: 0.2743 - val_loss: 4.3242 - val_accuracy: 0.1111\n",
      "Epoch 24/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4534 - accuracy: 0.2618 - val_loss: 3.0206 - val_accuracy: 0.2778\n",
      "Epoch 25/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4022 - accuracy: 0.2855 - val_loss: 3.8185 - val_accuracy: 0.1889\n",
      "Epoch 26/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3900 - accuracy: 0.2631 - val_loss: 7.9150 - val_accuracy: 0.2778\n",
      "Epoch 27/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 3.0335 - accuracy: 0.2618 - val_loss: 2.5563 - val_accuracy: 0.2778\n",
      "Epoch 28/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.2219 - accuracy: 0.2843 - val_loss: 6.2649 - val_accuracy: 0.2778\n",
      "Epoch 29/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6785 - accuracy: 0.2756 - val_loss: 5.5972 - val_accuracy: 0.0556\n",
      "Epoch 30/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 3.0321 - accuracy: 0.2145 - val_loss: 4.9234 - val_accuracy: 0.1889\n",
      "Epoch 31/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4147 - accuracy: 0.2743 - val_loss: 5.0668 - val_accuracy: 0.1889\n",
      "Epoch 32/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.6039 - accuracy: 0.2207 - val_loss: 3.9146 - val_accuracy: 0.2778\n",
      "Epoch 33/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3373 - accuracy: 0.2793 - val_loss: 6.1044 - val_accuracy: 0.1889\n",
      "Epoch 34/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.9604 - accuracy: 0.2182 - val_loss: 3.2700 - val_accuracy: 0.1889\n",
      "Epoch 35/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5841 - accuracy: 0.2693 - val_loss: 3.8378 - val_accuracy: 0.1111\n",
      "Epoch 36/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5073 - accuracy: 0.2556 - val_loss: 3.3044 - val_accuracy: 0.2778\n",
      "Epoch 37/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.1884 - accuracy: 0.3130 - val_loss: 4.8282 - val_accuracy: 0.1111\n",
      "Epoch 38/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6651 - accuracy: 0.2494 - val_loss: 7.8212 - val_accuracy: 0.2778\n",
      "Epoch 39/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.9757 - accuracy: 0.2781 - val_loss: 4.8255 - val_accuracy: 0.1111\n",
      "Epoch 40/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4989 - accuracy: 0.2244 - val_loss: 3.2640 - val_accuracy: 0.1889\n",
      "Epoch 41/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3110 - accuracy: 0.2793 - val_loss: 8.2415 - val_accuracy: 0.2778\n",
      "Epoch 42/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.7253 - accuracy: 0.2993 - val_loss: 5.8374 - val_accuracy: 0.0333\n",
      "Epoch 43/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5369 - accuracy: 0.2643 - val_loss: 2.9319 - val_accuracy: 0.2778\n",
      "Epoch 44/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.2355 - accuracy: 0.2768 - val_loss: 5.5140 - val_accuracy: 0.2778\n",
      "Epoch 45/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.6514 - accuracy: 0.2519 - val_loss: 4.4493 - val_accuracy: 0.1111\n",
      "Epoch 46/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5256 - accuracy: 0.2631 - val_loss: 4.4815 - val_accuracy: 0.1111\n",
      "Epoch 47/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.5273 - accuracy: 0.2718 - val_loss: 6.6124 - val_accuracy: 0.2778\n",
      "Epoch 48/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5678 - accuracy: 0.2805 - val_loss: 3.9606 - val_accuracy: 0.1889\n",
      "Epoch 49/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.4106 - accuracy: 0.2793 - val_loss: 4.6267 - val_accuracy: 0.0111\n",
      "Epoch 50/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.4402 - accuracy: 0.2382 - val_loss: 4.0708 - val_accuracy: 0.0333\n",
      "Epoch 51/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.5573 - accuracy: 0.2469 - val_loss: 4.2820 - val_accuracy: 0.1111\n",
      "Epoch 52/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.5674 - accuracy: 0.2282 - val_loss: 4.2043 - val_accuracy: 0.2778\n",
      "Epoch 53/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.5880 - accuracy: 0.2544 - val_loss: 7.7992 - val_accuracy: 0.2778\n",
      "Epoch 54/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.8267 - accuracy: 0.2668 - val_loss: 4.0220 - val_accuracy: 0.0111\n",
      "Epoch 55/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.4678 - accuracy: 0.2569 - val_loss: 3.8629 - val_accuracy: 0.2778\n",
      "Epoch 56/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.3587 - accuracy: 0.2980 - val_loss: 7.7080 - val_accuracy: 0.1889\n",
      "Epoch 57/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.8402 - accuracy: 0.2743 - val_loss: 3.8106 - val_accuracy: 0.1889\n",
      "Epoch 58/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6014 - accuracy: 0.2706 - val_loss: 4.2754 - val_accuracy: 0.2778\n",
      "Epoch 59/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.7692 - accuracy: 0.2556 - val_loss: 5.1872 - val_accuracy: 0.1889\n",
      "Epoch 60/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.5869 - accuracy: 0.2569 - val_loss: 5.9840 - val_accuracy: 0.1111\n",
      "Epoch 61/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.7531 - accuracy: 0.2606 - val_loss: 2.9773 - val_accuracy: 0.2778\n",
      "Epoch 62/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4416 - accuracy: 0.2843 - val_loss: 4.5609 - val_accuracy: 0.0556\n",
      "Epoch 63/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.2819 - accuracy: 0.2618 - val_loss: 3.5252 - val_accuracy: 0.1889\n",
      "Epoch 64/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5842 - accuracy: 0.2369 - val_loss: 3.7409 - val_accuracy: 0.1889\n",
      "Epoch 65/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5429 - accuracy: 0.2718 - val_loss: 3.2700 - val_accuracy: 0.1889\n",
      "Epoch 66/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.7119 - accuracy: 0.2431 - val_loss: 3.9459 - val_accuracy: 0.2778\n",
      "Epoch 67/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.2087 - accuracy: 0.2294 - val_loss: 4.4388 - val_accuracy: 0.0111\n",
      "Epoch 68/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.2498 - accuracy: 0.2756 - val_loss: 5.3562 - val_accuracy: 0.2778\n",
      "Epoch 69/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.3682 - accuracy: 0.3092 - val_loss: 4.1631 - val_accuracy: 0.1111\n",
      "Epoch 70/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5533 - accuracy: 0.2469 - val_loss: 3.1339 - val_accuracy: 0.2778\n",
      "Epoch 71/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5105 - accuracy: 0.2569 - val_loss: 2.5097 - val_accuracy: 0.2778\n",
      "Epoch 72/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.1739 - accuracy: 0.2444 - val_loss: 4.0170 - val_accuracy: 0.0556\n",
      "Epoch 73/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.7937 - accuracy: 0.2382 - val_loss: 3.4281 - val_accuracy: 0.1889\n",
      "Epoch 74/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5136 - accuracy: 0.2830 - val_loss: 3.3669 - val_accuracy: 0.1889\n",
      "Epoch 75/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.5006 - accuracy: 0.2494 - val_loss: 2.9091 - val_accuracy: 0.2778\n",
      "Epoch 76/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.3099 - accuracy: 0.2793 - val_loss: 4.5417 - val_accuracy: 0.2778\n",
      "Epoch 77/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5097 - accuracy: 0.2656 - val_loss: 4.4706 - val_accuracy: 0.1889\n",
      "Epoch 78/150\n",
      "802/802 [==============================] - 0s 80us/step - loss: 2.5694 - accuracy: 0.2693 - val_loss: 8.1809 - val_accuracy: 0.2778\n",
      "Epoch 79/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.8487 - accuracy: 0.2893 - val_loss: 3.6838 - val_accuracy: 0.2778\n",
      "Epoch 80/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.3366 - accuracy: 0.2843 - val_loss: 5.0431 - val_accuracy: 0.2778\n",
      "Epoch 81/150\n",
      "802/802 [==============================] - 0s 54us/step - loss: 2.5476 - accuracy: 0.2656 - val_loss: 4.2616 - val_accuracy: 0.2778\n",
      "Epoch 82/150\n",
      "802/802 [==============================] - 0s 103us/step - loss: 2.5405 - accuracy: 0.2406 - val_loss: 4.1063 - val_accuracy: 0.1111\n",
      "Epoch 83/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 3.1007 - accuracy: 0.2269 - val_loss: 8.6712 - val_accuracy: 0.1889\n",
      "Epoch 84/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 3.0654 - accuracy: 0.2731 - val_loss: 4.0342 - val_accuracy: 0.0556\n",
      "Epoch 85/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5434 - accuracy: 0.2544 - val_loss: 4.8080 - val_accuracy: 0.2778\n",
      "Epoch 86/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5205 - accuracy: 0.2643 - val_loss: 4.2773 - val_accuracy: 0.1111\n",
      "Epoch 87/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6301 - accuracy: 0.2643 - val_loss: 3.1248 - val_accuracy: 0.2778\n",
      "Epoch 88/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.8099 - accuracy: 0.2406 - val_loss: 5.4825 - val_accuracy: 0.2778\n",
      "Epoch 89/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.2393 - accuracy: 0.3105 - val_loss: 4.1367 - val_accuracy: 0.2778\n",
      "Epoch 90/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.1896 - accuracy: 0.2344 - val_loss: 2.6797 - val_accuracy: 0.2778\n",
      "Epoch 91/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.2836 - accuracy: 0.2793 - val_loss: 4.4785 - val_accuracy: 0.1889\n",
      "Epoch 92/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.7743 - accuracy: 0.2456 - val_loss: 2.3628 - val_accuracy: 0.2778\n",
      "Epoch 93/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.2595 - accuracy: 0.2606 - val_loss: 4.5001 - val_accuracy: 0.1111\n",
      "Epoch 94/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.6814 - accuracy: 0.2581 - val_loss: 3.3614 - val_accuracy: 0.2778\n",
      "Epoch 95/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.0662 - accuracy: 0.2893 - val_loss: 2.5232 - val_accuracy: 0.2778\n",
      "Epoch 96/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.1435 - accuracy: 0.2656 - val_loss: 4.4126 - val_accuracy: 0.1889\n",
      "Epoch 97/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.6366 - accuracy: 0.2656 - val_loss: 4.7320 - val_accuracy: 0.1889\n",
      "Epoch 98/150\n",
      "802/802 [==============================] - 0s 94us/step - loss: 2.5126 - accuracy: 0.2643 - val_loss: 3.0689 - val_accuracy: 0.2778\n",
      "Epoch 99/150\n",
      "802/802 [==============================] - 0s 95us/step - loss: 2.5277 - accuracy: 0.2594 - val_loss: 4.4540 - val_accuracy: 0.2778\n",
      "Epoch 100/150\n",
      "802/802 [==============================] - 0s 121us/step - loss: 2.4695 - accuracy: 0.2170 - val_loss: 4.4925 - val_accuracy: 0.1111\n",
      "Epoch 101/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.7056 - accuracy: 0.2170 - val_loss: 2.5356 - val_accuracy: 0.2778\n",
      "Epoch 102/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.0371 - accuracy: 0.3155 - val_loss: 3.8524 - val_accuracy: 0.0222\n",
      "Epoch 103/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.4422 - accuracy: 0.2494 - val_loss: 3.0325 - val_accuracy: 0.2778\n",
      "Epoch 104/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.2878 - accuracy: 0.2743 - val_loss: 6.2484 - val_accuracy: 0.2778\n",
      "Epoch 105/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5924 - accuracy: 0.2943 - val_loss: 4.2836 - val_accuracy: 0.1111\n",
      "Epoch 106/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.5674 - accuracy: 0.2594 - val_loss: 3.9672 - val_accuracy: 0.0333\n",
      "Epoch 107/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.4361 - accuracy: 0.2082 - val_loss: 7.7931 - val_accuracy: 0.2778\n",
      "Epoch 108/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.9493 - accuracy: 0.2681 - val_loss: 8.7734 - val_accuracy: 0.1111\n",
      "Epoch 109/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 3.0156 - accuracy: 0.2606 - val_loss: 4.2787 - val_accuracy: 0.2778\n",
      "Epoch 110/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.4835 - accuracy: 0.2681 - val_loss: 6.8200 - val_accuracy: 0.2778\n",
      "Epoch 111/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.5846 - accuracy: 0.2880 - val_loss: 3.9335 - val_accuracy: 0.1111\n",
      "Epoch 112/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.3260 - accuracy: 0.2843 - val_loss: 4.1792 - val_accuracy: 0.2778\n",
      "Epoch 113/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.4307 - accuracy: 0.2830 - val_loss: 3.2305 - val_accuracy: 0.2778\n",
      "Epoch 114/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3248 - accuracy: 0.2818 - val_loss: 6.6415 - val_accuracy: 0.2778\n",
      "Epoch 115/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.8751 - accuracy: 0.2731 - val_loss: 4.2690 - val_accuracy: 0.1111\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 81us/step - loss: 2.3503 - accuracy: 0.2594 - val_loss: 3.0617 - val_accuracy: 0.2778\n",
      "Epoch 117/150\n",
      "802/802 [==============================] - 0s 84us/step - loss: 2.4259 - accuracy: 0.2843 - val_loss: 2.9887 - val_accuracy: 0.2778\n",
      "Epoch 118/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.3935 - accuracy: 0.2943 - val_loss: 3.7934 - val_accuracy: 0.1889\n",
      "Epoch 119/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.7031 - accuracy: 0.2556 - val_loss: 3.9959 - val_accuracy: 0.1889\n",
      "Epoch 120/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.4554 - accuracy: 0.2830 - val_loss: 3.0810 - val_accuracy: 0.2778\n",
      "Epoch 121/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4279 - accuracy: 0.2793 - val_loss: 4.6148 - val_accuracy: 0.2778\n",
      "Epoch 122/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.5273 - accuracy: 0.2718 - val_loss: 3.8421 - val_accuracy: 0.1111\n",
      "Epoch 123/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6169 - accuracy: 0.2506 - val_loss: 3.5034 - val_accuracy: 0.1889\n",
      "Epoch 124/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6047 - accuracy: 0.2506 - val_loss: 5.8927 - val_accuracy: 0.2778\n",
      "Epoch 125/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.7469 - accuracy: 0.2556 - val_loss: 2.6800 - val_accuracy: 0.2778\n",
      "Epoch 126/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.1048 - accuracy: 0.2756 - val_loss: 5.5023 - val_accuracy: 0.2778\n",
      "Epoch 127/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.4510 - accuracy: 0.2955 - val_loss: 4.3677 - val_accuracy: 0.1889\n",
      "Epoch 128/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4737 - accuracy: 0.2556 - val_loss: 4.0693 - val_accuracy: 0.1111\n",
      "Epoch 129/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.6732 - accuracy: 0.2606 - val_loss: 3.4451 - val_accuracy: 0.2778\n",
      "Epoch 130/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.3901 - accuracy: 0.2743 - val_loss: 4.2202 - val_accuracy: 0.1889\n",
      "Epoch 131/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.4791 - accuracy: 0.2781 - val_loss: 2.5100 - val_accuracy: 0.2778\n",
      "Epoch 132/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.3286 - accuracy: 0.2793 - val_loss: 2.7569 - val_accuracy: 0.2778\n",
      "Epoch 133/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.2459 - accuracy: 0.2581 - val_loss: 5.5097 - val_accuracy: 0.1111\n",
      "Epoch 134/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.5530 - accuracy: 0.2631 - val_loss: 4.4863 - val_accuracy: 0.1111\n",
      "Epoch 135/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.4303 - accuracy: 0.2718 - val_loss: 3.5695 - val_accuracy: 0.2778\n",
      "Epoch 136/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.4337 - accuracy: 0.2581 - val_loss: 4.1130 - val_accuracy: 0.1889\n",
      "Epoch 137/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5620 - accuracy: 0.2718 - val_loss: 3.8865 - val_accuracy: 0.1889\n",
      "Epoch 138/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.2972 - accuracy: 0.2968 - val_loss: 3.9257 - val_accuracy: 0.1111\n",
      "Epoch 139/150\n",
      "802/802 [==============================] - 0s 59us/step - loss: 2.3490 - accuracy: 0.2868 - val_loss: 7.0732 - val_accuracy: 0.2778\n",
      "Epoch 140/150\n",
      "802/802 [==============================] - 0s 57us/step - loss: 2.7495 - accuracy: 0.2718 - val_loss: 7.5798 - val_accuracy: 0.2778\n",
      "Epoch 141/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6830 - accuracy: 0.2843 - val_loss: 4.5906 - val_accuracy: 0.1889\n",
      "Epoch 142/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.6953 - accuracy: 0.2456 - val_loss: 4.1810 - val_accuracy: 0.0222\n",
      "Epoch 143/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.3014 - accuracy: 0.2768 - val_loss: 4.4150 - val_accuracy: 0.2778\n",
      "Epoch 144/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.3980 - accuracy: 0.2556 - val_loss: 3.1668 - val_accuracy: 0.2778\n",
      "Epoch 145/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.3100 - accuracy: 0.2943 - val_loss: 8.6961 - val_accuracy: 0.1889\n",
      "Epoch 146/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.9532 - accuracy: 0.2693 - val_loss: 4.0763 - val_accuracy: 0.1111\n",
      "Epoch 147/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.5805 - accuracy: 0.2419 - val_loss: 4.4548 - val_accuracy: 0.1889\n",
      "Epoch 148/150\n",
      "802/802 [==============================] - 0s 61us/step - loss: 2.7302 - accuracy: 0.2307 - val_loss: 7.4063 - val_accuracy: 0.2778\n",
      "Epoch 149/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.9300 - accuracy: 0.2668 - val_loss: 3.5423 - val_accuracy: 0.2778\n",
      "Epoch 150/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5229 - accuracy: 0.2631 - val_loss: 5.3696 - val_accuracy: 0.2778\n",
      "460/460 [==============================] - 0s 57us/step\n",
      "Loss: 5.34\n",
      "Accuracy 0.29\n",
      "Train on 802 samples, validate on 90 samples\n",
      "Epoch 1/150\n",
      "802/802 [==============================] - 1s 934us/step - loss: 2.1473 - accuracy: 0.2943 - val_loss: 2.6985 - val_accuracy: 0.2778\n",
      "Epoch 2/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.6132 - accuracy: 0.2868 - val_loss: 3.8022 - val_accuracy: 0.2778\n",
      "Epoch 3/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.1707 - accuracy: 0.3155 - val_loss: 2.7887 - val_accuracy: 0.2778\n",
      "Epoch 4/150\n",
      "802/802 [==============================] - 0s 79us/step - loss: 2.3473 - accuracy: 0.2556 - val_loss: 4.3237 - val_accuracy: 0.1889\n",
      "Epoch 5/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.6547 - accuracy: 0.2618 - val_loss: 3.0019 - val_accuracy: 0.2778\n",
      "Epoch 6/150\n",
      "802/802 [==============================] - 0s 87us/step - loss: 2.5965 - accuracy: 0.2556 - val_loss: 3.7348 - val_accuracy: 0.1889\n",
      "Epoch 7/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.3285 - accuracy: 0.2718 - val_loss: 5.1640 - val_accuracy: 0.2778\n",
      "Epoch 8/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.3954 - accuracy: 0.3080 - val_loss: 3.9987 - val_accuracy: 0.0222\n",
      "Epoch 9/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.6778 - accuracy: 0.2120 - val_loss: 6.7973 - val_accuracy: 0.2778\n",
      "Epoch 10/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.4234 - accuracy: 0.2668 - val_loss: 4.8499 - val_accuracy: 0.2778\n",
      "Epoch 11/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.4143 - accuracy: 0.2918 - val_loss: 8.0539 - val_accuracy: 0.2778\n",
      "Epoch 12/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.9439 - accuracy: 0.2905 - val_loss: 3.5777 - val_accuracy: 0.1111\n",
      "Epoch 13/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.4679 - accuracy: 0.2332 - val_loss: 3.4543 - val_accuracy: 0.1889\n",
      "Epoch 14/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.5009 - accuracy: 0.2656 - val_loss: 2.7665 - val_accuracy: 0.2778\n",
      "Epoch 15/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.2299 - accuracy: 0.2781 - val_loss: 5.4728 - val_accuracy: 0.1889\n",
      "Epoch 16/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.6462 - accuracy: 0.2544 - val_loss: 3.5868 - val_accuracy: 0.1889\n",
      "Epoch 17/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.2171 - accuracy: 0.2781 - val_loss: 4.8584 - val_accuracy: 0.2778\n",
      "Epoch 18/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.3786 - accuracy: 0.2993 - val_loss: 9.0643 - val_accuracy: 0.1889\n",
      "Epoch 19/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 3.0228 - accuracy: 0.2818 - val_loss: 4.1224 - val_accuracy: 0.1889\n",
      "Epoch 20/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.4710 - accuracy: 0.2656 - val_loss: 3.5743 - val_accuracy: 0.1889\n",
      "Epoch 21/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.5557 - accuracy: 0.2731 - val_loss: 5.3711 - val_accuracy: 0.1111\n",
      "Epoch 22/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.5609 - accuracy: 0.2419 - val_loss: 4.4724 - val_accuracy: 0.2778\n",
      "Epoch 23/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.4209 - accuracy: 0.2731 - val_loss: 3.7848 - val_accuracy: 0.2778\n",
      "Epoch 24/150\n",
      "802/802 [==============================] - 0s 60us/step - loss: 2.5935 - accuracy: 0.2618 - val_loss: 3.0983 - val_accuracy: 0.2778\n",
      "Epoch 25/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.0085 - accuracy: 0.2980 - val_loss: 5.3411 - val_accuracy: 0.1111\n",
      "Epoch 26/150\n",
      "802/802 [==============================] - 0s 62us/step - loss: 2.5622 - accuracy: 0.2406 - val_loss: 4.2697 - val_accuracy: 0.2778\n",
      "Epoch 27/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.3240 - accuracy: 0.2781 - val_loss: 4.7503 - val_accuracy: 0.1111\n",
      "Epoch 28/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.5830 - accuracy: 0.2581 - val_loss: 3.1895 - val_accuracy: 0.2778\n",
      "Epoch 29/150\n",
      "802/802 [==============================] - 0s 84us/step - loss: 2.6176 - accuracy: 0.3080 - val_loss: 3.0639 - val_accuracy: 0.2778\n",
      "Epoch 30/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.4122 - accuracy: 0.2718 - val_loss: 4.4980 - val_accuracy: 0.2778\n",
      "Epoch 31/150\n",
      "802/802 [==============================] - 0s 94us/step - loss: 2.3602 - accuracy: 0.3005 - val_loss: 4.9011 - val_accuracy: 0.1111\n",
      "Epoch 32/150\n",
      "802/802 [==============================] - 0s 82us/step - loss: 2.4648 - accuracy: 0.2544 - val_loss: 3.7224 - val_accuracy: 0.1889\n",
      "Epoch 33/150\n",
      "802/802 [==============================] - 0s 92us/step - loss: 2.4708 - accuracy: 0.2469 - val_loss: 5.3427 - val_accuracy: 0.2778\n",
      "Epoch 34/150\n",
      "802/802 [==============================] - 0s 79us/step - loss: 2.6234 - accuracy: 0.2818 - val_loss: 3.8678 - val_accuracy: 0.0111\n",
      "Epoch 35/150\n",
      "802/802 [==============================] - 0s 96us/step - loss: 2.1565 - accuracy: 0.2693 - val_loss: 3.0422 - val_accuracy: 0.2778\n",
      "Epoch 36/150\n",
      "802/802 [==============================] - 0s 108us/step - loss: 2.4107 - accuracy: 0.2781 - val_loss: 3.2367 - val_accuracy: 0.2778\n",
      "Epoch 37/150\n",
      "802/802 [==============================] - 0s 89us/step - loss: 2.0445 - accuracy: 0.2531 - val_loss: 6.0598 - val_accuracy: 0.2778\n",
      "Epoch 38/150\n",
      "802/802 [==============================] - 0s 96us/step - loss: 2.5479 - accuracy: 0.2743 - val_loss: 2.8473 - val_accuracy: 0.2778\n",
      "Epoch 39/150\n",
      "802/802 [==============================] - 0s 151us/step - loss: 2.2924 - accuracy: 0.2893 - val_loss: 2.9532 - val_accuracy: 0.1889\n",
      "Epoch 40/150\n",
      "802/802 [==============================] - 0s 137us/step - loss: 2.0056 - accuracy: 0.2955 - val_loss: 4.2564 - val_accuracy: 0.1111\n",
      "Epoch 41/150\n",
      "802/802 [==============================] - 0s 127us/step - loss: 2.7185 - accuracy: 0.2456 - val_loss: 6.4908 - val_accuracy: 0.2778\n",
      "Epoch 42/150\n",
      "802/802 [==============================] - 0s 101us/step - loss: 2.4710 - accuracy: 0.2980 - val_loss: 3.8376 - val_accuracy: 0.1111\n",
      "Epoch 43/150\n",
      "802/802 [==============================] - 0s 91us/step - loss: 2.6555 - accuracy: 0.2631 - val_loss: 3.0752 - val_accuracy: 0.1889\n",
      "Epoch 44/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.5117 - accuracy: 0.2419 - val_loss: 4.2915 - val_accuracy: 0.1111\n",
      "Epoch 45/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 3.0080 - accuracy: 0.2382 - val_loss: 4.8042 - val_accuracy: 0.1889\n",
      "Epoch 46/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.3555 - accuracy: 0.2793 - val_loss: 2.7606 - val_accuracy: 0.2778\n",
      "Epoch 47/150\n",
      "802/802 [==============================] - 0s 87us/step - loss: 2.2241 - accuracy: 0.2943 - val_loss: 4.7192 - val_accuracy: 0.2778\n",
      "Epoch 48/150\n",
      "802/802 [==============================] - 0s 91us/step - loss: 2.4898 - accuracy: 0.2668 - val_loss: 3.2416 - val_accuracy: 0.2778\n",
      "Epoch 49/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.2243 - accuracy: 0.2980 - val_loss: 7.9933 - val_accuracy: 0.2778\n",
      "Epoch 50/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.8802 - accuracy: 0.2955 - val_loss: 4.2641 - val_accuracy: 0.2778\n",
      "Epoch 51/150\n",
      "802/802 [==============================] - 0s 86us/step - loss: 2.4109 - accuracy: 0.2618 - val_loss: 4.2648 - val_accuracy: 0.2778\n",
      "Epoch 52/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.5061 - accuracy: 0.2793 - val_loss: 7.5627 - val_accuracy: 0.2778\n",
      "Epoch 53/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.8107 - accuracy: 0.2855 - val_loss: 3.2540 - val_accuracy: 0.2778\n",
      "Epoch 54/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.2781 - accuracy: 0.2643 - val_loss: 5.2238 - val_accuracy: 0.2778\n",
      "Epoch 55/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.4325 - accuracy: 0.2993 - val_loss: 5.4834 - val_accuracy: 0.1889\n",
      "Epoch 56/150\n",
      "802/802 [==============================] - 0s 85us/step - loss: 2.5429 - accuracy: 0.2693 - val_loss: 3.6128 - val_accuracy: 0.1889\n",
      "Epoch 57/150\n",
      "802/802 [==============================] - 0s 89us/step - loss: 2.5649 - accuracy: 0.2681 - val_loss: 9.2534 - val_accuracy: 0.1889\n",
      "Epoch 58/150\n",
      "802/802 [==============================] - 0s 97us/step - loss: 2.9417 - accuracy: 0.2905 - val_loss: 3.6829 - val_accuracy: 0.1889\n",
      "Epoch 59/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.5010 - accuracy: 0.2581 - val_loss: 4.1812 - val_accuracy: 0.1889\n",
      "Epoch 60/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.6681 - accuracy: 0.2344 - val_loss: 7.6612 - val_accuracy: 0.2778\n",
      "Epoch 61/150\n",
      "802/802 [==============================] - 0s 85us/step - loss: 2.8258 - accuracy: 0.2905 - val_loss: 8.3762 - val_accuracy: 0.1111\n",
      "Epoch 62/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.9800 - accuracy: 0.2394 - val_loss: 4.1870 - val_accuracy: 0.2778\n",
      "Epoch 63/150\n",
      "802/802 [==============================] - 0s 79us/step - loss: 2.3467 - accuracy: 0.2993 - val_loss: 2.9856 - val_accuracy: 0.2778\n",
      "Epoch 64/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.8259 - accuracy: 0.2481 - val_loss: 4.7599 - val_accuracy: 0.1111\n",
      "Epoch 65/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.7157 - accuracy: 0.2394 - val_loss: 2.8164 - val_accuracy: 0.2778\n",
      "Epoch 66/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.2568 - accuracy: 0.2781 - val_loss: 4.4216 - val_accuracy: 0.2778\n",
      "Epoch 67/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.3560 - accuracy: 0.3042 - val_loss: 3.0130 - val_accuracy: 0.2778\n",
      "Epoch 68/150\n",
      "802/802 [==============================] - 0s 100us/step - loss: 2.1933 - accuracy: 0.2756 - val_loss: 2.8825 - val_accuracy: 0.2778\n",
      "Epoch 69/150\n",
      "802/802 [==============================] - 0s 99us/step - loss: 2.5226 - accuracy: 0.2494 - val_loss: 2.6826 - val_accuracy: 0.2778\n",
      "Epoch 70/150\n",
      "802/802 [==============================] - 0s 102us/step - loss: 2.1402 - accuracy: 0.3055 - val_loss: 6.1091 - val_accuracy: 0.2778\n",
      "Epoch 71/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.7004 - accuracy: 0.2581 - val_loss: 3.0937 - val_accuracy: 0.2778\n",
      "Epoch 72/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.4675 - accuracy: 0.2618 - val_loss: 3.7893 - val_accuracy: 0.1889\n",
      "Epoch 73/150\n",
      "802/802 [==============================] - 0s 130us/step - loss: 2.8289 - accuracy: 0.2681 - val_loss: 3.9621 - val_accuracy: 0.1889\n",
      "Epoch 74/150\n",
      "802/802 [==============================] - 0s 181us/step - loss: 2.4190 - accuracy: 0.2830 - val_loss: 4.5271 - val_accuracy: 0.2778\n",
      "Epoch 75/150\n",
      "802/802 [==============================] - 0s 117us/step - loss: 2.5291 - accuracy: 0.2793 - val_loss: 7.5936 - val_accuracy: 0.2778\n",
      "Epoch 76/150\n",
      "802/802 [==============================] - 0s 113us/step - loss: 2.6515 - accuracy: 0.2631 - val_loss: 3.8926 - val_accuracy: 0.1111\n",
      "Epoch 77/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 82us/step - loss: 2.5148 - accuracy: 0.2793 - val_loss: 7.0615 - val_accuracy: 0.2778\n",
      "Epoch 78/150\n",
      "802/802 [==============================] - 0s 96us/step - loss: 2.6090 - accuracy: 0.2918 - val_loss: 3.3300 - val_accuracy: 0.1889\n",
      "Epoch 79/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.3567 - accuracy: 0.2668 - val_loss: 3.6280 - val_accuracy: 0.2778\n",
      "Epoch 80/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.3918 - accuracy: 0.2830 - val_loss: 4.3626 - val_accuracy: 0.1889\n",
      "Epoch 81/150\n",
      "802/802 [==============================] - 0s 108us/step - loss: 2.3870 - accuracy: 0.2918 - val_loss: 3.7697 - val_accuracy: 0.1111\n",
      "Epoch 82/150\n",
      "802/802 [==============================] - 0s 91us/step - loss: 2.5623 - accuracy: 0.2569 - val_loss: 3.5591 - val_accuracy: 0.1889\n",
      "Epoch 83/150\n",
      "802/802 [==============================] - 0s 95us/step - loss: 2.7053 - accuracy: 0.2481 - val_loss: 3.5405 - val_accuracy: 0.1889\n",
      "Epoch 84/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.6565 - accuracy: 0.2419 - val_loss: 6.0740 - val_accuracy: 0.2778\n",
      "Epoch 85/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.5567 - accuracy: 0.3017 - val_loss: 7.9668 - val_accuracy: 0.2778\n",
      "Epoch 86/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.8357 - accuracy: 0.2905 - val_loss: 5.1685 - val_accuracy: 0.2778\n",
      "Epoch 87/150\n",
      "802/802 [==============================] - 0s 117us/step - loss: 2.5061 - accuracy: 0.2731 - val_loss: 3.3965 - val_accuracy: 0.1889\n",
      "Epoch 88/150\n",
      "802/802 [==============================] - 0s 103us/step - loss: 2.3357 - accuracy: 0.2868 - val_loss: 3.9328 - val_accuracy: 0.1111\n",
      "Epoch 89/150\n",
      "802/802 [==============================] - 0s 107us/step - loss: 2.9123 - accuracy: 0.2469 - val_loss: 3.7642 - val_accuracy: 0.0556\n",
      "Epoch 90/150\n",
      "802/802 [==============================] - 0s 79us/step - loss: 2.3259 - accuracy: 0.2643 - val_loss: 4.8767 - val_accuracy: 0.1889\n",
      "Epoch 91/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.8172 - accuracy: 0.2406 - val_loss: 4.3455 - val_accuracy: 0.1889\n",
      "Epoch 92/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.5388 - accuracy: 0.2643 - val_loss: 4.1402 - val_accuracy: 0.2778\n",
      "Epoch 93/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.5655 - accuracy: 0.2419 - val_loss: 6.4683 - val_accuracy: 0.1889\n",
      "Epoch 94/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.9179 - accuracy: 0.2357 - val_loss: 7.3739 - val_accuracy: 0.2778\n",
      "Epoch 95/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.6939 - accuracy: 0.2693 - val_loss: 7.6171 - val_accuracy: 0.2778\n",
      "Epoch 96/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.6446 - accuracy: 0.2594 - val_loss: 3.4797 - val_accuracy: 0.1889\n",
      "Epoch 97/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.1871 - accuracy: 0.2930 - val_loss: 3.1555 - val_accuracy: 0.2778\n",
      "Epoch 98/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.4490 - accuracy: 0.2918 - val_loss: 7.0607 - val_accuracy: 0.2778\n",
      "Epoch 99/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.6756 - accuracy: 0.3005 - val_loss: 4.7500 - val_accuracy: 0.1111\n",
      "Epoch 100/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.5199 - accuracy: 0.2219 - val_loss: 5.6727 - val_accuracy: 0.1889\n",
      "Epoch 101/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.6190 - accuracy: 0.2382 - val_loss: 4.6666 - val_accuracy: 0.2778\n",
      "Epoch 102/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.3866 - accuracy: 0.2930 - val_loss: 4.2027 - val_accuracy: 0.2778\n",
      "Epoch 103/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.6862 - accuracy: 0.2519 - val_loss: 5.5607 - val_accuracy: 0.1111\n",
      "Epoch 104/150\n",
      "802/802 [==============================] - 0s 87us/step - loss: 2.9011 - accuracy: 0.2394 - val_loss: 4.2325 - val_accuracy: 0.2778\n",
      "Epoch 105/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.4642 - accuracy: 0.2581 - val_loss: 3.5663 - val_accuracy: 0.1889\n",
      "Epoch 106/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.8096 - accuracy: 0.2369 - val_loss: 7.2689 - val_accuracy: 0.2778\n",
      "Epoch 107/150\n",
      "802/802 [==============================] - 0s 79us/step - loss: 2.7798 - accuracy: 0.2781 - val_loss: 3.3422 - val_accuracy: 0.2778\n",
      "Epoch 108/150\n",
      "802/802 [==============================] - 0s 87us/step - loss: 2.8581 - accuracy: 0.2494 - val_loss: 5.7683 - val_accuracy: 0.2778\n",
      "Epoch 109/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.5690 - accuracy: 0.2943 - val_loss: 3.7811 - val_accuracy: 0.1111\n",
      "Epoch 110/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.2763 - accuracy: 0.2743 - val_loss: 2.5631 - val_accuracy: 0.2778\n",
      "Epoch 111/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.5732 - accuracy: 0.2481 - val_loss: 4.6106 - val_accuracy: 0.2778\n",
      "Epoch 112/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.5162 - accuracy: 0.2718 - val_loss: 3.8440 - val_accuracy: 0.2778\n",
      "Epoch 113/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.5540 - accuracy: 0.2257 - val_loss: 3.7950 - val_accuracy: 0.1889\n",
      "Epoch 114/150\n",
      "802/802 [==============================] - 0s 90us/step - loss: 2.5211 - accuracy: 0.2494 - val_loss: 4.9838 - val_accuracy: 0.0556\n",
      "Epoch 115/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.3035 - accuracy: 0.2656 - val_loss: 3.6325 - val_accuracy: 0.1889\n",
      "Epoch 116/150\n",
      "802/802 [==============================] - 0s 87us/step - loss: 2.5677 - accuracy: 0.2531 - val_loss: 5.1590 - val_accuracy: 0.1111\n",
      "Epoch 117/150\n",
      "802/802 [==============================] - 0s 81us/step - loss: 2.6363 - accuracy: 0.2718 - val_loss: 6.9078 - val_accuracy: 0.2778\n",
      "Epoch 118/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.7242 - accuracy: 0.2494 - val_loss: 4.1242 - val_accuracy: 0.1111\n",
      "Epoch 119/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.7216 - accuracy: 0.2444 - val_loss: 4.2267 - val_accuracy: 0.0111\n",
      "Epoch 120/150\n",
      "802/802 [==============================] - 0s 100us/step - loss: 2.4857 - accuracy: 0.2519 - val_loss: 2.5410 - val_accuracy: 0.2778\n",
      "Epoch 121/150\n",
      "802/802 [==============================] - 0s 87us/step - loss: 2.2794 - accuracy: 0.2855 - val_loss: 3.0643 - val_accuracy: 0.2778\n",
      "Epoch 122/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.2406 - accuracy: 0.2768 - val_loss: 3.9809 - val_accuracy: 0.0222\n",
      "Epoch 123/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.2889 - accuracy: 0.2506 - val_loss: 5.4712 - val_accuracy: 0.1889\n",
      "Epoch 124/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.6827 - accuracy: 0.2731 - val_loss: 3.1427 - val_accuracy: 0.1889\n",
      "Epoch 125/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.8121 - accuracy: 0.2269 - val_loss: 4.3949 - val_accuracy: 0.0556\n",
      "Epoch 126/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.3577 - accuracy: 0.2319 - val_loss: 7.0698 - val_accuracy: 0.2778\n",
      "Epoch 127/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.7558 - accuracy: 0.2905 - val_loss: 3.8003 - val_accuracy: 0.2778\n",
      "Epoch 128/150\n",
      "802/802 [==============================] - 0s 81us/step - loss: 2.2115 - accuracy: 0.2980 - val_loss: 3.9261 - val_accuracy: 0.2778\n",
      "Epoch 129/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.3142 - accuracy: 0.2743 - val_loss: 5.3278 - val_accuracy: 0.1889\n",
      "Epoch 130/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.3783 - accuracy: 0.2631 - val_loss: 3.0671 - val_accuracy: 0.2778\n",
      "Epoch 131/150\n",
      "802/802 [==============================] - 0s 113us/step - loss: 2.5838 - accuracy: 0.2731 - val_loss: 3.6421 - val_accuracy: 0.2778\n",
      "Epoch 132/150\n",
      "802/802 [==============================] - 0s 118us/step - loss: 2.4941 - accuracy: 0.2481 - val_loss: 4.9676 - val_accuracy: 0.0333\n",
      "Epoch 133/150\n",
      "802/802 [==============================] - 0s 112us/step - loss: 2.5191 - accuracy: 0.2319 - val_loss: 5.0281 - val_accuracy: 0.1889\n",
      "Epoch 134/150\n",
      "802/802 [==============================] - 0s 130us/step - loss: 2.7884 - accuracy: 0.2569 - val_loss: 3.9692 - val_accuracy: 0.1889\n",
      "Epoch 135/150\n",
      "802/802 [==============================] - 0s 113us/step - loss: 2.3467 - accuracy: 0.2706 - val_loss: 3.8366 - val_accuracy: 0.0333\n",
      "Epoch 136/150\n",
      "802/802 [==============================] - 0s 81us/step - loss: 2.6690 - accuracy: 0.2294 - val_loss: 4.5021 - val_accuracy: 0.0556\n",
      "Epoch 137/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.7863 - accuracy: 0.2095 - val_loss: 4.8279 - val_accuracy: 0.2778\n",
      "Epoch 138/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.4274 - accuracy: 0.2681 - val_loss: 2.8190 - val_accuracy: 0.2778\n",
      "Epoch 139/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.5168 - accuracy: 0.2506 - val_loss: 3.8875 - val_accuracy: 0.0333\n",
      "Epoch 140/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.3538 - accuracy: 0.2382 - val_loss: 4.5667 - val_accuracy: 0.1111\n",
      "Epoch 141/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 3.2884 - accuracy: 0.2294 - val_loss: 3.9463 - val_accuracy: 0.1889\n",
      "Epoch 142/150\n",
      "802/802 [==============================] - 0s 82us/step - loss: 2.3413 - accuracy: 0.2980 - val_loss: 3.4727 - val_accuracy: 0.2778\n",
      "Epoch 143/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.7638 - accuracy: 0.2631 - val_loss: 4.1209 - val_accuracy: 0.0222\n",
      "Epoch 144/150\n",
      "802/802 [==============================] - 0s 80us/step - loss: 2.1989 - accuracy: 0.2768 - val_loss: 5.8166 - val_accuracy: 0.1111\n",
      "Epoch 145/150\n",
      "802/802 [==============================] - 0s 86us/step - loss: 2.7624 - accuracy: 0.2394 - val_loss: 8.2530 - val_accuracy: 0.1889\n",
      "Epoch 146/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.9664 - accuracy: 0.2706 - val_loss: 4.6920 - val_accuracy: 0.2778\n",
      "Epoch 147/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.2705 - accuracy: 0.2880 - val_loss: 7.9830 - val_accuracy: 0.2778\n",
      "Epoch 148/150\n",
      "802/802 [==============================] - 0s 79us/step - loss: 2.7830 - accuracy: 0.3005 - val_loss: 4.2996 - val_accuracy: 0.2778\n",
      "Epoch 149/150\n",
      "802/802 [==============================] - 0s 112us/step - loss: 2.2435 - accuracy: 0.2930 - val_loss: 7.7658 - val_accuracy: 0.2778\n",
      "Epoch 150/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 3.2819 - accuracy: 0.2269 - val_loss: 5.9716 - val_accuracy: 0.0333\n",
      "460/460 [==============================] - 0s 74us/step\n",
      "Loss: 5.95\n",
      "Accuracy 0.01\n",
      "Train on 802 samples, validate on 90 samples\n",
      "Epoch 1/150\n",
      "802/802 [==============================] - 1s 991us/step - loss: 2.0594 - accuracy: 0.2818 - val_loss: 3.0157 - val_accuracy: 0.2778\n",
      "Epoch 2/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.7111 - accuracy: 0.2756 - val_loss: 4.3722 - val_accuracy: 0.1111\n",
      "Epoch 3/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.4748 - accuracy: 0.2656 - val_loss: 8.0800 - val_accuracy: 0.2778\n",
      "Epoch 4/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.9248 - accuracy: 0.2556 - val_loss: 4.9874 - val_accuracy: 0.2778\n",
      "Epoch 5/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.5042 - accuracy: 0.3030 - val_loss: 3.7040 - val_accuracy: 0.1889\n",
      "Epoch 6/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.6902 - accuracy: 0.2357 - val_loss: 4.4623 - val_accuracy: 0.1111\n",
      "Epoch 7/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.6588 - accuracy: 0.2631 - val_loss: 2.9514 - val_accuracy: 0.2778\n",
      "Epoch 8/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.4765 - accuracy: 0.2880 - val_loss: 7.5832 - val_accuracy: 0.2778\n",
      "Epoch 9/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.7029 - accuracy: 0.2905 - val_loss: 4.1929 - val_accuracy: 0.1889\n",
      "Epoch 10/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.2907 - accuracy: 0.2893 - val_loss: 2.7580 - val_accuracy: 0.2778\n",
      "Epoch 11/150\n",
      "802/802 [==============================] - 0s 81us/step - loss: 2.1884 - accuracy: 0.2805 - val_loss: 2.8991 - val_accuracy: 0.2778\n",
      "Epoch 12/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.5784 - accuracy: 0.2544 - val_loss: 2.9319 - val_accuracy: 0.2778\n",
      "Epoch 13/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.2760 - accuracy: 0.2855 - val_loss: 2.9739 - val_accuracy: 0.2778\n",
      "Epoch 14/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.4688 - accuracy: 0.2793 - val_loss: 4.7969 - val_accuracy: 0.1889\n",
      "Epoch 15/150\n",
      "802/802 [==============================] - 0s 89us/step - loss: 2.6265 - accuracy: 0.2319 - val_loss: 7.4007 - val_accuracy: 0.2778\n",
      "Epoch 16/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.9520 - accuracy: 0.2693 - val_loss: 4.5725 - val_accuracy: 0.2778\n",
      "Epoch 17/150\n",
      "802/802 [==============================] - 0s 91us/step - loss: 2.2213 - accuracy: 0.3030 - val_loss: 4.6449 - val_accuracy: 0.1111\n",
      "Epoch 18/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.4870 - accuracy: 0.2643 - val_loss: 4.3122 - val_accuracy: 0.1111\n",
      "Epoch 19/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.6569 - accuracy: 0.2855 - val_loss: 6.3734 - val_accuracy: 0.2778\n",
      "Epoch 20/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.6294 - accuracy: 0.2855 - val_loss: 2.6210 - val_accuracy: 0.2778\n",
      "Epoch 21/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.2495 - accuracy: 0.2855 - val_loss: 4.2130 - val_accuracy: 0.2778\n",
      "Epoch 22/150\n",
      "802/802 [==============================] - 0s 96us/step - loss: 2.3680 - accuracy: 0.2643 - val_loss: 4.5015 - val_accuracy: 0.1111\n",
      "Epoch 23/150\n",
      "802/802 [==============================] - 0s 87us/step - loss: 2.4981 - accuracy: 0.2918 - val_loss: 4.4070 - val_accuracy: 0.0222\n",
      "Epoch 24/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.4228 - accuracy: 0.2581 - val_loss: 3.7556 - val_accuracy: 0.1889\n",
      "Epoch 25/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.3923 - accuracy: 0.2618 - val_loss: 3.8822 - val_accuracy: 0.1111\n",
      "Epoch 26/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.4956 - accuracy: 0.2444 - val_loss: 4.3533 - val_accuracy: 0.0222\n",
      "Epoch 27/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.3654 - accuracy: 0.2544 - val_loss: 3.4469 - val_accuracy: 0.2778\n",
      "Epoch 28/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.1917 - accuracy: 0.2880 - val_loss: 4.5488 - val_accuracy: 0.1889\n",
      "Epoch 29/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.5388 - accuracy: 0.2668 - val_loss: 2.9472 - val_accuracy: 0.2778\n",
      "Epoch 30/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.3930 - accuracy: 0.2781 - val_loss: 5.4502 - val_accuracy: 0.1111\n",
      "Epoch 31/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.3668 - accuracy: 0.3055 - val_loss: 3.5490 - val_accuracy: 0.1889\n",
      "Epoch 32/150\n",
      "802/802 [==============================] - 0s 85us/step - loss: 2.3640 - accuracy: 0.2718 - val_loss: 2.9826 - val_accuracy: 0.2778\n",
      "Epoch 33/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.2316 - accuracy: 0.2756 - val_loss: 4.3784 - val_accuracy: 0.1889\n",
      "Epoch 34/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.4710 - accuracy: 0.3017 - val_loss: 3.9844 - val_accuracy: 0.0556\n",
      "Epoch 35/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.5570 - accuracy: 0.2494 - val_loss: 3.2243 - val_accuracy: 0.2778\n",
      "Epoch 36/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.9228 - accuracy: 0.2394 - val_loss: 5.2760 - val_accuracy: 0.1889\n",
      "Epoch 37/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.6235 - accuracy: 0.2643 - val_loss: 6.4061 - val_accuracy: 0.2778\n",
      "Epoch 38/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 75us/step - loss: 2.6515 - accuracy: 0.2893 - val_loss: 3.0536 - val_accuracy: 0.2778\n",
      "Epoch 39/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.6012 - accuracy: 0.2693 - val_loss: 4.5533 - val_accuracy: 0.2778\n",
      "Epoch 40/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.4630 - accuracy: 0.2830 - val_loss: 5.9424 - val_accuracy: 0.2778\n",
      "Epoch 41/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.5967 - accuracy: 0.2731 - val_loss: 4.0489 - val_accuracy: 0.1111\n",
      "Epoch 42/150\n",
      "802/802 [==============================] - 0s 85us/step - loss: 2.6720 - accuracy: 0.2656 - val_loss: 5.3701 - val_accuracy: 0.1111\n",
      "Epoch 43/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.7496 - accuracy: 0.2394 - val_loss: 4.3608 - val_accuracy: 0.2778\n",
      "Epoch 44/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.5446 - accuracy: 0.2581 - val_loss: 4.7381 - val_accuracy: 0.1111\n",
      "Epoch 45/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.7417 - accuracy: 0.2668 - val_loss: 3.7472 - val_accuracy: 0.1111\n",
      "Epoch 46/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.4315 - accuracy: 0.2743 - val_loss: 8.2499 - val_accuracy: 0.1889\n",
      "Epoch 47/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.7894 - accuracy: 0.2781 - val_loss: 3.9427 - val_accuracy: 0.1889\n",
      "Epoch 48/150\n",
      "802/802 [==============================] - 0s 106us/step - loss: 2.2719 - accuracy: 0.2918 - val_loss: 7.1013 - val_accuracy: 0.2778\n",
      "Epoch 49/150\n",
      "802/802 [==============================] - 0s 112us/step - loss: 2.8220 - accuracy: 0.2456 - val_loss: 3.7121 - val_accuracy: 0.1889\n",
      "Epoch 50/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.6246 - accuracy: 0.2469 - val_loss: 4.6331 - val_accuracy: 0.2778\n",
      "Epoch 51/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.1766 - accuracy: 0.3005 - val_loss: 3.5552 - val_accuracy: 0.1889\n",
      "Epoch 52/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.5212 - accuracy: 0.2594 - val_loss: 3.9330 - val_accuracy: 0.0222\n",
      "Epoch 53/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.4036 - accuracy: 0.2232 - val_loss: 5.0423 - val_accuracy: 0.0111\n",
      "Epoch 54/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.5379 - accuracy: 0.2606 - val_loss: 4.0745 - val_accuracy: 0.0556\n",
      "Epoch 55/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.4452 - accuracy: 0.2357 - val_loss: 3.5838 - val_accuracy: 0.1889\n",
      "Epoch 56/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.6023 - accuracy: 0.2718 - val_loss: 5.6699 - val_accuracy: 0.2778\n",
      "Epoch 57/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.5097 - accuracy: 0.2955 - val_loss: 8.1291 - val_accuracy: 0.2778\n",
      "Epoch 58/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.8559 - accuracy: 0.2943 - val_loss: 3.5623 - val_accuracy: 0.1889\n",
      "Epoch 59/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.7447 - accuracy: 0.2257 - val_loss: 4.7281 - val_accuracy: 0.1111\n",
      "Epoch 60/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.6709 - accuracy: 0.2219 - val_loss: 3.6255 - val_accuracy: 0.2778\n",
      "Epoch 61/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.1992 - accuracy: 0.2706 - val_loss: 4.0462 - val_accuracy: 0.0556\n",
      "Epoch 62/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.5784 - accuracy: 0.2244 - val_loss: 3.5099 - val_accuracy: 0.2778\n",
      "Epoch 63/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.2816 - accuracy: 0.2643 - val_loss: 2.5617 - val_accuracy: 0.2778\n",
      "Epoch 64/150\n",
      "802/802 [==============================] - 0s 94us/step - loss: 2.3658 - accuracy: 0.2718 - val_loss: 4.1826 - val_accuracy: 0.1889\n",
      "Epoch 65/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.3159 - accuracy: 0.2943 - val_loss: 3.9556 - val_accuracy: 0.2778\n",
      "Epoch 66/150\n",
      "802/802 [==============================] - 0s 84us/step - loss: 2.1963 - accuracy: 0.2855 - val_loss: 3.5790 - val_accuracy: 0.1889\n",
      "Epoch 67/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.8721 - accuracy: 0.2045 - val_loss: 7.0176 - val_accuracy: 0.2778\n",
      "Epoch 68/150\n",
      "802/802 [==============================] - 0s 85us/step - loss: 2.6533 - accuracy: 0.2855 - val_loss: 3.6712 - val_accuracy: 0.1889\n",
      "Epoch 69/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.6990 - accuracy: 0.2544 - val_loss: 3.6434 - val_accuracy: 0.1889\n",
      "Epoch 70/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.8418 - accuracy: 0.2431 - val_loss: 3.0315 - val_accuracy: 0.2778\n",
      "Epoch 71/150\n",
      "802/802 [==============================] - 0s 81us/step - loss: 2.3424 - accuracy: 0.3092 - val_loss: 3.0585 - val_accuracy: 0.2778\n",
      "Epoch 72/150\n",
      "802/802 [==============================] - 0s 89us/step - loss: 2.5183 - accuracy: 0.2481 - val_loss: 3.1068 - val_accuracy: 0.2778\n",
      "Epoch 73/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.3038 - accuracy: 0.3005 - val_loss: 5.6470 - val_accuracy: 0.0556\n",
      "Epoch 74/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.9778 - accuracy: 0.2294 - val_loss: 3.5537 - val_accuracy: 0.2778\n",
      "Epoch 75/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.2557 - accuracy: 0.2618 - val_loss: 4.5802 - val_accuracy: 0.1111\n",
      "Epoch 76/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 3.0497 - accuracy: 0.2431 - val_loss: 4.4512 - val_accuracy: 0.0111\n",
      "Epoch 77/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.4543 - accuracy: 0.2431 - val_loss: 4.5720 - val_accuracy: 0.0556\n",
      "Epoch 78/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.3905 - accuracy: 0.2793 - val_loss: 3.5148 - val_accuracy: 0.2778\n",
      "Epoch 79/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.5784 - accuracy: 0.2581 - val_loss: 4.5551 - val_accuracy: 0.1889\n",
      "Epoch 80/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.3770 - accuracy: 0.2556 - val_loss: 5.2818 - val_accuracy: 0.1111\n",
      "Epoch 81/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.5787 - accuracy: 0.2643 - val_loss: 3.0421 - val_accuracy: 0.2778\n",
      "Epoch 82/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.0693 - accuracy: 0.3117 - val_loss: 3.6853 - val_accuracy: 0.2778\n",
      "Epoch 83/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.4067 - accuracy: 0.2494 - val_loss: 3.0614 - val_accuracy: 0.2778\n",
      "Epoch 84/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.3757 - accuracy: 0.2855 - val_loss: 2.9875 - val_accuracy: 0.2778\n",
      "Epoch 85/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.4774 - accuracy: 0.2681 - val_loss: 4.5884 - val_accuracy: 0.1111\n",
      "Epoch 86/150\n",
      "802/802 [==============================] - 0s 85us/step - loss: 3.0542 - accuracy: 0.2668 - val_loss: 5.3398 - val_accuracy: 0.1111\n",
      "Epoch 87/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.5729 - accuracy: 0.2344 - val_loss: 4.4442 - val_accuracy: 0.2778\n",
      "Epoch 88/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.2894 - accuracy: 0.3117 - val_loss: 3.5231 - val_accuracy: 0.1889\n",
      "Epoch 89/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.7520 - accuracy: 0.2332 - val_loss: 5.0363 - val_accuracy: 0.1889\n",
      "Epoch 90/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.4342 - accuracy: 0.2656 - val_loss: 3.0714 - val_accuracy: 0.2778\n",
      "Epoch 91/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.7253 - accuracy: 0.2506 - val_loss: 9.9747 - val_accuracy: 0.0222\n",
      "Epoch 92/150\n",
      "802/802 [==============================] - 0s 85us/step - loss: 3.2050 - accuracy: 0.2444 - val_loss: 5.1424 - val_accuracy: 0.1889\n",
      "Epoch 93/150\n",
      "802/802 [==============================] - 0s 111us/step - loss: 2.5522 - accuracy: 0.2282 - val_loss: 4.1231 - val_accuracy: 0.0556\n",
      "Epoch 94/150\n",
      "802/802 [==============================] - 0s 115us/step - loss: 2.3008 - accuracy: 0.2569 - val_loss: 7.8657 - val_accuracy: 0.2778\n",
      "Epoch 95/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.8317 - accuracy: 0.2930 - val_loss: 5.7375 - val_accuracy: 0.2778\n",
      "Epoch 96/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.7487 - accuracy: 0.2643 - val_loss: 4.2632 - val_accuracy: 0.2778\n",
      "Epoch 97/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.3993 - accuracy: 0.2756 - val_loss: 6.4929 - val_accuracy: 0.2778\n",
      "Epoch 98/150\n",
      "802/802 [==============================] - 0s 64us/step - loss: 2.6886 - accuracy: 0.2830 - val_loss: 3.9918 - val_accuracy: 0.0333\n",
      "Epoch 99/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.8104 - accuracy: 0.2344 - val_loss: 4.3625 - val_accuracy: 0.1889\n",
      "Epoch 100/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.5774 - accuracy: 0.2294 - val_loss: 3.7579 - val_accuracy: 0.0333\n",
      "Epoch 101/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.7210 - accuracy: 0.2257 - val_loss: 3.7969 - val_accuracy: 0.1111\n",
      "Epoch 102/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.4310 - accuracy: 0.2718 - val_loss: 3.8078 - val_accuracy: 0.0333\n",
      "Epoch 103/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.4099 - accuracy: 0.2506 - val_loss: 4.0414 - val_accuracy: 0.1111\n",
      "Epoch 104/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.7813 - accuracy: 0.2531 - val_loss: 3.8738 - val_accuracy: 0.2778\n",
      "Epoch 105/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.3657 - accuracy: 0.2631 - val_loss: 5.6825 - val_accuracy: 0.2778\n",
      "Epoch 106/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.4816 - accuracy: 0.3080 - val_loss: 2.5687 - val_accuracy: 0.2778\n",
      "Epoch 107/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.1434 - accuracy: 0.2880 - val_loss: 3.0081 - val_accuracy: 0.2778\n",
      "Epoch 108/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.1691 - accuracy: 0.3142 - val_loss: 9.3525 - val_accuracy: 0.1889\n",
      "Epoch 109/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 3.0735 - accuracy: 0.2706 - val_loss: 4.0101 - val_accuracy: 0.0222\n",
      "Epoch 110/150\n",
      "802/802 [==============================] - 0s 70us/step - loss: 2.7147 - accuracy: 0.2406 - val_loss: 4.0277 - val_accuracy: 0.1111\n",
      "Epoch 111/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.3117 - accuracy: 0.2756 - val_loss: 3.3410 - val_accuracy: 0.1889\n",
      "Epoch 112/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.5560 - accuracy: 0.2768 - val_loss: 3.6074 - val_accuracy: 0.1889\n",
      "Epoch 113/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.5026 - accuracy: 0.2855 - val_loss: 4.4330 - val_accuracy: 0.1889\n",
      "Epoch 114/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.6248 - accuracy: 0.2544 - val_loss: 8.0570 - val_accuracy: 0.2778\n",
      "Epoch 115/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.9246 - accuracy: 0.2818 - val_loss: 10.2145 - val_accuracy: 0.1111\n",
      "Epoch 116/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 3.0940 - accuracy: 0.2519 - val_loss: 4.5820 - val_accuracy: 0.2778\n",
      "Epoch 117/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.4471 - accuracy: 0.2843 - val_loss: 3.9615 - val_accuracy: 0.1889\n",
      "Epoch 118/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.3081 - accuracy: 0.2731 - val_loss: 2.9666 - val_accuracy: 0.2778\n",
      "Epoch 119/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.1774 - accuracy: 0.2943 - val_loss: 6.2298 - val_accuracy: 0.1111\n",
      "Epoch 120/150\n",
      "802/802 [==============================] - 0s 71us/step - loss: 2.5655 - accuracy: 0.2681 - val_loss: 4.7061 - val_accuracy: 0.1111\n",
      "Epoch 121/150\n",
      "802/802 [==============================] - 0s 107us/step - loss: 2.5700 - accuracy: 0.2531 - val_loss: 3.4413 - val_accuracy: 0.1889\n",
      "Epoch 122/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.4619 - accuracy: 0.2743 - val_loss: 3.4065 - val_accuracy: 0.1889\n",
      "Epoch 123/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.8428 - accuracy: 0.2257 - val_loss: 7.7252 - val_accuracy: 0.2778\n",
      "Epoch 124/150\n",
      "802/802 [==============================] - 0s 82us/step - loss: 2.8399 - accuracy: 0.2793 - val_loss: 5.2845 - val_accuracy: 0.1111\n",
      "Epoch 125/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.4554 - accuracy: 0.2668 - val_loss: 4.0806 - val_accuracy: 0.0556\n",
      "Epoch 126/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.4932 - accuracy: 0.2594 - val_loss: 3.5420 - val_accuracy: 0.1889\n",
      "Epoch 127/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.7840 - accuracy: 0.2032 - val_loss: 4.9260 - val_accuracy: 0.1111\n",
      "Epoch 128/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.6483 - accuracy: 0.2544 - val_loss: 3.7998 - val_accuracy: 0.0556\n",
      "Epoch 129/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.3598 - accuracy: 0.2731 - val_loss: 2.2656 - val_accuracy: 0.2778\n",
      "Epoch 130/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 1.9552 - accuracy: 0.2768 - val_loss: 7.2771 - val_accuracy: 0.2778\n",
      "Epoch 131/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.5150 - accuracy: 0.2905 - val_loss: 6.4551 - val_accuracy: 0.2778\n",
      "Epoch 132/150\n",
      "802/802 [==============================] - 0s 66us/step - loss: 2.8435 - accuracy: 0.2656 - val_loss: 8.5979 - val_accuracy: 0.1889\n",
      "Epoch 133/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 2.9131 - accuracy: 0.2893 - val_loss: 8.4007 - val_accuracy: 0.1889\n",
      "Epoch 134/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.8445 - accuracy: 0.2556 - val_loss: 4.6534 - val_accuracy: 0.0556\n",
      "Epoch 135/150\n",
      "802/802 [==============================] - 0s 81us/step - loss: 2.3112 - accuracy: 0.2556 - val_loss: 4.1710 - val_accuracy: 0.0111\n",
      "Epoch 136/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.4504 - accuracy: 0.2057 - val_loss: 4.3625 - val_accuracy: 0.0556\n",
      "Epoch 137/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.4557 - accuracy: 0.2481 - val_loss: 2.7948 - val_accuracy: 0.2778\n",
      "Epoch 138/150\n",
      "802/802 [==============================] - 0s 74us/step - loss: 2.4441 - accuracy: 0.2631 - val_loss: 4.7144 - val_accuracy: 0.1889\n",
      "Epoch 139/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.7743 - accuracy: 0.2357 - val_loss: 4.5862 - val_accuracy: 0.2778\n",
      "Epoch 140/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.4688 - accuracy: 0.2756 - val_loss: 7.7191 - val_accuracy: 0.2778\n",
      "Epoch 141/150\n",
      "802/802 [==============================] - 0s 69us/step - loss: 2.8872 - accuracy: 0.2581 - val_loss: 2.7868 - val_accuracy: 0.2778\n",
      "Epoch 142/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.2692 - accuracy: 0.2681 - val_loss: 3.2122 - val_accuracy: 0.2778\n",
      "Epoch 143/150\n",
      "802/802 [==============================] - 0s 65us/step - loss: 2.5561 - accuracy: 0.2805 - val_loss: 4.1410 - val_accuracy: 0.1111\n",
      "Epoch 144/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.6047 - accuracy: 0.2768 - val_loss: 2.8602 - val_accuracy: 0.2778\n",
      "Epoch 145/150\n",
      "802/802 [==============================] - 0s 77us/step - loss: 2.4800 - accuracy: 0.2506 - val_loss: 8.7064 - val_accuracy: 0.1889\n",
      "Epoch 146/150\n",
      "802/802 [==============================] - 0s 72us/step - loss: 3.0148 - accuracy: 0.2569 - val_loss: 4.4445 - val_accuracy: 0.2778\n",
      "Epoch 147/150\n",
      "802/802 [==============================] - 0s 67us/step - loss: 2.3299 - accuracy: 0.2668 - val_loss: 5.4342 - val_accuracy: 0.1889\n",
      "Epoch 148/150\n",
      "802/802 [==============================] - 0s 76us/step - loss: 2.7534 - accuracy: 0.2519 - val_loss: 4.1838 - val_accuracy: 0.1111\n",
      "Epoch 149/150\n",
      "802/802 [==============================] - 0s 75us/step - loss: 2.5289 - accuracy: 0.2656 - val_loss: 4.8295 - val_accuracy: 0.1111\n",
      "Epoch 150/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 67us/step - loss: 2.3261 - accuracy: 0.2843 - val_loss: 4.7525 - val_accuracy: 0.1889\n",
      "460/460 [==============================] - 0s 67us/step\n",
      "Loss: 4.99\n",
      "Accuracy 0.15\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "newModel = Sequential()\n",
    "newModel.add(Dense(3, activation='relu', input_dim=8))\n",
    "newModel.add(Dense(3, activation='relu'))\n",
    "newModel.add(Dense(10, activation='softmax'))\n",
    "#comile the model:\n",
    "newModel.compile(\n",
    "  optimizer=opt,\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "history = newModel.fit(\n",
    "  X_train,\n",
    "  y_train,\n",
    "  epochs=150,\n",
    "  batch_size=100, \n",
    "  verbose=1,\n",
    "  validation_split=0.1\n",
    ")\n",
    "loss, accuracy = newModel.evaluate(\n",
    "  X_test,\n",
    "  y_test\n",
    ")\n",
    "print(accuracy)\n",
    "#now using grid search:\n",
    "def createNewModel(i,j):\n",
    "    modelSearch = Sequential()\n",
    "    for nodes in range(0,j+1):\n",
    "        modelSearch.add(Dense(i, activation='relu'))\n",
    "    modelSearch.add(Dense(10, activation='softmax'))\n",
    "    modelSearch.compile(\n",
    "      optimizer=opt,\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy'],\n",
    "    )\n",
    "    modelSearch.fit(\n",
    "      X_train,\n",
    "      y_train,\n",
    "      epochs=150,\n",
    "      batch_size=100,\n",
    "      verbose=1,\n",
    "      validation_split=0.1,\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    loss, accuracy = modelSearch.evaluate(\n",
    "      X_test,\n",
    "      y_test\n",
    "    )\n",
    "    print('Loss: %.2f' % loss)\n",
    "    print(\"Accuracy %.2f\" %(accuracy))\n",
    "for i in range(1,4):\n",
    "    for j in range(3,13):\n",
    "        if(j%3 == 0):\n",
    "            createNewModel(i,j)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('train error per iteration')\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training error', 'testing error'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
